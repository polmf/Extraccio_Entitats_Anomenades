{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install python-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pycrfsuite\n",
    "from nltk.corpus import conll2002\n",
    "from nltk.tag import CRFTagger\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # Tokenitzador\n",
    "nltk.download('averaged_perceptron_tagger') # Etiquetador POS\n",
    "nltk.download('maxent_ne_chunker') # Etiquetador Entitats Anomenades\n",
    "nltk.download('words')\n",
    "nltk.download('treebank')\n",
    "nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_esp = conll2002.iob_sents('esp.train') # Train, ned.train => Neerlandès\n",
    "testa_esp = conll2002.iob_sents('esp.testa') # Dev\n",
    "testb_esp = conll2002.iob_sents('esp.testb') # Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ned = conll2002.iob_sents('ned.train') # Train, ned.train => Neerlandès\n",
    "testa_ned = conll2002.iob_sents('ned.testa') # Dev\n",
    "testb_ned = conll2002.iob_sents('ned.testb') # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicció amb BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Espanyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tagger = CRFTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447121289420479\n"
     ]
    }
   ],
   "source": [
    "# Entrenem el model per predir els POS que corresponen a cada token\n",
    "\n",
    "train_esp_pos_tag = []\n",
    "for sentence in train_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem2))\n",
    "    train_esp_pos_tag.append(frases)\n",
    "    \n",
    "model_tagger.train(train_esp_pos_tag, 'model_POS.crf.tagger')\n",
    "\n",
    "\n",
    "# Fem prediccions i mirem l'accuracy\n",
    "\n",
    "testa_esp_pre_tag = []\n",
    "for sentence in testa_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append(elem1)\n",
    "    testa_esp_pre_tag.append(frases)\n",
    "    \n",
    "predicted = model_tagger.tag_sents(testa_esp_pre_tag)\n",
    "\n",
    "predictions = [elem[1] for sentence in predicted for elem in sentence]\n",
    "real_label = [elem[1] for sentence in testa_esp for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions, real_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from nltk.tag import CRFTagger\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "\n",
    "class FeatureExtractor2:\n",
    "    def __init__(self, use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False, pattern = r'\\d+'):\n",
    "        self.use_basic_features = use_basic_features\n",
    "        self.use_prefix_suffix_features = use_prefix_suffix_features\n",
    "        self.use_context_features = use_context_features\n",
    "        self._pattern = pattern\n",
    "        self.feature_list = []\n",
    "\n",
    "    def _extract_basic_features(self, token):\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            self.feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            self.feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            self.feature_list.append(\"PUNCTUATION\")\n",
    "\n",
    "    def _extract_prefix_suffix_features(self, token):\n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            self.feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            self.feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            self.feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            self.feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            self.feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            self.feature_list.append(\"SUF_\" + token[-3:])\n",
    "\n",
    "    def _extract_context_features(self, token, tokens, idx):\n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            self.feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            self.feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            self.feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            self.feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        self.feature_list.append(\"WORD_\" + token)\n",
    "    \n",
    "    def _get_features(self, tokens, idx):\n",
    "        token = tokens[idx]\n",
    "        \n",
    "        if self.use_basic_features:\n",
    "            self._extract_basic_features(token)\n",
    "                    \n",
    "        if self.use_prefix_suffix_features:\n",
    "            self._extract_prefix_suffix_features(token)\n",
    "        \n",
    "        if self.use_context_features:\n",
    "            self._extract_context_features(token, tokens, idx)\n",
    "            \n",
    "        \n",
    "        return self.feature_list\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     train_esp_BIO_tag\u001b[38;5;241m.\u001b[39mappend(frases)\n\u001b[0;32m     11\u001b[0m model_BIO \u001b[38;5;241m=\u001b[39m CRFTagger(feature_func\u001b[38;5;241m=\u001b[39mfeature_extractor\u001b[38;5;241m.\u001b[39m_get_features)\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel_BIO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_esp_BIO_tag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_BIO.crf.tagger\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\nltk\\tag\\crf.py:187\u001b[0m, in \u001b[0;36mCRFTagger.train\u001b[1;34m(self, train_data, model_file)\u001b[0m\n\u001b[0;32m    185\u001b[0m     tokens, labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39msent)\n\u001b[0;32m    186\u001b[0m     features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_feature_func(tokens, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(tokens))]\n\u001b[1;32m--> 187\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mappend(features, labels)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# Now train the model, the output should be model_file\u001b[39;00m\n\u001b[0;32m    190\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain(model_file)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"#feature_extractor = FeatureExtractor2(use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False, pattern = r'\\d+')\n",
    "feature_extractor = FeatureExtractor2(use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True, pattern = r'\\d+')\n",
    "\n",
    "train_esp_BIO_tag = []\n",
    "for sentence in train_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    train_esp_BIO_tag.append(frases)\n",
    "    \n",
    "model_BIO = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIO.train(train_esp_BIO_tag, 'model_BIO.crf.tagger')\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span> Features que es tenen en compte:\n",
    "<ul>\n",
    "    <li>Paraula actual</li>\n",
    "    <li>Si comença en majúscula</li>\n",
    "    <li>Si té signe de puntuació</li>\n",
    "    <li>Si té números</li>\n",
    "    <li>Prefixos fins a longitud 3</li>\n",
    "    <li>Sufixos fins a longitud 3</li>\n",
    "    <li>Paraules prèvies i posteriors amb POS</li>\n",
    "    <li>POS-tags</li>\n",
    "    <li>Longitud de la paraula</li>\n",
    "</ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor1:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "            - longitud\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "        token= tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "            \n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"SUF_\" + token[-3:])\n",
    "        \n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        feature_list.append(\"WORD_\" + token)\n",
    "\n",
    "        return feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor2:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "\n",
    "        token = tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "            \n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"SUF_\" + token[-3:])\n",
    "\n",
    "        return feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor3:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "\n",
    "        token = tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "\n",
    "        return feature_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_esp_BIO_tag1 = []\n",
    "for sentence in train_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    train_esp_BIO_tag1.append(frases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia de FeatureExtractor\n",
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor1 = FeatureExtractor1(pattern)\n",
    "\n",
    "model_BIO1 = CRFTagger(feature_func=feature_extractor1._get_features)\n",
    "model_BIO1.train(train_esp_BIO_tag1, 'model_BIO.crf.tagger')\n",
    "\n",
    "feature_extractor2 = FeatureExtractor2(pattern)\n",
    "\n",
    "model_BIO2 = CRFTagger(feature_func=feature_extractor2._get_features)\n",
    "model_BIO2.train(train_esp_BIO_tag1, 'model_BIO.crf.tagger')\n",
    "\n",
    "feature_extractor3 = FeatureExtractor3(pattern)\n",
    "\n",
    "model_BIO3 = CRFTagger(feature_func=feature_extractor3._get_features)\n",
    "model_BIO3.train(train_esp_BIO_tag1, 'model_BIO.crf.tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilitzem aquest accuracy per ajustar els features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconeixem entitats i avaluem la detecció d'entitats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaluació amb sets veure si son iguals també es pot mirar per intersecció i si coincideixen\n",
    "def obtener_entidades_con_posiciones(testa_esp_BIO_tag):\n",
    "    entitats_con_posiciones = set()\n",
    "\n",
    "    for sentence_index, sentence in enumerate(testa_esp_BIO_tag):\n",
    "        ent = []\n",
    "        name = None\n",
    "        start_pos = None  # Posición de inicio de la entidad actual\n",
    "        prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "\n",
    "        for token_index, token in enumerate(sentence):\n",
    "            word, tag = token\n",
    "\n",
    "            if tag.startswith('B-'):\n",
    "                # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "                if ent:\n",
    "                    end_pos = token_index - 1  # La posición de fin es el token anterior\n",
    "                    entitats_con_posiciones.add((tuple(ent), (start_pos, end_pos)))\n",
    "                # Creamos una nueva entidad con la palabra actual\n",
    "                ent = [word]\n",
    "                # Obtenemos el tipo de entidad\n",
    "                name = tag.split('-')[1]\n",
    "                start_pos = token_index  # La posición de inicio es el token actual\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "            elif tag.startswith('I-'):\n",
    "                # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "                if prev_tag:\n",
    "                    ent.append(word)\n",
    "                    prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "            elif tag == 'O' and ent:\n",
    "                # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "                end_pos = token_index - 1  # La posición de fin es el token anterior\n",
    "                entitats_con_posiciones.add((tuple(ent), (start_pos, end_pos)))\n",
    "                # Reiniciamos la lista de la entidad actual\n",
    "                ent = []\n",
    "                prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "        # Agregamos la última entidad si la hay\n",
    "        if ent:\n",
    "            end_pos = len(sentence) - 1  # La posición de fin es el último token de la oración\n",
    "            entitats_con_posiciones.add((tuple(ent), (start_pos, end_pos)))\n",
    "\n",
    "    return entitats_con_posiciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_precision(entidades_referencia, entidades_extraidas):\n",
    "    # Calcular el número de entidades correctamente extraídas\n",
    "    entidades_correctas = entidades_referencia.intersection(entidades_extraidas)\n",
    "    \n",
    "    # Calcular la precisión\n",
    "    if len(entidades_extraidas) > 0:\n",
    "        precision = len(entidades_correctas) / len(entidades_extraidas)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "def calcular_exhaustividad(entidades_referencia, entidades_extraidas):\n",
    "    # Calcular el número de entidades correctamente extraídas\n",
    "    entidades_correctas = entidades_referencia.intersection(entidades_extraidas)\n",
    "    \n",
    "    # Calcular la exhaustividad\n",
    "    if len(entidades_referencia) > 0:\n",
    "        exhaustividad = len(entidades_correctas) / len(entidades_referencia)\n",
    "    else:\n",
    "        exhaustividad = 0.0\n",
    "    \n",
    "    return exhaustividad\n",
    "\n",
    "def calcular_f1_score(precision, exhaustividad):\n",
    "    # Calcular el F1-score\n",
    "    if (precision + exhaustividad) > 0:\n",
    "        f1_score = 2 * (precision * exhaustividad) / (precision + exhaustividad)\n",
    "    else:\n",
    "        f1_score = 0.0\n",
    "    \n",
    "    return f1_score\n",
    "\n",
    "def reultats(predicted_BIO, testa_esp_BIO_tag):\n",
    "\n",
    "    predicted_BIO = model_BIO1.tag_sents(testa_esp_pre_tag)\n",
    "    # Obtener los conjuntos de entidades de referencia y extraídas\n",
    "    entidades_referencia = obtener_entidades_con_posiciones(testa_esp_BIO_tag)  # Conjunto de entidades etiquetadas manualmente como referencia\n",
    "    entidades_extraidas =  obtener_entidades_con_posiciones(predicted_BIO) # Obtener conjuntos de entidades extraídas\n",
    "\n",
    "    # Calcular la precisión\n",
    "    precision = calcular_precision(entidades_referencia, entidades_extraidas)\n",
    "\n",
    "    # Calcular la exhaustividad\n",
    "    exhaustividad = calcular_exhaustividad(entidades_referencia, entidades_extraidas)\n",
    "\n",
    "    # Calcular el F1-score\n",
    "    f1_score = calcular_f1_score(precision, exhaustividad)\n",
    "\n",
    "    print(\"Precisión:\", precision)\n",
    "    print(\"Exhaustividad:\", exhaustividad)\n",
    "    print(\"F1-score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1\n",
      "Precisión: 0.9214474845542807\n",
      "Exhaustividad: 0.8743718592964824\n",
      "F1-score: 0.8972926514825956\n",
      "--------------------------------------------------\n",
      "Model 2\n",
      "Precisión: 0.9214474845542807\n",
      "Exhaustividad: 0.8743718592964824\n",
      "F1-score: 0.8972926514825956\n",
      "--------------------------------------------------\n",
      "Model 3\n",
      "Precisión: 0.9214474845542807\n",
      "Exhaustividad: 0.8743718592964824\n",
      "F1-score: 0.8972926514825956\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "testa_esp_BIO_tag = []\n",
    "for sentence in testa_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    testa_esp_BIO_tag.append(frases)\n",
    "\n",
    "real_label_BIO = [elem[1] for sentence in testa_esp_BIO_tag for elem in sentence]\n",
    "\n",
    "print('Model 1')\n",
    "predicted_BIO1 = model_BIO1.tag_sents(testa_esp_pre_tag)\n",
    "predictions_BIO1 = [elem[1] for sentence in predicted_BIO1 for elem in sentence]\n",
    "\n",
    "reultats(predictions_BIO1, testa_esp_BIO_tag)\n",
    "print('-'*50)\n",
    "\n",
    "print('Model 2')\n",
    "predicted_BIO2 = model_BIO2.tag_sents(testa_esp_pre_tag)\n",
    "predictions_BIO2 = [elem[1] for sentence in predicted_BIO2 for elem in sentence]\n",
    "\n",
    "reultats(predictions_BIO2, testa_esp_BIO_tag)\n",
    "print('-'*50)\n",
    "\n",
    "print('Model 3')\n",
    "predicted_BIO3 = model_BIO3.tag_sents(testa_esp_pre_tag)\n",
    "predictions_BIO3 = [elem[1] for sentence in predicted_BIO3 for elem in sentence]\n",
    "\n",
    "reultats(predictions_BIO3, testa_esp_BIO_tag)\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('CNE',), (27, 27)),\n",
       " (('Chandler', 'Thomson'), (30, 31)),\n",
       " (('UNA',), (6, 6)),\n",
       " (('Adecco', 'Estudiantes'), (43, 44)),\n",
       " (('CONGRESO',), (5, 5)),\n",
       " (('Mauro', 'Silva'), (34, 35)),\n",
       " (('BM.',\n",
       "   'GRANOLLERS',\n",
       "   '1959-60',\n",
       "   'BM.',\n",
       "   'GRANOLLERS',\n",
       "   '1960-61',\n",
       "   'BM.',\n",
       "   'GRANOLLERS',\n",
       "   '1961-62',\n",
       "   'SE',\n",
       "   'JUGO',\n",
       "   'LIGA',\n",
       "   'NACIONAL',\n",
       "   'DE'),\n",
       "  (27, 40)),\n",
       " (('Camacho', 'Solís'), (25, 26)),\n",
       " (('Fresi',), (42, 42)),\n",
       " (('PAIS', 'COTIZACION', 'OFICIAL', 'DOLAR', 'COMPRA', 'VENTA', 'Pesos'),\n",
       "  (17, 23)),\n",
       " (('Eugenio', 'Gay'), (15, 16)),\n",
       " (('América', 'Latina'), (24, 25)),\n",
       " (('Madrid',), (133, 133)),\n",
       " (('Badajoz', 'B'), (21, 22)),\n",
       " (('ESES&S',), (16, 16)),\n",
       " (('At',), (6, 6)),\n",
       " (('Grupo', 'Izquierda', 'Unida'), (19, 21)),\n",
       " (('Clinton',), (17, 17)),\n",
       " (('Chávez',), (38, 38)),\n",
       " (('Hugo', 'de', 'la', 'Calle'), (28, 31)),\n",
       " (('EFE',), (22, 22)),\n",
       " (('Djordjevic',), (0, 0)),\n",
       " (('Europa',), (35, 35)),\n",
       " (('EFECOM',), (5, 5)),\n",
       " (('Perú', '2000'), (36, 37)),\n",
       " (('Nantes',), (13, 13)),\n",
       " (('Puerta', 'Grande'), (48, 49)),\n",
       " (('Sao', 'Paulo'), (43, 44)),\n",
       " (('Bolsa', 'de', 'Nueva', 'York'), (5, 8)),\n",
       " (('Costa', 'Pacífica'), (18, 19)),\n",
       " (('Lupo',), (2, 2)),\n",
       " (('Zaplana',), (51, 51)),\n",
       " (('Sevilla',), (7, 7)),\n",
       " (('Agustin', 'Calleri'), (0, 1)),\n",
       " (('UEFA',), (4, 4)),\n",
       " (('Boehm',), (0, 0)),\n",
       " (('Moca',), (24, 24)),\n",
       " (('Saunders',), (35, 35)),\n",
       " (('Franklin', 'Barrett'), (11, 12)),\n",
       " (('Junta', 'de', 'Extremadura'), (4, 6)),\n",
       " (('BBVA',), (9, 9)),\n",
       " (('UNISYS',), (15, 15)),\n",
       " (('Puebla',), (23, 23)),\n",
       " (('ASAJA',), (6, 6)),\n",
       " (('Nueva', 'York'), (10, 11)),\n",
       " (('Pamplona',), (28, 28)),\n",
       " (('Nicaragua',), (93, 93)),\n",
       " (('Ministerio', 'de', 'Agricultura,', 'Pesca.', 'Alimentación'), (13, 17)),\n",
       " (('Nobel', 'de', 'Economía'), (12, 14)),\n",
       " (('Donna', 'Shalala'), (12, 13)),\n",
       " (('BBV-Probursa',), (17, 17)),\n",
       " (('Marx',), (13, 13)),\n",
       " (('ARG',), (9, 9)),\n",
       " (('Pedro', 'Cañellas'), (9, 10)),\n",
       " (('Adecco', 'Estudiantes', '73', 'Real', 'Madrid'), (15, 19)),\n",
       " (('Ejecutivo',), (5, 5)),\n",
       " (('Elián',), (37, 37)),\n",
       " (('Museo', 'de', 'Prehistoria'), (11, 13)),\n",
       " (('Lucio', 'Angulo'), (38, 39)),\n",
       " (('Instituto', 'Nacional', 'Demócrata'), (40, 42)),\n",
       " (('Gobierno',), (14, 14)),\n",
       " (('Badajoz',), (15, 15)),\n",
       " (('Tailandia',), (16, 16)),\n",
       " (('Copa', 'de', 'Campeones'), (69, 71)),\n",
       " (('Moisés',), (66, 66)),\n",
       " (('EFE',), (16, 16)),\n",
       " (('Efe', 'Castellano'), (21, 22)),\n",
       " (('Buenos', 'Aires'), (9, 10)),\n",
       " (('Juana', 'González', 'Linares'), (1, 3)),\n",
       " (('Eduardo', 'Nicolás'), (6, 7)),\n",
       " (('Feria', 'del', 'Libro'), (7, 9)),\n",
       " (('Departamento',\n",
       "   'de',\n",
       "   'Biología',\n",
       "   'Animal',\n",
       "   'de',\n",
       "   'la',\n",
       "   'Facultad',\n",
       "   'de',\n",
       "   'Ciencias',\n",
       "   'del',\n",
       "   'Mar',\n",
       "   'de',\n",
       "   'la',\n",
       "   'Universidad',\n",
       "   'de',\n",
       "   'Cádiz'),\n",
       "  (29, 44)),\n",
       " (('Gobierno',), (20, 20)),\n",
       " (('Valencia',), (15, 15)),\n",
       " (('Barcelona',), (15, 15)),\n",
       " (('Conchi', 'Paredes'), (21, 22)),\n",
       " (('Bolsa', 'Mexicana', 'de', 'Valores'), (1, 4)),\n",
       " (('Telesp',), (22, 22)),\n",
       " (('ESES&S',), (13, 13)),\n",
       " (('Allen',), (21, 21)),\n",
       " (('Real', 'Madrid'), (24, 25)),\n",
       " (('SEVILLA',), (12, 12)),\n",
       " (('BCR',), (41, 41)),\n",
       " (('Sao', 'Paulo'), (12, 13)),\n",
       " (('Instituto', 'del', 'Tabaco'), (44, 46)),\n",
       " (('Michael', 'Sell'), (6, 7)),\n",
       " (('Freestone',), (4, 4)),\n",
       " (('Maryland',), (4, 4)),\n",
       " (('Ibovespa',), (1, 1)),\n",
       " (('Cáceres',), (40, 40)),\n",
       " (('Wall', 'Street'), (24, 25)),\n",
       " (('Bernard', 'Kouchner'), (19, 20)),\n",
       " (('Telefónica',), (49, 49)),\n",
       " (('Santillana', 'del', 'Mar'), (30, 32)),\n",
       " (('Phillip', 'Cocu'), (35, 36)),\n",
       " (('Departamento', 'de', 'Energía'), (33, 35)),\n",
       " (('Susan', 'Pierson', 'Brown'), (3, 5)),\n",
       " (('Inter', 'de', 'Milán'), (1, 3)),\n",
       " (('Guy', 'Roux'), (5, 6)),\n",
       " (('Andalucía',), (45, 45)),\n",
       " (('Partido', 'Revolucionario', 'Dominicano'), (12, 14)),\n",
       " (('Perú',), (55, 55)),\n",
       " (('Palma',), (11, 11)),\n",
       " (('Aceuchal',), (18, 18)),\n",
       " (('Bilbao',), (20, 20)),\n",
       " (('Sicilia',), (41, 41)),\n",
       " (('Juan', 'de', 'Garay'), (0, 2)),\n",
       " (('Caracas',), (12, 12)),\n",
       " (('\"', 'Manza', 'Music'), (33, 35)),\n",
       " (('San', 'Cristóbal'), (10, 11)),\n",
       " (('BAH',), (9, 9)),\n",
       " (('Partido', 'Andalucista'), (19, 20)),\n",
       " (('Benavides',), (0, 0)),\n",
       " (('Wireless', 'Application', 'Protocol'), (36, 38)),\n",
       " (('EFE',), (13, 13)),\n",
       " (('Gobierno',), (36, 36)),\n",
       " (('COMPLOT',), (5, 5)),\n",
       " (('Gabriel', 'Omar', 'Batistuta'), (20, 22)),\n",
       " (('Arjona',), (21, 21)),\n",
       " (('EFE',), (38, 38)),\n",
       " (('Augusto', 'Pinochet'), (17, 18)),\n",
       " (('Chaves',), (51, 51)),\n",
       " (('Recreativo',), (26, 26)),\n",
       " (('España',), (12, 12)),\n",
       " (('Internet',), (9, 9)),\n",
       " (('Juan', 'Carlos', 'Doadrio'), (18, 20)),\n",
       " (('Brady',), (15, 15)),\n",
       " (('PM2044',), (1, 1)),\n",
       " (('Batistuta',), (16, 16)),\n",
       " (('Airport', 'Group', 'International'), (32, 34)),\n",
       " (('Doadrio',), (18, 18)),\n",
       " (('PSN',), (11, 11)),\n",
       " (('Fiesole',), (19, 19)),\n",
       " (('Parlamento', 'Foral'), (10, 11)),\n",
       " (('AFS',), (9, 9)),\n",
       " (('Liga',), (0, 0)),\n",
       " (('Real',), (34, 34)),\n",
       " (('Miguel', 'Miranda'), (32, 33)),\n",
       " (('Jorge', 'Escobar'), (45, 46)),\n",
       " (('UCK',), (31, 31)),\n",
       " (('Defensoría', 'del', 'Pueblo'), (4, 6)),\n",
       " (('Badajoz',), (10, 10)),\n",
       " (('Bob', 'Bryan'), (6, 7)),\n",
       " (('Cancún',), (0, 0)),\n",
       " (('Bustos',), (20, 20)),\n",
       " (('Congreso',\n",
       "   'Interamericano',\n",
       "   'del',\n",
       "   'Libro',\n",
       "   'del',\n",
       "   'Grupo',\n",
       "   'Interamericano',\n",
       "   'de',\n",
       "   'Editores'),\n",
       "  (21, 29)),\n",
       " (('Simic',), (8, 8)),\n",
       " (('Lawrence', 'R.', 'Klein'), (0, 2)),\n",
       " (('México',), (10, 10)),\n",
       " (('Mérida',), (3, 3)),\n",
       " (('Parlamento',), (14, 14)),\n",
       " (('Giro', 'de', 'Italia'), (20, 22)),\n",
       " (('CZE',), (32, 32)),\n",
       " (('Finanzas',), (3, 3)),\n",
       " (('Endesa',), (35, 35)),\n",
       " (('Tenerife',), (37, 37)),\n",
       " (('Menorca',), (15, 15)),\n",
       " (('Josep', 'Maldonado'), (6, 7)),\n",
       " (('Barcelona',), (10, 10)),\n",
       " (('Castaño',), (18, 18)),\n",
       " (('Breda',), (21, 21)),\n",
       " (('Jose', 'Acasuso'), (23, 24)),\n",
       " (('Cataluña',), (32, 32)),\n",
       " (('Lleida',), (55, 55)),\n",
       " (('Colombia',), (6, 6)),\n",
       " (('Germán', 'Puentes'), (0, 1)),\n",
       " (('PSOE',), (19, 19)),\n",
       " (('Toledo',), (13, 13)),\n",
       " (('Geles',), (8, 8)),\n",
       " (('EFE',), (54, 54)),\n",
       " (('II',), (48, 48)),\n",
       " (('Bogotá',), (36, 36)),\n",
       " (('Jose',), (41, 41)),\n",
       " (('Caicedo',), (2, 2)),\n",
       " (('López', 'de', 'Arriortúa'), (6, 8)),\n",
       " (('Campeonato', 'Suramericano', 'Juvenil', 'Masculino'), (12, 15)),\n",
       " (('Alomar',), (13, 13)),\n",
       " (('BBVA',), (30, 30)),\n",
       " (('Mejía',), (0, 0)),\n",
       " (('Palacio', 'de', 'La', 'Merced'), (71, 74)),\n",
       " (('Gobierno',), (83, 83)),\n",
       " (('Gobierno', 'de', 'Sierra', 'Leona'), (3, 6)),\n",
       " (('Stanic',), (16, 16)),\n",
       " (('ALOMAR', 'MANTIENE', 'QUE', '\"', 'HABRA', 'CONSENSO', 'SOCIAL'), (3, 9)),\n",
       " (('Venezuela',), (129, 129)),\n",
       " (('Andoni', 'Goicoetxea'), (17, 18)),\n",
       " (('Francesc', 'Ricomé'), (14, 15)),\n",
       " (('Estudiantes',), (50, 50)),\n",
       " (('Hizbulá',), (21, 21)),\n",
       " (('Muestra', 'de', 'Arte', 'Electrónico'), (23, 26)),\n",
       " (('Comunicación', 'Social'), (3, 4)),\n",
       " (('BankWest',), (29, 29)),\n",
       " (('Copa', 'del', 'Mundo'), (7, 9)),\n",
       " (('La', 'Voz', 'de', 'Galicia'), (16, 19)),\n",
       " (('David', 'Albelda'), (27, 28)),\n",
       " (('CNE',), (7, 7)),\n",
       " (('Televisa',), (16, 16)),\n",
       " (('Gerard', 'Quintana'), (44, 45)),\n",
       " (('Leganés',), (27, 27)),\n",
       " (('Percy', 'Olivares'), (21, 22)),\n",
       " (('Betts',), (44, 44)),\n",
       " (('Aristide',), (6, 6)),\n",
       " (('Constitución',), (9, 9)),\n",
       " (('Mérida',), (19, 19)),\n",
       " (('Varela',), (99, 99)),\n",
       " (('Madrid',), (28, 28)),\n",
       " (('Relaciones', 'Internacionales', 'de', 'la', 'Agencia', 'Efe'), (3, 8)),\n",
       " (('Ley', 'de', 'Enjuiciamiento', 'Criminal', 'moderna'), (24, 28)),\n",
       " (('Universidad', 'de', 'las', 'Islas', 'Baleares'), (1, 5)),\n",
       " (('IPC',), (6, 6)),\n",
       " (('Tiago',), (35, 35)),\n",
       " (('Vigo',), (0, 0)),\n",
       " (('Cesar', 'Sampaio'), (25, 26)),\n",
       " (('Ejecutivo',), (37, 37)),\n",
       " (('Argentina',), (14, 14)),\n",
       " (('Sao', 'Paulo'), (23, 24)),\n",
       " (('Recreativo',), (17, 17)),\n",
       " (('EFE',), (55, 55)),\n",
       " (('Centroamérica',), (21, 21)),\n",
       " (('Pristina',), (0, 0)),\n",
       " (('Espanyol',), (8, 8)),\n",
       " (('F.', 'G.', 'M.'), (31, 33)),\n",
       " (('Londres',), (24, 24)),\n",
       " (('Liga', 'de', 'Campeones'), (13, 15)),\n",
       " (('Josep', 'Lluís', 'Vilaseca'), (2, 4)),\n",
       " (('Wappup.com',), (0, 0)),\n",
       " (('Nasdaq',), (61, 61)),\n",
       " (('Transportes',), (31, 31)),\n",
       " (('ESL',), (31, 31)),\n",
       " (('Perú',), (39, 39)),\n",
       " (('Consejo', 'por', 'la', 'Paz'), (46, 49)),\n",
       " (('Canadá',), (24, 24)),\n",
       " (('Arranz',), (54, 54)),\n",
       " (('Argentina',), (20, 20)),\n",
       " (('Turismo.', 'Deporte'), (3, 4)),\n",
       " (('Edica',), (49, 49)),\n",
       " ((\"Moody's\", 'Investors'), (33, 34)),\n",
       " (('Galilea',), (49, 49)),\n",
       " (('Arabia', 'Saudí'), (33, 34)),\n",
       " (('Juan', 'Carlos', 'Estévez'), (0, 2)),\n",
       " (('CBF',), (14, 14)),\n",
       " (('Guipúzcoa',), (52, 52)),\n",
       " (('José', 'María', 'Aznar'), (5, 7)),\n",
       " (('Organización', 'Nacional', 'de', 'Ciegos', 'de', 'España'), (17, 22)),\n",
       " (('Mario', 'Stanic'), (2, 3)),\n",
       " (('Curro', 'Romero'), (0, 1)),\n",
       " (('Linda', 'Woods'), (13, 14)),\n",
       " (('Si', 'Río'), (1, 2)),\n",
       " (('Danny', 'Rivera'), (31, 32)),\n",
       " (('Europa',), (32, 32)),\n",
       " (('Vitoria',), (0, 0)),\n",
       " (('Concepción', 'de', 'Nuestra', 'Señora'), (38, 41)),\n",
       " (('Brasil',), (6, 6)),\n",
       " (('Everest',), (14, 14)),\n",
       " (('WAP',), (34, 34)),\n",
       " (('Iván', 'Vallejo'), (3, 4)),\n",
       " (('Congreso', 'de', 'los', 'Diputados'), (1, 4)),\n",
       " (('Mallorca',), (46, 46)),\n",
       " (('Harmodio', 'Arias'), (16, 17)),\n",
       " (('USA',), (3, 3)),\n",
       " (('Fernando', 'Fernández'), (6, 7)),\n",
       " (('Córdoba',), (37, 37)),\n",
       " (('Puerto', 'de', 'Santa', 'María', 'de', 'los', 'Buenos', 'Aires'),\n",
       "  (14, 21)),\n",
       " (('Guayana', 'Francesa'), (42, 43)),\n",
       " (('Verona',), (39, 39)),\n",
       " (('Cuarta',\n",
       "   'Reunión',\n",
       "   'Ministerial',\n",
       "   'de',\n",
       "   'Telecomunicaciones.',\n",
       "   'Industria',\n",
       "   'de',\n",
       "   'la',\n",
       "   'Información'),\n",
       "  (22, 30)),\n",
       " (('Euskal', 'Herritarrok'), (3, 4)),\n",
       " (('Ignacio', 'Truyol'), (0, 1)),\n",
       " (('PA',), (7, 7)),\n",
       " (('Brasil',), (21, 21)),\n",
       " (('UPC',), (15, 15)),\n",
       " (('Extremadura',), (6, 6)),\n",
       " (('Colombia',), (16, 16)),\n",
       " (('Chandler', 'Thompson'), (3, 4)),\n",
       " (('España',), (29, 29)),\n",
       " (('Recreativo',), (43, 43)),\n",
       " (('Govern',), (29, 29)),\n",
       " (('Qatar',), (58, 58)),\n",
       " (('Musimundo',), (5, 5)),\n",
       " (('Sergi', 'Bruguera'), (3, 4)),\n",
       " (('Sercam',), (30, 30)),\n",
       " (('Getafe',), (33, 33)),\n",
       " (('Antoine', 'Duboscq'), (54, 55)),\n",
       " (('Copa', 'del', 'Rey'), (42, 44)),\n",
       " (('Sporting',), (31, 31)),\n",
       " (('Jurado',), (6, 6)),\n",
       " (('AMAN',), (18, 18)),\n",
       " (('Florida',), (12, 12)),\n",
       " (('Rodri',), (5, 5)),\n",
       " (('Júpiter',), (32, 32)),\n",
       " (('PYP', 'B'), (8, 9)),\n",
       " (('Escuela', 'Reina', 'Sofía'), (29, 31)),\n",
       " (('Joao', 'Pimienta', 'da', 'Veiga'), (23, 26)),\n",
       " (('BARCELONA',), (49, 49)),\n",
       " (('Ayuntamiento', 'de', 'Puerto', 'Príncipe'), (40, 43)),\n",
       " (('Julio', 'Rivera'), (6, 7)),\n",
       " (('Chávez',), (8, 8)),\n",
       " (('Banco', 'Bilbao-Vizcaya'), (29, 30)),\n",
       " (('Michel', 'Francois', 'Poncet'), (9, 11)),\n",
       " (('Secretaría', 'de', 'Finanzas'), (4, 6)),\n",
       " (('Alexandria',), (9, 9)),\n",
       " (('Consejo', 'Nacional', 'Electoral'), (23, 25)),\n",
       " (('ACOPEP',), (13, 13)),\n",
       " (('FNC',), (38, 38)),\n",
       " (('Martianez',), (2, 2)),\n",
       " (('III',\n",
       "   'Conferencia',\n",
       "   'Iberoamericana',\n",
       "   'de',\n",
       "   'Ministros',\n",
       "   'de',\n",
       "   'Administración',\n",
       "   'Pública.',\n",
       "   'Reforma',\n",
       "   'del',\n",
       "   'Estado'),\n",
       "  (15, 25)),\n",
       " (('FC', 'Barcelona'), (27, 28)),\n",
       " (('INFORME', 'ARARTEKO'), (1, 2)),\n",
       " (('Raimundo', 'Saporta'), (20, 21)),\n",
       " (('Christian', 'Vieri'), (3, 4)),\n",
       " (('Miami',), (13, 13)),\n",
       " (('Barrufet',), (43, 43)),\n",
       " (('Carlos', 'Floriano'), (8, 9)),\n",
       " (('Diputación',), (7, 7)),\n",
       " (('UIB',), (3, 3)),\n",
       " (('Mar', 'del', 'Plata'), (33, 35)),\n",
       " (('Misión', 'de', 'las', 'Naciones', 'Unidas'), (4, 8)),\n",
       " (('Euroliga',), (27, 27)),\n",
       " (('Mickey', 'Blue', 'Eyes'), (36, 38)),\n",
       " (('Guayana',), (6, 6)),\n",
       " (('Joana', 'Barceló'), (7, 8)),\n",
       " (('ACNO',), (3, 3)),\n",
       " (('Carvalho',), (8, 8)),\n",
       " (('Telefónica',), (3, 3)),\n",
       " (('Estados', 'Unidos'), (34, 35)),\n",
       " (('Orquesta', 'Sinfónica', 'de', 'RTVE'), (9, 12)),\n",
       " (('Comisión', 'de', 'Concordia.', 'Pacificación'), (23, 26)),\n",
       " (('Concierto', 'del', 'amor'), (36, 38)),\n",
       " (('Josep', 'Maldonado'), (38, 39)),\n",
       " (('Albert', 'Montañés'), (0, 1)),\n",
       " (('Departamento', 'de', 'Justicia'), (44, 46)),\n",
       " (('TEKA', 'SANTANDER', 'ELGORRIAGA', 'BIDASOA'), (44, 47)),\n",
       " (('India',), (13, 13)),\n",
       " (('Alianza', 'de', 'la', 'Unión', 'Cívica', 'Radical'), (6, 11)),\n",
       " (('Carlos', 'Reutemann'), (51, 52)),\n",
       " (('Congreso', 'de', 'la', 'República'), (21, 24)),\n",
       " (('Kuru',), (37, 37)),\n",
       " (('Datanálisis',), (3, 3)),\n",
       " (('Chicago',), (23, 23)),\n",
       " (('Pedralbes',), (49, 49)),\n",
       " (('París',), (0, 0)),\n",
       " (('Feria', 'de', 'Alfarería.', 'el', 'Barro'), (11, 15)),\n",
       " (('Armando', 'Manzanero'), (4, 5)),\n",
       " (('Chávez',), (24, 24)),\n",
       " (('JNE',), (15, 15)),\n",
       " (('PNV',), (12, 12)),\n",
       " (('Microsoft',), (13, 13)),\n",
       " (('Pau',), (10, 10)),\n",
       " (('Grupo', 'de', 'Telecomunicaciones'), (36, 38)),\n",
       " (('Comunidad', 'Valenciana'), (66, 67)),\n",
       " (('Iberdrola',), (26, 26)),\n",
       " (('SV2071',), (1, 1)),\n",
       " (('CVM',), (12, 12)),\n",
       " (('Isaías', 'Abrutzky'), (12, 13)),\n",
       " (('Fernando', 'González'), (6, 7)),\n",
       " (('FDA',), (30, 30)),\n",
       " (('Brasil',), (16, 16)),\n",
       " (('Copa', 'de', 'la', 'UEFA'), (16, 19)),\n",
       " (('Cataluña',), (22, 22)),\n",
       " (('Tribunal',), (3, 3)),\n",
       " (('Lupo',), (9, 9)),\n",
       " (('Fundación', 'Ramon', 'Trias', 'Fargas'), (43, 46)),\n",
       " (('PRD',), (21, 21)),\n",
       " (('FRA',), (3, 3)),\n",
       " (('Córdoba',), (6, 6)),\n",
       " (('Francisco', 'Pizarro'), (8, 9)),\n",
       " (('Grupo', 'Bancomer'), (5, 6)),\n",
       " (('Maharastra',), (29, 29)),\n",
       " (('Programa',\n",
       "   'Venezolano',\n",
       "   'de',\n",
       "   'Educación-Acción',\n",
       "   'en',\n",
       "   'Derechos',\n",
       "   'Humanos'),\n",
       "  (1, 7)),\n",
       " (('Nueva', 'York'), (27, 28)),\n",
       " (('PA',), (45, 45)),\n",
       " (('Paribas',), (18, 18)),\n",
       " (('Málaga',), (46, 46)),\n",
       " (('Baleares',), (11, 11)),\n",
       " (('estadio', 'del', 'Milenio'), (21, 23)),\n",
       " (('Fuser',), (12, 12)),\n",
       " (('Latin', 'Look'), (16, 17)),\n",
       " (('Carlos', 'Luis', 'López'), (4, 6)),\n",
       " (('Chávez',), (3, 3)),\n",
       " (('Italia',), (2, 2)),\n",
       " (('Antonio', 'Chenel'), (0, 1)),\n",
       " (('Leica',), (21, 21)),\n",
       " (('Domingo', 'Siro'), (2, 3)),\n",
       " (('Fede', 'Marín'), (12, 13)),\n",
       " (('EFE',), (8, 8)),\n",
       " (('Frente', 'del', 'País', 'Solidario'), (14, 17)),\n",
       " (('Venezuela',), (4, 4)),\n",
       " (('FEMPEX',), (1, 1)),\n",
       " (('Cafú',), (4, 4)),\n",
       " (('Cámara', 'Costarricense', 'de', 'Libro'), (1, 4)),\n",
       " (('María', 'de', 'Palma'), (47, 49)),\n",
       " (('Ley', 'de', 'Comercio', 'Minorista', 'de', 'Extremadura'), (8, 13)),\n",
       " (('Real', 'Madrid'), (10, 11)),\n",
       " (('Teatro', 'Teresa', 'Carreño'), (26, 28)),\n",
       " (('Daniel', 'Melo'), (6, 7)),\n",
       " (('Gaston', 'Etlis'), (0, 1)),\n",
       " (('HOL',), (9, 9)),\n",
       " (('Matilde', 'Fernández'), (6, 7)),\n",
       " (('Florencia',), (31, 31)),\n",
       " (('España',), (40, 40)),\n",
       " (('Consejo', 'por', 'la', 'Paz'), (5, 8)),\n",
       " (('Sabas',), (19, 19)),\n",
       " (('Las', 'Fallas', 'de', 'Valencia'), (33, 36)),\n",
       " (('Dáger',), (38, 38)),\n",
       " (('Cormar',), (36, 36)),\n",
       " (('Barbeito',), (14, 14)),\n",
       " (('Argentina',), (25, 25)),\n",
       " (('Efe',), (25, 25)),\n",
       " (('Salamanca',), (9, 9)),\n",
       " (('\"', 'Iglesia.', 'Medios', 'de', 'Comunicación'), (26, 30)),\n",
       " (('Liga', 'Asobal'), (50, 51)),\n",
       " (('Universitat', 'Politécnica', 'de', 'Catalunya'), (21, 24)),\n",
       " (('Instituto', 'Hispano-árabe', 'para', 'la', 'Comunicación'), (23, 27)),\n",
       " (('Fidel', 'Castro'), (39, 40)),\n",
       " (('Pablo', 'Zúniga'), (29, 30)),\n",
       " (('Quince',), (6, 6)),\n",
       " (('Buenos', 'Aires'), (42, 43)),\n",
       " (('Siria',), (29, 29)),\n",
       " (('Juiz', 'de', 'Fora'), (3, 5)),\n",
       " (('PRD',), (16, 16)),\n",
       " (('Daniel', 'Sawicki'), (49, 50)),\n",
       " (('Sevilla',), (9, 9)),\n",
       " (('Antonio', 'Viana', 'Baptista'), (12, 14)),\n",
       " (('EEUU',), (25, 25)),\n",
       " (('Cáceres',), (5, 5)),\n",
       " (('R.', 'IBARRA'), (3, 4)),\n",
       " (('Manzanero',), (20, 20)),\n",
       " (('Mariano', 'Hood'), (6, 7)),\n",
       " (('Federación', 'Nacional', 'de', 'Cafeteros', 'de', 'Colombia'), (4, 9)),\n",
       " (('Feria', 'Internacional', 'del', 'Libro', 'de', 'San', 'José'), (20, 26)),\n",
       " (('Chile',), (27, 27)),\n",
       " (('PP',), (0, 0)),\n",
       " (('Vicente',), (56, 56)),\n",
       " (('Gallego',), (9, 9)),\n",
       " (('OEA',), (17, 17)),\n",
       " (('ELN',), (38, 38)),\n",
       " (('Brasil',), (54, 54)),\n",
       " (('GOBIERNO',), (5, 5)),\n",
       " (('Javier', 'Irureta'), (42, 43)),\n",
       " (('Castillo',), (18, 18)),\n",
       " (('Córdoba',), (16, 16)),\n",
       " (('Bracamonte',), (9, 9)),\n",
       " (('Consejo', 'Europeo'), (16, 17)),\n",
       " (('France', 'Telecom'), (26, 27)),\n",
       " (('Bustamante',), (0, 0)),\n",
       " (('Ley', 'sobre', 'Derechos.', 'Cultura', 'Indígena'), (9, 13)),\n",
       " (('Cannavaro',), (12, 12)),\n",
       " (('Aznar',), (0, 0)),\n",
       " (('Barrena',), (27, 27)),\n",
       " (('Corte',), (3, 3)),\n",
       " (('Arce',), (87, 87)),\n",
       " (('Ejecutivo',), (13, 13)),\n",
       " (('Venezuela',), (72, 72)),\n",
       " (('Carlos', 'Ruiz', 'Sacristán'), (22, 24)),\n",
       " (('Bogotá',), (0, 0)),\n",
       " (('\"', 'Fomento', 'de', 'Emprendedores'), (3, 6)),\n",
       " (('Aquel',), (0, 0)),\n",
       " (('Salamanca',), (10, 10)),\n",
       " (('Marín',), (46, 46)),\n",
       " (('Consejo', 'Electoral'), (30, 31)),\n",
       " (('León',), (7, 7)),\n",
       " (('Comisión', 'Europea'), (1, 2)),\n",
       " (('Ciudad', 'Condal'), (8, 9)),\n",
       " (('Portugal',), (24, 24)),\n",
       " (('Panamá',), (0, 0)),\n",
       " (('Jordi', 'Pujol'), (6, 7)),\n",
       " (('Asociación', 'de', 'Corresponsales', 'de', 'Prensa', 'Extranjera'),\n",
       "  (6, 11)),\n",
       " (('Barcelona',), (17, 17)),\n",
       " (('Valencia',), (42, 42)),\n",
       " (('PP', 'O', 'GIL', 'Casares'), (12, 15)),\n",
       " (('Jurado', 'Nacional', 'de', 'Elecciones'), (10, 13)),\n",
       " (('Lockart',), (35, 35)),\n",
       " (('Coso', 'de', 'los', 'Califas'), (2, 5)),\n",
       " (('Vitor', 'Manuel', 'Melo', 'Pereira'), (2, 5)),\n",
       " (('Minas', 'Gerais'), (10, 11)),\n",
       " (('Cuba',), (10, 10)),\n",
       " (('Sevilla',), (10, 10)),\n",
       " (('Telesp', 'Celular'), (27, 28)),\n",
       " (('EFE',), (46, 46)),\n",
       " (('José', 'María', 'Aznar'), (85, 87)),\n",
       " (('Hong', 'Kong'), (38, 39)),\n",
       " (('Javier', 'Castaño'), (9, 10)),\n",
       " (('Jon', 'Jauregi'), (9, 10)),\n",
       " (('Maríaa', 'del', 'Mar', 'Bonet'), (39, 42)),\n",
       " (('Jean-Marc', 'Chanelet'), (9, 10)),\n",
       " (('Conselleria', 'de', 'Educación.', 'Cultura'), (11, 14)),\n",
       " (('Vallejo',), (0, 0)),\n",
       " (('Líbano',), (34, 34)),\n",
       " (('Simian', 'Films'), (7, 8)),\n",
       " (('La', 'Coruña'), (0, 1)),\n",
       " (('Castellón',), (41, 41)),\n",
       " (('Joan', 'Mesquida'), (12, 13)),\n",
       " (('Federación', 'Nacional', 'de', 'Cafeteros', 'de', 'Colombia'), (30, 35)),\n",
       " (('Savage',), (23, 23)),\n",
       " (('Garay',), (13, 13)),\n",
       " (('Asia',), (19, 19)),\n",
       " (('UEFA',), (6, 6)),\n",
       " (('FMI',), (9, 9)),\n",
       " (('Ejército',), (18, 18)),\n",
       " (('BARCELO', 'DICE', 'QUE', 'EL', 'COBRO', 'EN', 'HOTELES'), (3, 9)),\n",
       " (('Peter', 'Boehm'), (7, 8)),\n",
       " (('Juan', 'Santamaría'), (18, 19)),\n",
       " (('México',), (21, 21)),\n",
       " (('Provincia', 'Eclesiástica', 'de', 'Extremadura'), (30, 33)),\n",
       " (('Mainer',), (23, 23)),\n",
       " (('Contraloría', 'General', 'de', 'la', 'República'), (15, 19)),\n",
       " (('Inter',), (14, 14)),\n",
       " (('Túnez',), (31, 31)),\n",
       " (('De', 'la', 'Serna'), (0, 2)),\n",
       " (('CARRILLO',), (5, 5)),\n",
       " (('EFE',), (19, 19)),\n",
       " (('Ortuondo',), (7, 7)),\n",
       " (('Alfredo', 'Kraus'), (12, 13)),\n",
       " (('Jones',), (2, 2)),\n",
       " (('Aznar',), (26, 26)),\n",
       " (('Roberto', 'Baggio'), (2, 3)),\n",
       " (('Marcello', 'Lippi'), (48, 49)),\n",
       " (('PAR',), (9, 9)),\n",
       " (('República', 'Cooperativa', 'de', 'Guayana'), (25, 28)),\n",
       " (('Sergio', 'Arellano', 'Stark'), (9, 11)),\n",
       " (('RUM',), (3, 3)),\n",
       " (('Supercopas', 'de', 'Europa'), (40, 42)),\n",
       " (('Antonio', 'de', 'la', 'Rosa'), (49, 52)),\n",
       " (('Casa', 'Blanca'), (34, 35)),\n",
       " (('Roma',), (2, 2)),\n",
       " (('AENA',), (22, 22)),\n",
       " (('Vanoli',), (31, 31)),\n",
       " (('Primera',), (10, 10)),\n",
       " (('Comisión',\n",
       "   'Nacional',\n",
       "   'contra',\n",
       "   'la',\n",
       "   'Violencia',\n",
       "   'en',\n",
       "   'los',\n",
       "   'Espectáculos',\n",
       "   'Deportivos'),\n",
       "  (1, 9)),\n",
       " (('Hércules',), (39, 39)),\n",
       " (('OTAN',), (19, 19)),\n",
       " (('Bolaño',), (14, 14)),\n",
       " (('RCP',), (22, 22)),\n",
       " (('Franca',), (27, 27)),\n",
       " (('Murguía',), (32, 32)),\n",
       " (('Portugal',), (46, 46)),\n",
       " (('Bayern', 'Múnich'), (25, 26)),\n",
       " (('Bolivia',), (1, 1)),\n",
       " (('IBARRA',), (0, 0)),\n",
       " (('Alfonso', 'Guerra'), (47, 48)),\n",
       " (('Partido', 'de', 'la', 'Revolución', 'Democrática'), (15, 19)),\n",
       " (('Jugovic',), (20, 20)),\n",
       " (('San', 'José'), (0, 1)),\n",
       " (('Govern',), (4, 4)),\n",
       " (('Pastrana',), (17, 17)),\n",
       " (('Simian', 'Films'), (23, 24)),\n",
       " (('Chile',), (12, 12)),\n",
       " (('BARCELONA',), (19, 19)),\n",
       " (('Rodolpho', 'Tourinho'), (21, 22)),\n",
       " (('Aquiles', 'Machado'), (25, 26)),\n",
       " (('Soria',), (2, 2)),\n",
       " (('José', 'Aníbal', 'Peres', 'de', 'Pontes'), (50, 54)),\n",
       " (('Managua',), (24, 24)),\n",
       " (('EA',), (13, 13)),\n",
       " (('Viana', 'Baptista'), (1, 2)),\n",
       " (('Gobierno',), (17, 17)),\n",
       " (('Nasdaq',), (32, 32)),\n",
       " (('Kouchner',), (35, 35)),\n",
       " (('Albania',), (27, 27)),\n",
       " (('Toledo',), (19, 19)),\n",
       " (('Wall', 'Street'), (42, 43)),\n",
       " (('Tarcisio', 'Delgado'), (17, 18)),\n",
       " (('COI',), (40, 40)),\n",
       " (('Caracas',), (15, 15)),\n",
       " (('II', 'Congreso', 'Español', 'de', 'Metrología'), (6, 10)),\n",
       " (('Andrei', 'Pavel'), (0, 1)),\n",
       " (('Martínez',), (49, 49)),\n",
       " (('BNP',), (17, 17)),\n",
       " (('Elián',), (8, 8)),\n",
       " (('UPC',), (26, 26)),\n",
       " (('López', 'de', 'Arriortúa'), (8, 10)),\n",
       " (('Roland', 'Garros'), (10, 11)),\n",
       " (('Unión', 'Europea'), (26, 27)),\n",
       " (('Líbano',), (29, 29)),\n",
       " (('Baggio',), (12, 12)),\n",
       " (('Liga', 'ACB'), (12, 13)),\n",
       " (('colegio', 'San', 'Juan', 'Bosco'), (12, 15)),\n",
       " (('Chiquiquirá',), (49, 49)),\n",
       " (('Real', 'Madrid', '67', 'Real', 'Madrid'), (35, 39)),\n",
       " (('UE',), (23, 23)),\n",
       " (('Josemi',), (15, 15)),\n",
       " (('Supercopa', 'de', 'España'), (64, 66)),\n",
       " (('Banco', 'Central', 'Europeo'), (14, 16)),\n",
       " (('Relaciones',\n",
       "   'Económicas',\n",
       "   'Internacionales',\n",
       "   'de',\n",
       "   'la',\n",
       "   'Cancillería',\n",
       "   'panameña'),\n",
       "  (3, 9)),\n",
       " (('Parma',), (10, 10)),\n",
       " (('Lucy', 'Medina'), (38, 39)),\n",
       " (('Guaraníes',), (101, 101)),\n",
       " (('Magdalena',), (20, 20)),\n",
       " (('Londres',), (57, 57)),\n",
       " (('PP',), (17, 17)),\n",
       " (('Denis',), (5, 5)),\n",
       " (('Perú',), (72, 72)),\n",
       " (('Presidencia', 'de', 'México'), (6, 8)),\n",
       " (('Gareth', 'Roberts'), (6, 7)),\n",
       " (('Grecia',), (19, 19)),\n",
       " (('O', 'Globo'), (40, 41)),\n",
       " (('Nueva', 'York'), (23, 24)),\n",
       " (('Xabier', 'Markiegi'), (3, 4)),\n",
       " (('EFE',), (14, 14)),\n",
       " (('Liga', 'de', 'los', 'Pirineos'), (73, 76)),\n",
       " (('Caracas',), (9, 9)),\n",
       " (('Víctor', 'de', 'la', 'Serna'), (16, 19)),\n",
       " (('PSOE',), (0, 0)),\n",
       " (('Angel', 'Vicioso'), (18, 19)),\n",
       " (('Los', 'Tecos', 'mexicano'), (70, 72)),\n",
       " (('Pérez',), (17, 17)),\n",
       " (('FC',), (60, 60)),\n",
       " (('Linda', 'Woods'), (30, 31)),\n",
       " (('Euskadiko', 'Ezkerra', 'Kepa', 'Aulestia'), (36, 39)),\n",
       " (('TAU', 'Vitoria'), (2, 3)),\n",
       " (('Dida',), (6, 6)),\n",
       " (('Corte',), (4, 4)),\n",
       " (('CDC',), (24, 24)),\n",
       " (('Corte', 'de', 'Apelaciones', 'de', 'Santiago'), (1, 5)),\n",
       " (('Camacho',), (10, 10)),\n",
       " (('Alcorcón',), (0, 0)),\n",
       " (('Consell', 'de', 'Menorca'), (3, 5)),\n",
       " (('Londres',), (30, 30)),\n",
       " (('Canadá',), (5, 5)),\n",
       " (('Gales',), (4, 4)),\n",
       " (('Bolsa', 'de', 'Buenos', 'Aires'), (15, 18)),\n",
       " (('Betis', 'Denilson'), (43, 44)),\n",
       " (('Argentina',), (26, 26)),\n",
       " (('ETA',), (1, 1)),\n",
       " (('Transparencia',), (27, 27)),\n",
       " (('Estatuto', 'de', 'Autonomía'), (44, 46)),\n",
       " (('EFE', 'Baleares'), (0, 1)),\n",
       " (('Obelisco',), (30, 30)),\n",
       " (('Terra', 'Mítica'), (31, 32)),\n",
       " (('Isaías', 'Pérez', 'Saldaña'), (20, 22)),\n",
       " (('Gonzalo', 'Martínez'), (5, 6)),\n",
       " (('Copa', 'Asobal'), (0, 1)),\n",
       " (('Buffon',), (31, 31)),\n",
       " (('Rivaldo',), (15, 15)),\n",
       " (('Mérida',), (0, 0)),\n",
       " (('Hugo', 'Chávez'), (13, 14)),\n",
       " (('Pakistán',), (46, 46)),\n",
       " (('Servicio', 'de', 'Emergencia', 'de', 'la', 'Comunidad'), (23, 28)),\n",
       " (('Red', 'Sismológica', 'Nacional'), (38, 40)),\n",
       " (('Québec',), (68, 68)),\n",
       " (('Pinochet',), (7, 7)),\n",
       " (('Israel', 'Zuñiga'), (75, 76)),\n",
       " (('Cardiff',), (15, 15)),\n",
       " (('La', 'Magdalena'), (38, 39)),\n",
       " (('Miami',), (3, 3)),\n",
       " (('Parlamento',), (17, 17)),\n",
       " (('México',), (38, 38)),\n",
       " (('Delegación', 'de', 'la', 'Agencia', 'Efe'), (1, 5)),\n",
       " (('De', 'la', 'Calle'), (0, 2)),\n",
       " (('Agencia', 'Efe'), (11, 12)),\n",
       " (('Teófila', 'Martínez'), (6, 7)),\n",
       " (('Armando', 'Manzanero'), (21, 22)),\n",
       " (('Universidad', 'de', 'Pensilvania'), (15, 17)),\n",
       " (('FNC',), (46, 46)),\n",
       " (('Tailandia',), (61, 61)),\n",
       " (('Toledo',), (20, 20)),\n",
       " (('Nasdaq',), (17, 17)),\n",
       " (('CNE',), (25, 25)),\n",
       " (('España',), (10, 10)),\n",
       " (('Federico', 'Browne'), (0, 1)),\n",
       " (('BNP-Paribas',), (2, 2)),\n",
       " (('España',), (35, 35)),\n",
       " (('Siria',), (41, 41)),\n",
       " (('Sagem',), (17, 17)),\n",
       " (('ANTONIO', 'MONTERO'), (1, 2)),\n",
       " (('FC', 'BARCELONA', 'TEKA', 'SANTANDER'), (60, 63)),\n",
       " (('Brasil',), (8, 8)),\n",
       " (('Mireya', 'Moscoso'), (11, 12)),\n",
       " (('Miami',), (46, 46)),\n",
       " (('Bohdan', 'Ulihrach'), (0, 1)),\n",
       " (('Caracas',), (25, 25)),\n",
       " (('Batistuta',), (14, 14)),\n",
       " (('Estado',), (34, 34)),\n",
       " (('Luis', 'López'), (30, 31)),\n",
       " (('EZLN',), (33, 33)),\n",
       " (('CONGRESO',), (2, 2)),\n",
       " (('Nariño',), (26, 26)),\n",
       " (('Marcos',), (19, 19)),\n",
       " (('Argentina',), (48, 48)),\n",
       " (('Tribunal', 'Supremo', 'de', 'Justicia'), (34, 37)),\n",
       " (('The', 'American', 'Tobacco', 'Company'), (16, 19)),\n",
       " (('Teixeira',), (1, 1)),\n",
       " (('CREEN',\n",
       "   'IMPUESTO',\n",
       "   'TURISTICO',\n",
       "   'ES',\n",
       "   '\"',\n",
       "   'INJUSTO',\n",
       "   'Y',\n",
       "   'DISCRIMINATORIO'),\n",
       "  (1, 8)),\n",
       " (('Asamblea', 'de', 'Extremadura'), (34, 36)),\n",
       " (('Nueva', 'York'), (18, 19)),\n",
       " (('R..', 'Reynolds', 'Tobacco', 'Company'), (7, 10)),\n",
       " (('Alex', 'López', 'Morón'), (6, 8)),\n",
       " (('Moca',), (6, 6)),\n",
       " (('Bruselas',), (22, 22)),\n",
       " (('Jason',), (24, 24)),\n",
       " (('Tommy', 'Robredo'), (0, 1)),\n",
       " (('Kaduna',), (22, 22)),\n",
       " (('Gales',), (9, 9)),\n",
       " (('Ballesteros',), (27, 27)),\n",
       " (('Cáceres',), (6, 6)),\n",
       " (('Offenbach',), (35, 35)),\n",
       " (('Asociación', 'de', 'Guías', 'Turísticas', 'de', 'Cantabria'), (25, 30)),\n",
       " (('Salud',), (3, 3)),\n",
       " (('RELIGIOSA', 'Lagos'), (10, 11)),\n",
       " (('José', 'del', 'Solar'), (15, 17)),\n",
       " (('Conselleria', 'de', 'Interior', 'del', 'Govern'), (28, 32)),\n",
       " (('Aldair',), (16, 16)),\n",
       " (('Miami',), (44, 44)),\n",
       " (('Juan', 'Carlos', 'Rodríguez', 'Ibarra'), (37, 40)),\n",
       " (('Interior',), (3, 3)),\n",
       " (('Patrick', 'Muller'), (38, 39)),\n",
       " (('Jean', 'Bertrand', 'Aristide'), (19, 21)),\n",
       " (('Junta',), (7, 7)),\n",
       " (('Arias',), (8, 8)),\n",
       " (('Estudiantes',), (5, 5)),\n",
       " (('Pinochet',), (29, 29)),\n",
       " (('Vieri',), (38, 38)),\n",
       " (('EFECOM',), (8, 8)),\n",
       " (('Madrid',), (25, 25)),\n",
       " (('Alcatel',), (15, 15)),\n",
       " (('EEUU',), (48, 48)),\n",
       " (('Liz',), (4, 4)),\n",
       " (('Pamplona',), (0, 0)),\n",
       " (('OCM',), (49, 49)),\n",
       " (('CECEI',), (48, 48)),\n",
       " (('Nasdaq',), (43, 43)),\n",
       " (('EL', 'GOVERN', 'TIENE', 'PREVISTO', 'APROBAR', 'PLAN', 'ENERGETICO'),\n",
       "  (3, 9)),\n",
       " (('Hughes',), (3, 3)),\n",
       " (('Cámara',), (42, 42)),\n",
       " (('OEA',), (12, 12)),\n",
       " (('VEN',), (3, 3)),\n",
       " (('Extreme', 'mesures'), (31, 32)),\n",
       " (('Efe',), (17, 17)),\n",
       " (('Presidencia', 'de', 'México', 'Cuauhtémoc', 'Cárdenas'), (4, 8)),\n",
       " (('Murcia',), (41, 41)),\n",
       " (('Nueva', 'York'), (13, 14)),\n",
       " (('Jurado', 'Nacional', 'de', 'Elecciones'), (12, 15)),\n",
       " (('K-2',), (4, 4)),\n",
       " (('Bancomer',), (21, 21)),\n",
       " (('Sergi', 'Bruguera'), (6, 7)),\n",
       " (('Hugo', 'Chávez'), (8, 9)),\n",
       " (('Comercio',), (4, 4)),\n",
       " (('Centroamérica',), (46, 46)),\n",
       " (('Fuerzas', 'Armadas', 'del', 'Líbano'), (5, 8)),\n",
       " (('Bonoloto',), (26, 26)),\n",
       " (('RSN',), (19, 19)),\n",
       " (('Economía',), (13, 13)),\n",
       " (('Petróleo', 'Intermedio', 'de', 'Texas'), (9, 12)),\n",
       " (('Evangelista', 'Mora'), (7, 8)),\n",
       " (('Extremadura',), (24, 24)),\n",
       " (('Desarrollo', 'Económico'), (3, 4)),\n",
       " (('Joe', 'Lockhart'), (37, 38)),\n",
       " (('Manuel', 'Chaves'), (17, 18)),\n",
       " (('Ecija',), (10, 10)),\n",
       " (('Facultad', 'de', 'Ciencias', 'Económicas.', 'Empresariales'), (24, 28)),\n",
       " (('Augusto', 'Centena', 'Hermanos'), (68, 70)),\n",
       " (('Ejército',), (15, 15)),\n",
       " (('Consejo', 'General', 'del', 'Poder', 'Judicial'), (9, 13)),\n",
       " (('JNE',), (17, 17)),\n",
       " (('EEUU',), (17, 17)),\n",
       " (('Galarza',), (19, 19)),\n",
       " (('Miguel',), (34, 34)),\n",
       " (('Olaya',), (19, 19)),\n",
       " (('EEUU',), (42, 42)),\n",
       " (('Televisa',), (4, 4)),\n",
       " (('PM2011',), (1, 1)),\n",
       " (('Guatemala',), (74, 74)),\n",
       " (('AGORA',), (15, 15)),\n",
       " (('Menem',), (0, 0)),\n",
       " (('Unión', 'Europea'), (32, 33)),\n",
       " (('IND',), (44, 44)),\n",
       " (('Roger', 'Serrano'), (61, 62)),\n",
       " (('Grupo', 'Banamex', 'Accival'), (29, 31)),\n",
       " (('Christian', 'Vieri'), (6, 7)),\n",
       " (('Instituto', 'Nicaragüense', 'de', 'Estudios', 'Territoriales'), (11, 15)),\n",
       " (('Brasil',), (3, 3)),\n",
       " (('Ministerio', 'de', 'Infraestructura'), (2, 4)),\n",
       " (('Panaria',), (23, 23)),\n",
       " (('FALLECE', 'EN', 'SEVILLA', 'EL', 'FOTOGRAFO', 'TAURINO', 'PEPE', 'ARJONA'),\n",
       "  (14, 21)),\n",
       " (('Miami',), (66, 66)),\n",
       " (('Paraguay',), (10, 10)),\n",
       " (('Pedro', 'de', 'Mendoza'), (29, 31)),\n",
       " (('Nueva', 'Guinea'), (52, 53)),\n",
       " (('R.', 'Baggio'), (9, 10)),\n",
       " (('Las', 'Américas'), (12, 13)),\n",
       " (('Kily\"', 'González'), (17, 18)),\n",
       " (('San', 'Juan'), (0, 1)),\n",
       " (('Bomberos', 'de', 'la', 'Comunidad'), (30, 33)),\n",
       " (('Logroñés',), (48, 48)),\n",
       " (('Pakistán',), (4, 4)),\n",
       " (('Dida',), (13, 13)),\n",
       " (('Asociación', 'de', 'Países', 'Productores', 'de', 'Café'), (8, 13)),\n",
       " (('OEA',), (34, 34)),\n",
       " (('Diego', 'Manzanero'), (15, 16)),\n",
       " (('Jorge', 'Soto'), (38, 39)),\n",
       " (('Parlamento', 'Andino'), (27, 28)),\n",
       " (('ESP',), (10, 10)),\n",
       " (('Guillermo', 'Moreno'), (3, 4)),\n",
       " (('TAU', 'Vitoria'), (8, 9)),\n",
       " (('FC', 'Barcelona'), (24, 25)),\n",
       " (('Enrique', 'Olivera'), (13, 14)),\n",
       " (('Bolivia',), (28, 28)),\n",
       " (('Santini',), (0, 0)),\n",
       " (('II',\n",
       "   'Reunión',\n",
       "   'de',\n",
       "   'Coordinación.',\n",
       "   'Responsables',\n",
       "   'de',\n",
       "   'Cooperación'),\n",
       "  (34, 40)),\n",
       " (('ONG',), (1, 1)),\n",
       " (('Consejo', 'Nacional', 'del', 'Partido', 'Justicialista'), (11, 15)),\n",
       " (('CONFIEP',), (4, 4)),\n",
       " (('Mérida',), (11, 11)),\n",
       " (('Martín', 'Bertrán'), (4, 5)),\n",
       " (('Puerta', 'Grande'), (46, 47)),\n",
       " (('Mark', 'Knowles'), (6, 7)),\n",
       " (('Sao', 'Paulo'), (41, 42)),\n",
       " (('Fiscalía',), (43, 43)),\n",
       " (('Matos',), (21, 21)),\n",
       " (('Cáceres',), (16, 16)),\n",
       " (('ELN',), (3, 3)),\n",
       " (('Comité', 'de', 'Entidades', 'de', 'Crédito.', 'Inversiones'), (41, 46)),\n",
       " (('Liga', 'ACB'), (34, 35)),\n",
       " (('Brasil',), (19, 19)),\n",
       " (('Andalucía',), (6, 6)),\n",
       " (('Metrología,', 'Ciencia.', 'Innovación', 'para', 'la', 'Empresa'), (8, 13)),\n",
       " (('BBVA',), (39, 39)),\n",
       " (('SIERRA', 'LEONA', 'GOLPE', 'AUTORIDADES'), (0, 3)),\n",
       " (('Colombia',), (14, 14)),\n",
       " (('Tribunal', 'de', 'la', 'Competencia'), (29, 32)),\n",
       " (('Telefónica',), (0, 0)),\n",
       " (('Cumbre',), (20, 20)),\n",
       " (('Lucha',), (12, 12)),\n",
       " (('Madeleine', 'Albright'), (36, 37)),\n",
       " (('Cuba',), (42, 42)),\n",
       " (('Sebastian', 'Prieto'), (0, 1)),\n",
       " (('OPA',), (16, 16)),\n",
       " (('NBC',), (6, 6)),\n",
       " (('Estados', 'Unidos'), (41, 42)),\n",
       " (('Juan', 'Ortuño'), (27, 28)),\n",
       " (('Betancor',), (2, 2)),\n",
       " (('Puñal',), (25, 25)),\n",
       " (('Lionel', 'Roux'), (0, 1)),\n",
       " (('NOBEL', 'ECONOMIA'), (1, 2)),\n",
       " (('EFECOM',), (46, 46)),\n",
       " (('VI', 'Feria', 'de', 'la', 'Alfarería.', 'el', 'Barro'), (12, 18)),\n",
       " (('Reino', 'Unido'), (2, 3)),\n",
       " (('Ejecutivo',), (3, 3)),\n",
       " (('Contreras',), (4, 4)),\n",
       " (('Pernando', 'Barrena'), (36, 37)),\n",
       " (('Scott',), (24, 24)),\n",
       " (('Alfredo', 'Kraus'), (29, 30)),\n",
       " (('Celestí', 'Alomar'), (5, 6)),\n",
       " (('Extremadura',), (19, 19)),\n",
       " (('JIAM',), (10, 10)),\n",
       " (('Harry', 'Rosario'), (6, 7)),\n",
       " (('Salomon', 'Smith', 'Barney'), (41, 43)),\n",
       " (('Palacio',), (13, 13)),\n",
       " (('At.', 'Madrid'), (20, 21)),\n",
       " (('Iván', 'Luis', 'Zamorano'), (6, 8)),\n",
       " (('Barcelona',), (7, 7)),\n",
       " (('Cortes',), (20, 20)),\n",
       " (('Toni', 'Velamazán'), (26, 27)),\n",
       " (('Banco', 'Central', 'de', 'Rusia'), (36, 39)),\n",
       " (('Alvaro', 'Vega'), (33, 34)),\n",
       " (('Centro', 'Pasarela', 'Show'), (11, 13)),\n",
       " (('Wembley',), (65, 65)),\n",
       " (('Antonio', 'Chenel'), (28, 29)),\n",
       " (('Leopoldo', 'Torrado'), (37, 38)),\n",
       " (('Jurado',), (19, 19)),\n",
       " (('Dow', 'Jones'), (43, 44)),\n",
       " (('Lockhart',), (0, 0)),\n",
       " (('Puerto', 'Suárez'), (34, 35)),\n",
       " (('Caquetá',), (28, 28)),\n",
       " (('Junta', 'de', 'Andalucía'), (27, 29)),\n",
       " (('NO', 'ES', 'LA', 'FORMULA', 'IDEAL'), (11, 15)),\n",
       " (('PRD',), (3, 3)),\n",
       " (('Copa', 'del', 'Rey'), (54, 56)),\n",
       " (('Santa', 'Fe'), (8, 9)),\n",
       " (('OEA',), (23, 23)),\n",
       " (('Américas',), (15, 15)),\n",
       " (('Miño',), (25, 25)),\n",
       " (('Albright',), (5, 5)),\n",
       " (('Cáceres',), (13, 13)),\n",
       " (('Buda',), (52, 52)),\n",
       " (('Guatemala',), (58, 58)),\n",
       " (('Urdangarin',), (53, 53)),\n",
       " (('Santander',), (0, 0)),\n",
       " (('\"', 'caso', 'Elián'), (45, 47)),\n",
       " (('Juegos',), (37, 37)),\n",
       " (('OEA',), (29, 29)),\n",
       " (('Miss', 'Brasil', 'Gay'), (24, 26)),\n",
       " (('Franca',), (24, 24)),\n",
       " (('Córdoba',), (3, 3)),\n",
       " (('Chávez',), (0, 0)),\n",
       " (('Montero',), (33, 33)),\n",
       " (('Curro', 'Romero'), (34, 35)),\n",
       " (('Deportivo',), (28, 28)),\n",
       " (('Perú',), (47, 47)),\n",
       " (('BEL',), (4, 4)),\n",
       " (('France', 'Telecom'), (28, 29)),\n",
       " (('Maia',), (17, 17)),\n",
       " (('Río',), (28, 28)),\n",
       " (('Oscar', 'Burrieza'), (6, 7)),\n",
       " (('AENA',), (2, 2)),\n",
       " (('Juegos', 'Panamericanos'), (8, 9)),\n",
       " (('XIV', 'Juegos', 'Panamericanos'), (9, 11)),\n",
       " (('Compañía', 'Riograndense', 'de', 'Telecomunicaciones'), (48, 51)),\n",
       " (('Alemania',), (18, 18)),\n",
       " (('Diego', 'Manzanero'), (0, 1)),\n",
       " (('BANACCI',), (21, 21)),\n",
       " (('Alberto', 'Martín'), (55, 56)),\n",
       " (('Asuntos', 'Sociales'), (17, 18)),\n",
       " (('JUNTA',), (13, 13)),\n",
       " (('Brown',), (25, 25)),\n",
       " (('Rivera',), (4, 4)),\n",
       " (('Gobierno',), (34, 34)),\n",
       " (('ESES&S',), (31, 31)),\n",
       " (('Horst', 'Koehler'), (12, 13)),\n",
       " (('París',), (29, 29)),\n",
       " (('Grupo', 'Popular'), (11, 12)),\n",
       " (('Díez', 'Canseco'), (0, 1)),\n",
       " (('Banco', 'Central'), (27, 28)),\n",
       " (('ECOTASA',), (2, 2)),\n",
       " (('Marx',), (0, 0)),\n",
       " (('Jeff', 'Tarango'), (19, 20)),\n",
       " (('Grupo', 'Catalán'), (14, 15)),\n",
       " (('OPEP',), (6, 6)),\n",
       " (('IU',), (3, 3)),\n",
       " (('Real', 'Federación', 'Española', 'de', 'Atletismo'), (10, 14)),\n",
       " (('Convergencia',), (34, 34)),\n",
       " (('Manza', 'Music'), (11, 12)),\n",
       " (('Lázaro', 'González'), (39, 40)),\n",
       " (('Scariolo',), (9, 9)),\n",
       " (('Congreso',), (5, 5)),\n",
       " (('Osvaldo', 'Braga'), (28, 29)),\n",
       " (('Asturias',), (6, 6)),\n",
       " (('Gobierno', 'de', 'Georgetown'), (52, 54)),\n",
       " (('Jean-Michel', 'Aulas'), (6, 7)),\n",
       " (('Campus', 'de', 'Verano'), (11, 13)),\n",
       " (('Domoraud',), (14, 14)),\n",
       " (('Paul', 'Denis'), (0, 1)),\n",
       " (('Badajoz',), (8, 8)),\n",
       " (('Gobierno',), (7, 7)),\n",
       " (('España',), (37, 37)),\n",
       " (('Departamento', 'de', 'Salud'), (15, 17)),\n",
       " (('Sebastián', 'Castella'), (6, 7)),\n",
       " (('SV2188',), (1, 1)),\n",
       " (('Carmen', 'Hermosín'), (12, 13)),\n",
       " (('Fundación', 'Española', 'del', 'Corazón'), (4, 7)),\n",
       " (('Mérida', 'CP'), (4, 5)),\n",
       " (('Barcelona',), (2, 2)),\n",
       " (('Gobierno', 'de', 'Estados', 'Unidos'), (16, 19)),\n",
       " (('México',), (8, 8)),\n",
       " (('Alfonso', 'Reyes'), (2, 3)),\n",
       " (('Mundial', 'del', '2002'), (25, 27)),\n",
       " (('Jim', 'Johnson'), (0, 1)),\n",
       " (('\"', 'Buda'), (9, 10)),\n",
       " (('Sao', 'Paulo'), (14, 15)),\n",
       " (('Serbia',), (17, 17)),\n",
       " (('Cantabria',), (29, 29)),\n",
       " (('Adecco', 'Estudiantes'), (42, 43)),\n",
       " (('Sergipe',), (18, 18)),\n",
       " (('Suramericano',), (1, 1)),\n",
       " (('Castaño',), (16, 16)),\n",
       " (('Divine', 'Brown'), (29, 30)),\n",
       " (('Perú', '2000'), (20, 21)),\n",
       " (('Bogotá',), (28, 28)),\n",
       " (('Rebeldes', 'de', 'Moca'), (5, 7)),\n",
       " (('Fiesta', 'por', 'la', 'Paz'), (6, 9)),\n",
       " (('Milwaukee',), (21, 21)),\n",
       " (('Copa', 'de', 'la', 'UEFA'), (34, 37)),\n",
       " (('Policía', 'serbia'), (40, 41)),\n",
       " (('Santiago', 'Jaramillo'), (13, 14)),\n",
       " (('ABC',), (22, 22)),\n",
       " (('Agencia', 'Nacional', 'de', 'Telecomunicaciones'), (37, 40)),\n",
       " (('Copas', 'del', 'Rey'), (50, 52)),\n",
       " (('Pere', 'Duran', 'Farell'), (54, 56)),\n",
       " (('K-2',), (5, 5)),\n",
       " (('Pasto',), (17, 17)),\n",
       " (('OEA',), (18, 18)),\n",
       " (('Comisión', 'Metrosur'), (3, 4)),\n",
       " (('Américas',), (10, 10)),\n",
       " (('Casqueiro',), (35, 35)),\n",
       " (('Federación', 'de', 'Municipios.', 'Provincias', 'de', 'Extremadura'),\n",
       "  (1, 6)),\n",
       " (('Breuer',), (2, 2)),\n",
       " (('Coventry',), (78, 78)),\n",
       " (('Convergencia',), (50, 50)),\n",
       " (('Rivaldo',), (32, 32)),\n",
       " (('Brasil',), (36, 36)),\n",
       " (('Cantabria',), (2, 2)),\n",
       " (('Ayuntamiento', 'de', 'Casares'), (3, 5)),\n",
       " (('Juan', 'Carlos', 'Galaverna'), (35, 37)),\n",
       " (('ARG',), (3, 3)),\n",
       " (('Bayamón',), (12, 12)),\n",
       " (('Comité', 'Ejecutivo'), (22, 23)),\n",
       " (('EFE',), (0, 0)),\n",
       " (('Hugh', 'Grant'), (3, 4)),\n",
       " (('Adecco', 'Estudiantes'), (21, 22)),\n",
       " (('Barcelona',), (18, 18)),\n",
       " (('Hugo', 'Chávez'), (4, 5)),\n",
       " (('Liga', 'de', 'los', 'Pirineos'), (59, 62)),\n",
       " (('Telebras',), (22, 22)),\n",
       " (('John', 'Maisto'), (11, 12)),\n",
       " (('PIDE', 'CHAVES', 'NO', 'USE', 'DOBLE', 'MORAL'), (4, 9)),\n",
       " (('TAU',), (53, 53)),\n",
       " (('PA',), (37, 37)),\n",
       " (('Pujol',), (56, 56)),\n",
       " (('Mario', 'Stanic'), (21, 22)),\n",
       " (('Alberto', 'Bustamante'), (5, 6)),\n",
       " ...}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entidades_extraidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(('CNE',), (27, 27)),\n",
       " (('Chandler', 'Thomson'), (30, 31)),\n",
       " (('CONGRESO',), (5, 5)),\n",
       " (('Adecco', 'Estudiantes'), (43, 44)),\n",
       " (('Mauro', 'Silva'), (34, 35)),\n",
       " (('MundoIT',), (1, 1)),\n",
       " (('Camacho', 'Solís'), (25, 26)),\n",
       " (('Fresi',), (42, 42)),\n",
       " (('Inter', 'de', 'Milán'), (6, 8)),\n",
       " (('Eugenio', 'Gay'), (15, 16)),\n",
       " (('América', 'Latina'), (24, 25)),\n",
       " (('Madrid',), (133, 133)),\n",
       " (('Badajoz', 'B'), (21, 22)),\n",
       " (('Desayuno', 'Cardiosaludable'), (0, 1)),\n",
       " (('ESES&S',), (16, 16)),\n",
       " (('Grupo', 'Izquierda', 'Unida'), (19, 21)),\n",
       " (('Clinton',), (17, 17)),\n",
       " (('Chávez',), (38, 38)),\n",
       " (('Hugo', 'de', 'la', 'Calle'), (28, 31)),\n",
       " (('EFE',), (22, 22)),\n",
       " (('Djordjevic',), (0, 0)),\n",
       " (('Europa',), (35, 35)),\n",
       " (('EFECOM',), (5, 5)),\n",
       " (('Perú', '2000'), (36, 37)),\n",
       " (('Nantes',), (13, 13)),\n",
       " (('Puerta', 'Grande'), (48, 49)),\n",
       " (('Sao', 'Paulo'), (43, 44)),\n",
       " (('Bolsa', 'de', 'Nueva', 'York'), (5, 8)),\n",
       " (('29',\n",
       "   'de',\n",
       "   'las',\n",
       "   'Fuerzas',\n",
       "   'Armadas',\n",
       "   'Revolucionarias',\n",
       "   'de',\n",
       "   'Colombia'),\n",
       "  (17, 24)),\n",
       " (('MERIDA-EXTREMADURA',), (2, 2)),\n",
       " (('\"', 'La', 'vida', 'es', 'silbar', '\"'), (25, 30)),\n",
       " (('Costa', 'Pacífica'), (18, 19)),\n",
       " (('Lupo',), (2, 2)),\n",
       " (('Zaplana',), (51, 51)),\n",
       " (('Sevilla',), (7, 7)),\n",
       " (('Agustin', 'Calleri'), (0, 1)),\n",
       " (('Boehm',), (0, 0)),\n",
       " (('Moca',), (24, 24)),\n",
       " (('Saunders',), (35, 35)),\n",
       " (('Franklin', 'Barrett'), (11, 12)),\n",
       " (('Junta', 'de', 'Extremadura'), (4, 6)),\n",
       " (('BBVA',), (9, 9)),\n",
       " (('UNISYS',), (15, 15)),\n",
       " (('Puebla',), (23, 23)),\n",
       " (('ASAJA',), (6, 6)),\n",
       " (('IU',), (10, 10)),\n",
       " (('Nueva', 'York'), (10, 11)),\n",
       " (('Pamplona',), (28, 28)),\n",
       " (('FC.', 'BARCELONA'), (110, 111)),\n",
       " (('Nicaragua',), (93, 93)),\n",
       " (('Ministerio', 'de', 'Agricultura,', 'Pesca.', 'Alimentación'), (13, 17)),\n",
       " (('Nobel', 'de', 'Economía'), (12, 14)),\n",
       " (('Donna', 'Shalala'), (12, 13)),\n",
       " (('BBV-Probursa',), (17, 17)),\n",
       " (('Marx',), (13, 13)),\n",
       " (('ARG',), (9, 9)),\n",
       " (('Pedro', 'Cañellas'), (9, 10)),\n",
       " (('Ejecutivo',), (5, 5)),\n",
       " (('Santillana', 'del', 'Mar'), (14, 16)),\n",
       " (('Elián',), (37, 37)),\n",
       " (('Museo', 'de', 'Prehistoria'), (11, 13)),\n",
       " (('Lucio', 'Angulo'), (38, 39)),\n",
       " (('Instituto', 'Nacional', 'Demócrata'), (40, 42)),\n",
       " (('Gobierno',), (14, 14)),\n",
       " (('Badajoz',), (15, 15)),\n",
       " (('\"', 'The', 'Web', 'Hatchery', '\"'), (2, 6)),\n",
       " (('Tailandia',), (16, 16)),\n",
       " (('Copa', 'de', 'Campeones'), (69, 71)),\n",
       " (('Moisés',), (66, 66)),\n",
       " (('EFE',), (16, 16)),\n",
       " (('Buenos', 'Aires'), (9, 10)),\n",
       " (('Juana', 'González', 'Linares'), (1, 3)),\n",
       " (('Eduardo', 'Nicolás'), (6, 7)),\n",
       " (('Feria', 'del', 'Libro'), (7, 9)),\n",
       " (('Departamento',\n",
       "   'de',\n",
       "   'Biología',\n",
       "   'Animal',\n",
       "   'de',\n",
       "   'la',\n",
       "   'Facultad',\n",
       "   'de',\n",
       "   'Ciencias',\n",
       "   'del',\n",
       "   'Mar',\n",
       "   'de',\n",
       "   'la',\n",
       "   'Universidad',\n",
       "   'de',\n",
       "   'Cádiz'),\n",
       "  (29, 44)),\n",
       " (('Gobierno',), (20, 20)),\n",
       " (('Valencia',), (15, 15)),\n",
       " (('Delarts',), (0, 0)),\n",
       " (('Barcelona',), (15, 15)),\n",
       " (('Conchi', 'Paredes'), (21, 22)),\n",
       " (('Bolsa', 'Mexicana', 'de', 'Valores'), (1, 4)),\n",
       " (('Telesp',), (22, 22)),\n",
       " (('ESES&S',), (13, 13)),\n",
       " (('Ledezma',), (0, 0)),\n",
       " (('Allen',), (21, 21)),\n",
       " (('Real', 'Madrid'), (24, 25)),\n",
       " (('SEVILLA',), (12, 12)),\n",
       " (('BCR',), (41, 41)),\n",
       " (('Sao', 'Paulo'), (12, 13)),\n",
       " (('Instituto', 'del', 'Tabaco'), (44, 46)),\n",
       " (('Michael', 'Sell'), (6, 7)),\n",
       " (('Freestone',), (4, 4)),\n",
       " (('Maryland',), (4, 4)),\n",
       " (('Ibovespa',), (1, 1)),\n",
       " (('Cáceres',), (40, 40)),\n",
       " (('Wall', 'Street'), (24, 25)),\n",
       " (('Bernard', 'Kouchner'), (19, 20)),\n",
       " (('Telefónica',), (49, 49)),\n",
       " (('Santillana', 'del', 'Mar'), (30, 32)),\n",
       " (('Phillip', 'Cocu'), (35, 36)),\n",
       " (('Departamento', 'de', 'Energía'), (33, 35)),\n",
       " (('Susan', 'Pierson', 'Brown'), (3, 5)),\n",
       " (('coliseo', 'Evangelista', 'Mora'), (6, 8)),\n",
       " (('Inter', 'de', 'Milán'), (1, 3)),\n",
       " (('Consejo',), (18, 18)),\n",
       " (('Guy', 'Roux'), (5, 6)),\n",
       " (('Andalucía',), (45, 45)),\n",
       " (('Partido', 'Revolucionario', 'Dominicano'), (12, 14)),\n",
       " (('Perú',), (55, 55)),\n",
       " (('Palma',), (11, 11)),\n",
       " (('Aceuchal',), (18, 18)),\n",
       " (('Bilbao',), (20, 20)),\n",
       " (('Sicilia',), (41, 41)),\n",
       " (('Juan', 'de', 'Garay'), (0, 2)),\n",
       " (('Caracas',), (12, 12)),\n",
       " (('San', 'Cristóbal'), (10, 11)),\n",
       " (('BAH',), (9, 9)),\n",
       " (('Partido', 'Andalucista'), (19, 20)),\n",
       " (('Gobierno',), (36, 36)),\n",
       " (('Benavides',), (0, 0)),\n",
       " (('Wireless', 'Application', 'Protocol'), (36, 38)),\n",
       " (('EFE',), (13, 13)),\n",
       " (('Batistuta',), (1, 1)),\n",
       " (('Gabriel', 'Omar', 'Batistuta'), (20, 22)),\n",
       " (('Arjona',), (21, 21)),\n",
       " (('EFE',), (38, 38)),\n",
       " (('Augusto', 'Pinochet'), (17, 18)),\n",
       " (('Chaves',), (51, 51)),\n",
       " (('Recreativo',), (26, 26)),\n",
       " (('España',), (12, 12)),\n",
       " (('Elián',), (58, 58)),\n",
       " (('Internet',), (9, 9)),\n",
       " (('Juan', 'Carlos', 'Doadrio'), (18, 20)),\n",
       " (('Brady',), (15, 15)),\n",
       " (('PM2044',), (1, 1)),\n",
       " (('ME2030',), (1, 1)),\n",
       " (('Batistuta',), (16, 16)),\n",
       " (('Doadrio',), (18, 18)),\n",
       " (('\"', 'Deutsche', 'Boerse', 'AG', '\"'), (15, 19)),\n",
       " (('GUADALUPE',), (8, 8)),\n",
       " (('Parlamento', 'Foral'), (10, 11)),\n",
       " (('PSN',), (11, 11)),\n",
       " (('Fiesole',), (19, 19)),\n",
       " (('AFS',), (9, 9)),\n",
       " (('Miguel', 'Miranda'), (32, 33)),\n",
       " (('Jorge', 'Escobar'), (45, 46)),\n",
       " (('UCK',), (31, 31)),\n",
       " (('Defensoría', 'del', 'Pueblo'), (4, 6)),\n",
       " (('Badajoz',), (10, 10)),\n",
       " (('Bob', 'Bryan'), (6, 7)),\n",
       " (('Cancún',), (0, 0)),\n",
       " (('Dida',), (4, 4)),\n",
       " (('Bustos',), (20, 20)),\n",
       " (('Simic',), (8, 8)),\n",
       " (('Lawrence', 'R.', 'Klein'), (0, 2)),\n",
       " (('México',), (10, 10)),\n",
       " (('Mérida',), (3, 3)),\n",
       " (('Parlamento',), (14, 14)),\n",
       " (('Giro', 'de', 'Italia'), (20, 22)),\n",
       " (('CZE',), (32, 32)),\n",
       " (('convento', 'de', 'las', 'Clarisas'), (3, 6)),\n",
       " (('Finanzas',), (3, 3)),\n",
       " (('Endesa',), (35, 35)),\n",
       " (('Tenerife',), (37, 37)),\n",
       " (('Menorca',), (15, 15)),\n",
       " (('Josep', 'Maldonado'), (6, 7)),\n",
       " (('Barcelona',), (10, 10)),\n",
       " (('Castaño',), (18, 18)),\n",
       " (('Breda',), (21, 21)),\n",
       " (('Jose', 'Acasuso'), (23, 24)),\n",
       " (('Cataluña',), (32, 32)),\n",
       " (('Lleida',), (55, 55)),\n",
       " (('Colombia',), (6, 6)),\n",
       " (('Germán', 'Puentes'), (0, 1)),\n",
       " (('PSOE',), (19, 19)),\n",
       " (('Estudiantes',), (7, 7)),\n",
       " (('Toledo',), (13, 13)),\n",
       " (('Geles',), (8, 8)),\n",
       " (('EFE',), (54, 54)),\n",
       " (('II',), (48, 48)),\n",
       " (('Bogotá',), (36, 36)),\n",
       " (('Jose',), (41, 41)),\n",
       " (('Caicedo',), (2, 2)),\n",
       " (('López', 'de', 'Arriortúa'), (6, 8)),\n",
       " (('Campeonato', 'Suramericano', 'Juvenil', 'Masculino'), (12, 15)),\n",
       " (('Alomar',), (13, 13)),\n",
       " (('BBVA',), (30, 30)),\n",
       " (('Mejía',), (0, 0)),\n",
       " (('Palacio', 'de', 'La', 'Merced'), (71, 74)),\n",
       " (('Gobierno',), (83, 83)),\n",
       " (('Gobierno', 'de', 'Sierra', 'Leona'), (3, 6)),\n",
       " (('Stanic',), (16, 16)),\n",
       " (('\"',\n",
       "   'XV',\n",
       "   'sesiones',\n",
       "   'sobre',\n",
       "   'acceso',\n",
       "   'de',\n",
       "   'las',\n",
       "   'personas',\n",
       "   'con',\n",
       "   'discapacidad',\n",
       "   'al',\n",
       "   'empleo',\n",
       "   'público'),\n",
       "  (11, 23)),\n",
       " (('Venezuela',), (129, 129)),\n",
       " (('Andoni', 'Goicoetxea'), (17, 18)),\n",
       " (('Francesc', 'Ricomé'), (14, 15)),\n",
       " (('Estudiantes',), (50, 50)),\n",
       " (('Hizbulá',), (21, 21)),\n",
       " (('Muestra', 'de', 'Arte', 'Electrónico'), (23, 26)),\n",
       " (('Comunicación', 'Social'), (3, 4)),\n",
       " (('BankWest',), (29, 29)),\n",
       " (('Copa', 'del', 'Mundo'), (7, 9)),\n",
       " (('La', 'Voz', 'de', 'Galicia'), (16, 19)),\n",
       " (('David', 'Albelda'), (27, 28)),\n",
       " (('CNE',), (7, 7)),\n",
       " (('Televisa',), (16, 16)),\n",
       " (('Gerard', 'Quintana'), (44, 45)),\n",
       " (('Leganés',), (27, 27)),\n",
       " (('Percy', 'Olivares'), (21, 22)),\n",
       " (('ecotasa',), (21, 21)),\n",
       " (('Betts',), (44, 44)),\n",
       " (('Aristide',), (6, 6)),\n",
       " (('Constitución',), (9, 9)),\n",
       " (('Mérida',), (19, 19)),\n",
       " (('Varela',), (99, 99)),\n",
       " (('Madrid',), (28, 28)),\n",
       " (('\"', 'Burger', 'King', '\"'), (25, 28)),\n",
       " (('Relaciones', 'Internacionales', 'de', 'la', 'Agencia', 'Efe'), (3, 8)),\n",
       " (('BARCELO',), (3, 3)),\n",
       " (('Universidad', 'de', 'las', 'Islas', 'Baleares'), (1, 5)),\n",
       " (('IPC',), (6, 6)),\n",
       " (('Tiago',), (35, 35)),\n",
       " (('Vigo',), (0, 0)),\n",
       " (('Cesar', 'Sampaio'), (25, 26)),\n",
       " (('Ejecutivo',), (37, 37)),\n",
       " (('Argentina',), (14, 14)),\n",
       " (('Sao', 'Paulo'), (23, 24)),\n",
       " (('Recreativo',), (17, 17)),\n",
       " (('EFE',), (55, 55)),\n",
       " (('Centroamérica',), (21, 21)),\n",
       " (('Pristina',), (0, 0)),\n",
       " (('Espanyol',), (8, 8)),\n",
       " (('F.', 'G.', 'M.'), (31, 33)),\n",
       " (('Londres',), (24, 24)),\n",
       " (('Josep', 'Lluís', 'Vilaseca'), (2, 4)),\n",
       " (('ESL',), (31, 31)),\n",
       " (('Wappup.com',), (0, 0)),\n",
       " (('Nasdaq',), (61, 61)),\n",
       " (('Perú',), (39, 39)),\n",
       " (('Consejo', 'por', 'la', 'Paz'), (46, 49)),\n",
       " (('Canadá',), (24, 24)),\n",
       " (('MESA', 'DEL', 'TURISMO', 'ANDALUZ'), (4, 7)),\n",
       " (('Argentina',), (20, 20)),\n",
       " (('Arranz',), (54, 54)),\n",
       " (('CHILE',), (1, 1)),\n",
       " (('Edica',), (49, 49)),\n",
       " ((\"Moody's\", 'Investors'), (33, 34)),\n",
       " (('PTE',), (3, 3)),\n",
       " (('Real', 'Madrid'), (35, 36)),\n",
       " (('Estudiante',), (3, 3)),\n",
       " (('Galilea',), (49, 49)),\n",
       " (('Arabia', 'Saudí'), (33, 34)),\n",
       " (('Juan', 'Carlos', 'Estévez'), (0, 2)),\n",
       " (('CBF',), (14, 14)),\n",
       " (('Guipúzcoa',), (52, 52)),\n",
       " (('José', 'María', 'Aznar'), (5, 7)),\n",
       " (('Organización', 'Nacional', 'de', 'Ciegos', 'de', 'España'), (17, 22)),\n",
       " (('Mario', 'Stanic'), (2, 3)),\n",
       " (('Curro', 'Romero'), (0, 1)),\n",
       " (('Linda', 'Woods'), (13, 14)),\n",
       " (('Danny', 'Rivera'), (31, 32)),\n",
       " (('Vitoria',), (0, 0)),\n",
       " (('Concepción', 'de', 'Nuestra', 'Señora'), (38, 41)),\n",
       " (('Brasil',), (6, 6)),\n",
       " (('Everest',), (14, 14)),\n",
       " (('WAP',), (34, 34)),\n",
       " (('Iván', 'Vallejo'), (3, 4)),\n",
       " (('Congreso', 'de', 'los', 'Diputados'), (1, 4)),\n",
       " (('Mallorca',), (46, 46)),\n",
       " (('Harmodio', 'Arias'), (16, 17)),\n",
       " (('USA',), (3, 3)),\n",
       " (('SEVILLA',), (2, 2)),\n",
       " (('Fernando', 'Fernández'), (6, 7)),\n",
       " (('Córdoba',), (37, 37)),\n",
       " (('Puerto', 'de', 'Santa', 'María', 'de', 'los', 'Buenos', 'Aires'),\n",
       "  (14, 21)),\n",
       " (('Guayana', 'Francesa'), (42, 43)),\n",
       " (('Verona',), (39, 39)),\n",
       " (('Cuarta',\n",
       "   'Reunión',\n",
       "   'Ministerial',\n",
       "   'de',\n",
       "   'Telecomunicaciones.',\n",
       "   'Industria',\n",
       "   'de',\n",
       "   'la',\n",
       "   'Información'),\n",
       "  (22, 30)),\n",
       " (('Euskal', 'Herritarrok'), (3, 4)),\n",
       " (('Ignacio', 'Truyol'), (0, 1)),\n",
       " (('PA',), (7, 7)),\n",
       " (('Brasil',), (21, 21)),\n",
       " (('UPC',), (15, 15)),\n",
       " (('Gales',), (34, 34)),\n",
       " (('Extremadura',), (6, 6)),\n",
       " (('Colombia',), (16, 16)),\n",
       " (('Chandler', 'Thompson'), (3, 4)),\n",
       " (('PINOCHET',), (10, 10)),\n",
       " (('España',), (29, 29)),\n",
       " (('Recreativo',), (43, 43)),\n",
       " (('BM.', 'GRANOLLERS'), (63, 64)),\n",
       " (('Govern',), (29, 29)),\n",
       " (('Qatar',), (58, 58)),\n",
       " (('Musimundo',), (5, 5)),\n",
       " (('Recopas', 'de', 'Europa'), (30, 32)),\n",
       " (('Sergi', 'Bruguera'), (3, 4)),\n",
       " (('Sercam',), (30, 30)),\n",
       " (('Getafe',), (33, 33)),\n",
       " (('Antoine', 'Duboscq'), (54, 55)),\n",
       " (('Copa', 'del', 'Rey'), (42, 44)),\n",
       " (('Sporting',), (31, 31)),\n",
       " (('Jurado',), (6, 6)),\n",
       " (('AMAN',), (18, 18)),\n",
       " (('Florida',), (12, 12)),\n",
       " (('Rodri',), (5, 5)),\n",
       " (('Júpiter',), (32, 32)),\n",
       " (('PYP', 'B'), (8, 9)),\n",
       " (('Comercial', 'del', 'Plata'), (46, 48)),\n",
       " (('Escuela', 'Reina', 'Sofía'), (29, 31)),\n",
       " (('Joao', 'Pimienta', 'da', 'Veiga'), (23, 26)),\n",
       " (('BARCELONA',), (49, 49)),\n",
       " (('Ayuntamiento', 'de', 'Puerto', 'Príncipe'), (40, 43)),\n",
       " (('Julio', 'Rivera'), (6, 7)),\n",
       " (('Chávez',), (8, 8)),\n",
       " (('Banco', 'Bilbao-Vizcaya'), (29, 30)),\n",
       " (('GOVERN',), (4, 4)),\n",
       " (('Michel', 'Francois', 'Poncet'), (9, 11)),\n",
       " (('Secretaría', 'de', 'Finanzas'), (4, 6)),\n",
       " (('Alexandria',), (9, 9)),\n",
       " (('Consejo', 'Nacional', 'Electoral'), (23, 25)),\n",
       " (('ACOPEP',), (13, 13)),\n",
       " (('FNC',), (38, 38)),\n",
       " (('Martianez',), (2, 2)),\n",
       " (('MADRID',), (9, 9)),\n",
       " (('III',\n",
       "   'Conferencia',\n",
       "   'Iberoamericana',\n",
       "   'de',\n",
       "   'Ministros',\n",
       "   'de',\n",
       "   'Administración',\n",
       "   'Pública.',\n",
       "   'Reforma',\n",
       "   'del',\n",
       "   'Estado'),\n",
       "  (15, 25)),\n",
       " (('FC', 'Barcelona'), (27, 28)),\n",
       " (('INFORME', 'ARARTEKO'), (1, 2)),\n",
       " (('Raimundo', 'Saporta'), (20, 21)),\n",
       " (('Christian', 'Vieri'), (3, 4)),\n",
       " (('Miami',), (13, 13)),\n",
       " (('Barrufet',), (43, 43)),\n",
       " (('Carlos', 'Floriano'), (8, 9)),\n",
       " (('Diputación',), (7, 7)),\n",
       " (('UIB',), (3, 3)),\n",
       " (('Mar', 'del', 'Plata'), (33, 35)),\n",
       " (('Euroliga',), (27, 27)),\n",
       " (('Guayana',), (6, 6)),\n",
       " (('Joana', 'Barceló'), (7, 8)),\n",
       " (('ACNO',), (3, 3)),\n",
       " (('Carvalho',), (8, 8)),\n",
       " (('Telefónica',), (3, 3)),\n",
       " (('Estados', 'Unidos'), (34, 35)),\n",
       " (('ATLETICO', 'DE', 'MADRID'), (52, 54)),\n",
       " (('Orquesta', 'Sinfónica', 'de', 'RTVE'), (9, 12)),\n",
       " (('Comisión', 'de', 'Concordia.', 'Pacificación'), (23, 26)),\n",
       " (('Josep', 'Maldonado'), (38, 39)),\n",
       " (('Albert', 'Montañés'), (0, 1)),\n",
       " (('Departamento', 'de', 'Justicia'), (44, 46)),\n",
       " (('India',), (13, 13)),\n",
       " (('Alianza', 'de', 'la', 'Unión', 'Cívica', 'Radical'), (6, 11)),\n",
       " (('Carlos', 'Reutemann'), (51, 52)),\n",
       " (('\"', 'El', 'Concierto', 'del', 'amor', '\"'), (34, 39)),\n",
       " (('Congreso', 'de', 'la', 'República'), (21, 24)),\n",
       " (('Kuru',), (37, 37)),\n",
       " (('Datanálisis',), (3, 3)),\n",
       " (('Asobal',), (12, 12)),\n",
       " (('Chicago',), (23, 23)),\n",
       " (('Pedralbes',), (49, 49)),\n",
       " (('París',), (0, 0)),\n",
       " (('Armando', 'Manzanero'), (4, 5)),\n",
       " (('Chávez',), (24, 24)),\n",
       " (('JNE',), (15, 15)),\n",
       " (('PNV',), (12, 12)),\n",
       " (('Microsoft',), (13, 13)),\n",
       " (('Grupo', 'de', 'Telecomunicaciones'), (36, 38)),\n",
       " (('Comunidad', 'Valenciana'), (66, 67)),\n",
       " (('Iberdrola',), (26, 26)),\n",
       " (('SV2071',), (1, 1)),\n",
       " (('CVM',), (12, 12)),\n",
       " (('Isaías', 'Abrutzky'), (12, 13)),\n",
       " (('Fernando', 'González'), (6, 7)),\n",
       " (('Red', 'Extremeña', 'de', 'Inserción', 'Sociolaboral'), (1, 5)),\n",
       " (('guerra', 'fría'), (35, 36)),\n",
       " (('FDA',), (30, 30)),\n",
       " (('Brasil',), (16, 16)),\n",
       " (('Copa', 'de', 'la', 'UEFA'), (16, 19)),\n",
       " (('Cataluña',), (22, 22)),\n",
       " (('Tribunal',), (3, 3)),\n",
       " (('Lupo',), (9, 9)),\n",
       " (('Fundación', 'Ramon', 'Trias', 'Fargas'), (43, 46)),\n",
       " (('PRD',), (21, 21)),\n",
       " (('FRA',), (3, 3)),\n",
       " (('Córdoba',), (6, 6)),\n",
       " (('ACEUCHAL',), (7, 7)),\n",
       " (('Casares',), (15, 15)),\n",
       " (('VENEZUELA',), (0, 0)),\n",
       " (('Francisco', 'Pizarro'), (8, 9)),\n",
       " (('Grupo', 'Bancomer'), (5, 6)),\n",
       " (('Maharastra',), (29, 29)),\n",
       " (('Programa',\n",
       "   'Venezolano',\n",
       "   'de',\n",
       "   'Educación-Acción',\n",
       "   'en',\n",
       "   'Derechos',\n",
       "   'Humanos'),\n",
       "  (1, 7)),\n",
       " (('Nueva', 'York'), (27, 28)),\n",
       " (('PA',), (45, 45)),\n",
       " (('Paribas',), (18, 18)),\n",
       " (('Málaga',), (46, 46)),\n",
       " (('Baleares',), (11, 11)),\n",
       " (('estadio', 'del', 'Milenio'), (21, 23)),\n",
       " (('Fuser',), (12, 12)),\n",
       " (('Carlos', 'Luis', 'López'), (4, 6)),\n",
       " (('Egibar',), (0, 0)),\n",
       " (('Chávez',), (3, 3)),\n",
       " (('Italia',), (2, 2)),\n",
       " (('Antonio', 'Chenel'), (0, 1)),\n",
       " (('Leica',), (21, 21)),\n",
       " (('ATLETICO', 'DE', 'MADRID'), (99, 101)),\n",
       " (('Gales',), (2, 2)),\n",
       " (('Domingo', 'Siro'), (2, 3)),\n",
       " (('Fede', 'Marín'), (12, 13)),\n",
       " (('Dow', 'Jones'), (15, 16)),\n",
       " (('EFE',), (8, 8)),\n",
       " (('Frente', 'del', 'País', 'Solidario'), (14, 17)),\n",
       " (('Venezuela',), (4, 4)),\n",
       " (('FEMPEX',), (1, 1)),\n",
       " (('Poblador',), (0, 0)),\n",
       " (('Cafú',), (4, 4)),\n",
       " (('Cámara', 'Costarricense', 'de', 'Libro'), (1, 4)),\n",
       " (('María', 'de', 'Palma'), (47, 49)),\n",
       " (('Ley', 'de', 'Comercio', 'Minorista', 'de', 'Extremadura'), (8, 13)),\n",
       " (('Real', 'Madrid'), (10, 11)),\n",
       " (('Teatro', 'Teresa', 'Carreño'), (26, 28)),\n",
       " (('Las', 'Fallas'), (33, 34)),\n",
       " (('\"', 'Antoñete', '\"'), (5, 7)),\n",
       " (('Daniel', 'Melo'), (6, 7)),\n",
       " (('Gaston', 'Etlis'), (0, 1)),\n",
       " (('HOL',), (9, 9)),\n",
       " (('Matilde', 'Fernández'), (6, 7)),\n",
       " (('Florencia',), (31, 31)),\n",
       " (('España',), (40, 40)),\n",
       " (('Consejo', 'por', 'la', 'Paz'), (5, 8)),\n",
       " (('Sabas',), (19, 19)),\n",
       " (('Dáger',), (38, 38)),\n",
       " (('Consejo', 'Nacional'), (20, 21)),\n",
       " (('Puerto', 'Príncipe'), (2, 3)),\n",
       " (('Cormar',), (36, 36)),\n",
       " (('Barbeito',), (14, 14)),\n",
       " (('Argentina',), (25, 25)),\n",
       " (('Efe',), (25, 25)),\n",
       " (('Salamanca',), (9, 9)),\n",
       " (('Liga', 'Asobal'), (50, 51)),\n",
       " (('Universitat', 'Politécnica', 'de', 'Catalunya'), (21, 24)),\n",
       " (('Instituto', 'Hispano-árabe', 'para', 'la', 'Comunicación'), (23, 27)),\n",
       " (('FC.', 'BARCELONA'), (69, 70)),\n",
       " (('Fidel', 'Castro'), (39, 40)),\n",
       " (('Pablo', 'Zúniga'), (29, 30)),\n",
       " (('Quince',), (6, 6)),\n",
       " (('Ballesteros',), (32, 32)),\n",
       " (('Buenos', 'Aires'), (42, 43)),\n",
       " (('Siria',), (29, 29)),\n",
       " (('Juiz', 'de', 'Fora'), (3, 5)),\n",
       " (('PRD',), (16, 16)),\n",
       " (('Daniel', 'Sawicki'), (49, 50)),\n",
       " (('Sevilla',), (9, 9)),\n",
       " (('Antonio', 'Viana', 'Baptista'), (12, 14)),\n",
       " (('EEUU',), (25, 25)),\n",
       " (('Cáceres',), (5, 5)),\n",
       " (('R.', 'IBARRA'), (3, 4)),\n",
       " (('Manzanero',), (20, 20)),\n",
       " (('Mariano', 'Hood'), (6, 7)),\n",
       " (('Federación', 'Nacional', 'de', 'Cafeteros', 'de', 'Colombia'), (4, 9)),\n",
       " (('Feria', 'Internacional', 'del', 'Libro', 'de', 'San', 'José'), (20, 26)),\n",
       " (('Chile',), (27, 27)),\n",
       " (('PP',), (0, 0)),\n",
       " (('Vicente',), (56, 56)),\n",
       " (('Gallego',), (9, 9)),\n",
       " (('OEA',), (17, 17)),\n",
       " (('ELN',), (38, 38)),\n",
       " (('Brasil',), (54, 54)),\n",
       " (('GOBIERNO',), (5, 5)),\n",
       " (('Javier', 'Irureta'), (42, 43)),\n",
       " (('Castillo',), (18, 18)),\n",
       " (('ME2048',), (1, 1)),\n",
       " (('Córdoba',), (16, 16)),\n",
       " (('Bracamonte',), (9, 9)),\n",
       " (('Consejo', 'Europeo'), (16, 17)),\n",
       " (('France', 'Telecom'), (26, 27)),\n",
       " (('Bustamante',), (0, 0)),\n",
       " (('Ley', 'sobre', 'Derechos.', 'Cultura', 'Indígena'), (9, 13)),\n",
       " (('Cannavaro',), (12, 12)),\n",
       " (('Aznar',), (0, 0)),\n",
       " (('Barrena',), (27, 27)),\n",
       " (('Corte',), (3, 3)),\n",
       " (('Arce',), (87, 87)),\n",
       " (('Ejecutivo',), (13, 13)),\n",
       " (('LETES',), (36, 36)),\n",
       " (('Venezuela',), (72, 72)),\n",
       " (('Carlos', 'Ruiz', 'Sacristán'), (22, 24)),\n",
       " (('Bogotá',), (0, 0)),\n",
       " (('BM.', 'GRANOLLERS'), (27, 28)),\n",
       " (('Salamanca',), (10, 10)),\n",
       " (('Ciudad', 'Condal'), (8, 9)),\n",
       " (('Marín',), (46, 46)),\n",
       " (('Consejo', 'Electoral'), (30, 31)),\n",
       " (('León',), (7, 7)),\n",
       " (('Comisión', 'Europea'), (1, 2)),\n",
       " (('Panamá',), (0, 0)),\n",
       " (('Portugal',), (24, 24)),\n",
       " (('Jordi', 'Pujol'), (6, 7)),\n",
       " (('Asociación', 'de', 'Corresponsales', 'de', 'Prensa', 'Extranjera'),\n",
       "  (6, 11)),\n",
       " (('Barcelona',), (17, 17)),\n",
       " (('Valencia',), (42, 42)),\n",
       " (('Jurado', 'Nacional', 'de', 'Elecciones'), (10, 13)),\n",
       " (('Lockart',), (35, 35)),\n",
       " (('Coso', 'de', 'los', 'Califas'), (2, 5)),\n",
       " (('Móstoles',), (0, 0)),\n",
       " (('Vitor', 'Manuel', 'Melo', 'Pereira'), (2, 5)),\n",
       " (('Minas', 'Gerais'), (10, 11)),\n",
       " (('Cuba',), (10, 10)),\n",
       " (('Sevilla',), (10, 10)),\n",
       " (('Telesp', 'Celular'), (27, 28)),\n",
       " (('EFE',), (46, 46)),\n",
       " (('SV2113',), (1, 1)),\n",
       " (('José', 'María', 'Aznar'), (85, 87)),\n",
       " (('Hacienda', 'del', 'Ayuntamiento', 'de', 'Sevilla'), (3, 7)),\n",
       " (('Hong', 'Kong'), (38, 39)),\n",
       " (('Javier', 'Castaño'), (9, 10)),\n",
       " (('Jon', 'Jauregi'), (9, 10)),\n",
       " (('Maríaa', 'del', 'Mar', 'Bonet'), (39, 42)),\n",
       " (('Jean-Marc', 'Chanelet'), (9, 10)),\n",
       " (('Conselleria', 'de', 'Educación.', 'Cultura'), (11, 14)),\n",
       " (('Vallejo',), (0, 0)),\n",
       " (('Líbano',), (34, 34)),\n",
       " (('Simian', 'Films'), (7, 8)),\n",
       " (('La', 'Coruña'), (0, 1)),\n",
       " (('Castellón',), (41, 41)),\n",
       " (('Joan', 'Mesquida'), (12, 13)),\n",
       " (('Federación', 'Nacional', 'de', 'Cafeteros', 'de', 'Colombia'), (30, 35)),\n",
       " (('TAU', 'VITORIA'), (53, 54)),\n",
       " (('Savage',), (23, 23)),\n",
       " (('Garay',), (13, 13)),\n",
       " (('Edson', 'Arantes', 'do', 'Nascimento'), (38, 41)),\n",
       " (('Asia',), (19, 19)),\n",
       " (('UEFA',), (6, 6)),\n",
       " (('ministerio', 'de', 'Finanzas'), (3, 5)),\n",
       " (('FMI',), (9, 9)),\n",
       " (('Minas', 'Gerais'), (25, 26)),\n",
       " (('Ejército',), (18, 18)),\n",
       " (('Peter', 'Boehm'), (7, 8)),\n",
       " (('México',), (21, 21)),\n",
       " (('Provincia', 'Eclesiástica', 'de', 'Extremadura'), (30, 33)),\n",
       " (('Mainer',), (23, 23)),\n",
       " (('Contraloría', 'General', 'de', 'la', 'República'), (15, 19)),\n",
       " (('Inter',), (14, 14)),\n",
       " (('Túnez',), (31, 31)),\n",
       " (('De', 'la', 'Serna'), (0, 2)),\n",
       " (('CARRILLO',), (5, 5)),\n",
       " (('EFE',), (19, 19)),\n",
       " (('Ortuondo',), (7, 7)),\n",
       " (('Alfredo', 'Kraus'), (12, 13)),\n",
       " (('Jones',), (2, 2)),\n",
       " (('Aznar',), (26, 26)),\n",
       " (('Roberto', 'Baggio'), (2, 3)),\n",
       " (('Marcello', 'Lippi'), (48, 49)),\n",
       " (('PAR',), (9, 9)),\n",
       " (('República', 'Cooperativa', 'de', 'Guayana'), (25, 28)),\n",
       " (('Sergio', 'Arellano', 'Stark'), (9, 11)),\n",
       " (('RUM',), (3, 3)),\n",
       " (('Supercopas', 'de', 'Europa'), (40, 42)),\n",
       " (('Antonio', 'de', 'la', 'Rosa'), (49, 52)),\n",
       " (('Casa', 'Blanca'), (34, 35)),\n",
       " (('Roma',), (2, 2)),\n",
       " (('AENA',), (22, 22)),\n",
       " (('Vanoli',), (31, 31)),\n",
       " (('Comisión',\n",
       "   'Nacional',\n",
       "   'contra',\n",
       "   'la',\n",
       "   'Violencia',\n",
       "   'en',\n",
       "   'los',\n",
       "   'Espectáculos',\n",
       "   'Deportivos'),\n",
       "  (1, 9)),\n",
       " (('Hércules',), (39, 39)),\n",
       " (('VITORIA',), (0, 0)),\n",
       " (('OTAN',), (19, 19)),\n",
       " (('Bolaño',), (14, 14)),\n",
       " (('\"', 'ESES&S', '\"'), (17, 19)),\n",
       " (('RCP',), (22, 22)),\n",
       " (('Franca',), (27, 27)),\n",
       " (('Murguía',), (32, 32)),\n",
       " (('Portugal',), (46, 46)),\n",
       " (('Bayern', 'Múnich'), (25, 26)),\n",
       " (('Bolivia',), (1, 1)),\n",
       " (('IBARRA',), (0, 0)),\n",
       " (('Alfonso', 'Guerra'), (47, 48)),\n",
       " (('Partido', 'de', 'la', 'Revolución', 'Democrática'), (15, 19)),\n",
       " (('BM', 'GRANOLLERS'), (30, 31)),\n",
       " (('San', 'José'), (0, 1)),\n",
       " (('Govern',), (4, 4)),\n",
       " (('Jugovic',), (20, 20)),\n",
       " (('Pastrana',), (17, 17)),\n",
       " (('Simian', 'Films'), (23, 24)),\n",
       " (('Jerez', 'de', 'la', 'Frontera'), (10, 13)),\n",
       " (('Liga', 'en', 'Primera'), (8, 10)),\n",
       " (('Chile',), (12, 12)),\n",
       " (('BARCELONA',), (19, 19)),\n",
       " (('Rodolpho', 'Tourinho'), (21, 22)),\n",
       " (('Aquiles', 'Machado'), (25, 26)),\n",
       " (('Soria',), (2, 2)),\n",
       " (('José', 'Aníbal', 'Peres', 'de', 'Pontes'), (50, 54)),\n",
       " (('Lleida',), (20, 20)),\n",
       " (('Managua',), (24, 24)),\n",
       " (('EA',), (13, 13)),\n",
       " (('Viana', 'Baptista'), (1, 2)),\n",
       " (('Gobierno',), (17, 17)),\n",
       " (('Nasdaq',), (32, 32)),\n",
       " (('\"', 'Daily', 'News', '\"'), (1, 4)),\n",
       " (('Kouchner',), (35, 35)),\n",
       " (('Albania',), (27, 27)),\n",
       " (('Toledo',), (19, 19)),\n",
       " (('Wall', 'Street'), (42, 43)),\n",
       " (('Tarcisio', 'Delgado'), (17, 18)),\n",
       " (('COI',), (40, 40)),\n",
       " (('Caracas',), (15, 15)),\n",
       " (('REVOLUCION', 'CLAVELES'), (9, 10)),\n",
       " (('II', 'Congreso', 'Español', 'de', 'Metrología'), (6, 10)),\n",
       " (('Andrei', 'Pavel'), (0, 1)),\n",
       " (('Martínez',), (49, 49)),\n",
       " (('BNP',), (17, 17)),\n",
       " (('Elián',), (8, 8)),\n",
       " (('UPC',), (26, 26)),\n",
       " (('López', 'de', 'Arriortúa'), (8, 10)),\n",
       " (('Roland', 'Garros'), (10, 11)),\n",
       " (('Unión', 'Europea'), (26, 27)),\n",
       " (('Líbano',), (29, 29)),\n",
       " (('Baggio',), (12, 12)),\n",
       " (('Liga', 'ACB'), (12, 13)),\n",
       " (('servicio', '061'), (3, 4)),\n",
       " (('colegio', 'San', 'Juan', 'Bosco'), (12, 15)),\n",
       " (('Chiquiquirá',), (49, 49)),\n",
       " (('Parma',), (10, 10)),\n",
       " (('UE',), (23, 23)),\n",
       " (('Josemi',), (15, 15)),\n",
       " (('Supercopa', 'de', 'España'), (64, 66)),\n",
       " (('Banco', 'Central', 'Europeo'), (14, 16)),\n",
       " (('Relaciones',\n",
       "   'Económicas',\n",
       "   'Internacionales',\n",
       "   'de',\n",
       "   'la',\n",
       "   'Cancillería',\n",
       "   'panameña'),\n",
       "  (3, 9)),\n",
       " (('Lucy', 'Medina'), (38, 39)),\n",
       " (('Magdalena',), (20, 20)),\n",
       " (('Londres',), (57, 57)),\n",
       " (('PP',), (17, 17)),\n",
       " (('Denis',), (5, 5)),\n",
       " (('Perú',), (72, 72)),\n",
       " (('Presidencia', 'de', 'México'), (6, 8)),\n",
       " (('Gareth', 'Roberts'), (6, 7)),\n",
       " (('Grecia',), (19, 19)),\n",
       " (('Nueva', 'York'), (23, 24)),\n",
       " (('Xabier', 'Markiegi'), (3, 4)),\n",
       " (('EFE',), (14, 14)),\n",
       " (('Liga', 'de', 'los', 'Pirineos'), (73, 76)),\n",
       " (('Caracas',), (9, 9)),\n",
       " (('Víctor', 'de', 'la', 'Serna'), (16, 19)),\n",
       " (('San', 'Juan', 'Jorge', 'Escobar'), (13, 16)),\n",
       " (('PSOE',), (0, 0)),\n",
       " (('Angel', 'Vicioso'), (18, 19)),\n",
       " (('Pérez',), (17, 17)),\n",
       " (('Linda', 'Woods'), (30, 31)),\n",
       " (('TAU', 'Vitoria'), (2, 3)),\n",
       " (('Dida',), (6, 6)),\n",
       " (('Corte',), (4, 4)),\n",
       " (('CDC',), (24, 24)),\n",
       " (('Corte', 'de', 'Apelaciones', 'de', 'Santiago'), (1, 5)),\n",
       " (('Camacho',), (10, 10)),\n",
       " (('Alcorcón',), (0, 0)),\n",
       " (('\"', 'Airport', 'Group', 'International', '\"'), (31, 35)),\n",
       " (('Consell', 'de', 'Menorca'), (3, 5)),\n",
       " (('Londres',), (30, 30)),\n",
       " (('Canadá',), (5, 5)),\n",
       " (('ELGORRIAGA', 'BIDASOA'), (52, 53)),\n",
       " (('Gales',), (4, 4)),\n",
       " (('Bolsa', 'de', 'Buenos', 'Aires'), (15, 18)),\n",
       " (('Betis', 'Denilson'), (43, 44)),\n",
       " (('Argentina',), (26, 26)),\n",
       " (('ETA',), (1, 1)),\n",
       " (('Transparencia',), (27, 27)),\n",
       " (('Estatuto', 'de', 'Autonomía'), (44, 46)),\n",
       " (('Obelisco',), (30, 30)),\n",
       " (('Isaías', 'Pérez', 'Saldaña'), (20, 22)),\n",
       " (('Gonzalo', 'Martínez'), (5, 6)),\n",
       " (('Copa', 'Asobal'), (0, 1)),\n",
       " (('Buffon',), (31, 31)),\n",
       " (('Petrobras',), (3, 3)),\n",
       " (('Rivaldo',), (15, 15)),\n",
       " (('Mérida',), (0, 0)),\n",
       " (('Hugo', 'Chávez'), (13, 14)),\n",
       " (('Pakistán',), (46, 46)),\n",
       " (('Servicio', 'de', 'Emergencia', 'de', 'la', 'Comunidad'), (23, 28)),\n",
       " (('Red', 'Sismológica', 'Nacional'), (38, 40)),\n",
       " (('Québec',), (68, 68)),\n",
       " (('Pinochet',), (7, 7)),\n",
       " (('Israel', 'Zuñiga'), (75, 76)),\n",
       " (('Cardiff',), (15, 15)),\n",
       " (('La', 'Magdalena'), (38, 39)),\n",
       " (('Miami',), (3, 3)),\n",
       " (('Parlamento',), (17, 17)),\n",
       " (('México',), (38, 38)),\n",
       " (('Delegación', 'de', 'la', 'Agencia', 'Efe'), (1, 5)),\n",
       " (('De', 'la', 'Calle'), (0, 2)),\n",
       " (('Agencia', 'Efe'), (11, 12)),\n",
       " (('Teófila', 'Martínez'), (6, 7)),\n",
       " (('Armando', 'Manzanero'), (21, 22)),\n",
       " (('Universidad', 'de', 'Pensilvania'), (15, 17)),\n",
       " (('FNC',), (46, 46)),\n",
       " (('Tailandia',), (61, 61)),\n",
       " (('Toledo',), (20, 20)),\n",
       " (('Nasdaq',), (17, 17)),\n",
       " (('CNE',), (25, 25)),\n",
       " (('España',), (10, 10)),\n",
       " (('CB.', 'CALPISA'), (93, 94)),\n",
       " (('Federico', 'Browne'), (0, 1)),\n",
       " (('BNP-Paribas',), (2, 2)),\n",
       " (('España',), (35, 35)),\n",
       " (('Siria',), (41, 41)),\n",
       " (('Sagem',), (17, 17)),\n",
       " (('ANTONIO', 'MONTERO'), (1, 2)),\n",
       " (('Mireya', 'Moscoso'), (11, 12)),\n",
       " (('Brasil',), (8, 8)),\n",
       " (('Bohdan', 'Ulihrach'), (0, 1)),\n",
       " (('Miami',), (46, 46)),\n",
       " (('Caracas',), (25, 25)),\n",
       " (('Batistuta',), (14, 14)),\n",
       " (('Estado',), (34, 34)),\n",
       " (('Luis', 'López'), (30, 31)),\n",
       " (('EZLN',), (33, 33)),\n",
       " (('BM.', 'GRANOLLERS'), (75, 76)),\n",
       " (('Nariño',), (26, 26)),\n",
       " (('Marcos',), (19, 19)),\n",
       " (('Argentina',), (48, 48)),\n",
       " (('Tribunal', 'Supremo', 'de', 'Justicia'), (34, 37)),\n",
       " (('The', 'American', 'Tobacco', 'Company'), (16, 19)),\n",
       " (('Teixeira',), (1, 1)),\n",
       " (('Asamblea', 'de', 'Extremadura'), (34, 36)),\n",
       " (('Nueva', 'York'), (18, 19)),\n",
       " (('R..', 'Reynolds', 'Tobacco', 'Company'), (7, 10)),\n",
       " (('Alex', 'López', 'Morón'), (6, 8)),\n",
       " (('Moca',), (6, 6)),\n",
       " (('Bruselas',), (22, 22)),\n",
       " (('Jason',), (24, 24)),\n",
       " (('Tommy', 'Robredo'), (0, 1)),\n",
       " (('Kaduna',), (22, 22)),\n",
       " (('Policía',), (40, 40)),\n",
       " (('Ballesteros',), (27, 27)),\n",
       " (('Cáceres',), (6, 6)),\n",
       " (('Offenbach',), (35, 35)),\n",
       " (('Asociación', 'de', 'Guías', 'Turísticas', 'de', 'Cantabria'), (25, 30)),\n",
       " (('Gales',), (9, 9)),\n",
       " (('José', 'del', 'Solar'), (15, 17)),\n",
       " (('Aldair',), (16, 16)),\n",
       " (('Miami',), (44, 44)),\n",
       " (('Juan', 'Carlos', 'Rodríguez', 'Ibarra'), (37, 40)),\n",
       " (('Interior',), (3, 3)),\n",
       " (('Patrick', 'Muller'), (38, 39)),\n",
       " (('Jean', 'Bertrand', 'Aristide'), (19, 21)),\n",
       " (('Junta',), (7, 7)),\n",
       " (('Arias',), (8, 8)),\n",
       " (('Estudiantes',), (5, 5)),\n",
       " (('Pinochet',), (29, 29)),\n",
       " (('Vieri',), (38, 38)),\n",
       " (('EFECOM',), (8, 8)),\n",
       " (('Madrid',), (25, 25)),\n",
       " (('Alcatel',), (15, 15)),\n",
       " (('EEUU',), (48, 48)),\n",
       " (('Liz',), (4, 4)),\n",
       " (('Pamplona',), (0, 0)),\n",
       " (('OCM',), (49, 49)),\n",
       " (('CECEI',), (48, 48)),\n",
       " (('Nasdaq',), (43, 43)),\n",
       " (('XIII', 'cumbre'), (1, 2)),\n",
       " (('Hughes',), (3, 3)),\n",
       " (('OEA',), (12, 12)),\n",
       " (('VEN',), (3, 3)),\n",
       " (('Efe',), (17, 17)),\n",
       " (('Murcia',), (41, 41)),\n",
       " (('Nueva', 'York'), (13, 14)),\n",
       " (('Jurado', 'Nacional', 'de', 'Elecciones'), (12, 15)),\n",
       " (('K-2',), (4, 4)),\n",
       " (('Bancomer',), (21, 21)),\n",
       " (('Sergi', 'Bruguera'), (6, 7)),\n",
       " (('Hugo', 'Chávez'), (8, 9)),\n",
       " (('Comercio',), (4, 4)),\n",
       " (('Centroamérica',), (46, 46)),\n",
       " (('Zarrías',), (0, 0)),\n",
       " (('Fuerzas', 'Armadas', 'del', 'Líbano'), (5, 8)),\n",
       " (('Bonoloto',), (26, 26)),\n",
       " (('RSN',), (19, 19)),\n",
       " (('Economía',), (13, 13)),\n",
       " (('Petróleo', 'Intermedio', 'de', 'Texas'), (9, 12)),\n",
       " (('Extremadura',), (24, 24)),\n",
       " (('Desarrollo', 'Económico'), (3, 4)),\n",
       " (('Joe', 'Lockhart'), (37, 38)),\n",
       " (('Manuel', 'Chaves'), (17, 18)),\n",
       " (('Ecija',), (10, 10)),\n",
       " (('INDIA',), (0, 0)),\n",
       " (('Facultad', 'de', 'Ciencias', 'Económicas.', 'Empresariales'), (24, 28)),\n",
       " (('Augusto', 'Centena', 'Hermanos'), (68, 70)),\n",
       " (('Ejército',), (15, 15)),\n",
       " (('Consejo', 'General', 'del', 'Poder', 'Judicial'), (9, 13)),\n",
       " (('JNE',), (17, 17)),\n",
       " (('EEUU',), (17, 17)),\n",
       " (('Galarza',), (19, 19)),\n",
       " (('Miguel',), (34, 34)),\n",
       " (('Olaya',), (19, 19)),\n",
       " (('ESTADO',), (5, 5)),\n",
       " (('EEUU',), (42, 42)),\n",
       " (('Televisa',), (4, 4)),\n",
       " (('PM2011',), (1, 1)),\n",
       " (('Guatemala',), (74, 74)),\n",
       " (('Supercopas', 'de', 'España'), (45, 47)),\n",
       " (('Ibovespa',), (15, 15)),\n",
       " (('ME2056',), (1, 1)),\n",
       " (('Menem',), (0, 0)),\n",
       " (('Unión', 'Europea'), (32, 33)),\n",
       " (('MADRID',), (22, 22)),\n",
       " (('IND',), (44, 44)),\n",
       " (('Roger', 'Serrano'), (61, 62)),\n",
       " (('Grupo', 'Banamex', 'Accival'), (29, 31)),\n",
       " (('Christian', 'Vieri'), (6, 7)),\n",
       " (('PACHECO',), (3, 3)),\n",
       " (('Instituto', 'Nicaragüense', 'de', 'Estudios', 'Territoriales'), (11, 15)),\n",
       " (('Brasil',), (3, 3)),\n",
       " (('Ministerio', 'de', 'Infraestructura'), (2, 4)),\n",
       " (('Panaria',), (23, 23)),\n",
       " (('Miami',), (66, 66)),\n",
       " (('Paraguay',), (10, 10)),\n",
       " (('Pedro', 'de', 'Mendoza'), (29, 31)),\n",
       " (('Nueva', 'Guinea'), (52, 53)),\n",
       " (('estadio', 'Artemio', 'Franchi'), (24, 26)),\n",
       " (('GUERRA',), (10, 10)),\n",
       " (('PORTLAND', 'S.', 'ANTONIO'), (78, 80)),\n",
       " (('R.', 'Baggio'), (9, 10)),\n",
       " (('Las', 'Américas'), (12, 13)),\n",
       " (('Logroñés',), (48, 48)),\n",
       " (('San', 'Juan'), (0, 1)),\n",
       " (('Bomberos', 'de', 'la', 'Comunidad'), (30, 33)),\n",
       " (('Pakistán',), (4, 4)),\n",
       " (('Dida',), (13, 13)),\n",
       " (('Asociación', 'de', 'Países', 'Productores', 'de', 'Café'), (8, 13)),\n",
       " (('OEA',), (34, 34)),\n",
       " (('Extremadura',), (3, 3)),\n",
       " (('Griñón',), (8, 8)),\n",
       " (('Diego', 'Manzanero'), (15, 16)),\n",
       " (('Parlamento', 'Andino'), (27, 28)),\n",
       " (('Jorge', 'Soto'), (38, 39)),\n",
       " (('ESP',), (10, 10)),\n",
       " (('Guillermo', 'Moreno'), (3, 4)),\n",
       " (('CHAVES',), (5, 5)),\n",
       " (('FC.', 'BARCELONA'), (134, 135)),\n",
       " (('TAU', 'Vitoria'), (8, 9)),\n",
       " (('FC', 'Barcelona'), (24, 25)),\n",
       " (('Enrique', 'Olivera'), (13, 14)),\n",
       " (('Bolivia',), (28, 28)),\n",
       " (('Santini',), (0, 0)),\n",
       " (('II',\n",
       "   'Reunión',\n",
       "   'de',\n",
       "   'Coordinación.',\n",
       "   'Responsables',\n",
       "   'de',\n",
       "   'Cooperación'),\n",
       "  (34, 40)),\n",
       " (('Concejo', 'Municipal'), (26, 27)),\n",
       " (('ONG',), (1, 1)),\n",
       " (('Consejo', 'Nacional', 'del', 'Partido', 'Justicialista'), (11, 15)),\n",
       " (('CONFIEP',), (4, 4)),\n",
       " (('Mérida',), (11, 11)),\n",
       " (('\"', 'Ley', 'de', 'Enjuiciamiento', 'Criminal', 'moderna', '\"'), (23, 29)),\n",
       " (('Puerta', 'Grande'), (46, 47)),\n",
       " (('Mark', 'Knowles'), (6, 7)),\n",
       " (('Martín', 'Bertrán'), (4, 5)),\n",
       " (('Sao', 'Paulo'), (41, 42)),\n",
       " (('Fiscalía',), (43, 43)),\n",
       " (('Matos',), (21, 21)),\n",
       " (('Cáceres',), (16, 16)),\n",
       " (('ELN',), (3, 3)),\n",
       " (('Comité', 'de', 'Entidades', 'de', 'Crédito.', 'Inversiones'), (41, 46)),\n",
       " (('Liga', 'ACB'), (34, 35)),\n",
       " (('Brasil',), (19, 19)),\n",
       " (('Andalucía',), (6, 6)),\n",
       " (('BBVA',), (39, 39)),\n",
       " (('Colombia',), (14, 14)),\n",
       " (('Tribunal', 'de', 'la', 'Competencia'), (29, 32)),\n",
       " (('Telefónica',), (0, 0)),\n",
       " (('Cumbre',), (20, 20)),\n",
       " (('Madeleine', 'Albright'), (36, 37)),\n",
       " (('Puebla',), (21, 21)),\n",
       " (('Cuba',), (42, 42)),\n",
       " (('Sebastian', 'Prieto'), (0, 1)),\n",
       " (('OPA',), (16, 16)),\n",
       " (('NBC',), (6, 6)),\n",
       " (('Estados', 'Unidos'), (41, 42)),\n",
       " (('Juan', 'Ortuño'), (27, 28)),\n",
       " (('Betancor',), (2, 2)),\n",
       " (('Puñal',), (25, 25)),\n",
       " (('Lionel', 'Roux'), (0, 1)),\n",
       " (('NOBEL', 'ECONOMIA'), (1, 2)),\n",
       " (('EFECOM',), (46, 46)),\n",
       " (('VI', 'Feria', 'de', 'la', 'Alfarería.', 'el', 'Barro'), (12, 18)),\n",
       " (('Reino', 'Unido'), (2, 3)),\n",
       " (('Ejecutivo',), (3, 3)),\n",
       " (('Contreras',), (4, 4)),\n",
       " (('Pernando', 'Barrena'), (36, 37)),\n",
       " (('Scott',), (24, 24)),\n",
       " (('Alfredo', 'Kraus'), (29, 30)),\n",
       " (('Celestí', 'Alomar'), (5, 6)),\n",
       " (('Extremadura',), (19, 19)),\n",
       " (('JIAM',), (10, 10)),\n",
       " (('Harry', 'Rosario'), (6, 7)),\n",
       " (('Salomon', 'Smith', 'Barney'), (41, 43)),\n",
       " (('Palacio',), (13, 13)),\n",
       " (('At.', 'Madrid'), (20, 21)),\n",
       " (('Iván', 'Luis', 'Zamorano'), (6, 8)),\n",
       " (('Barcelona',), (7, 7)),\n",
       " (('Cortes',), (20, 20)),\n",
       " (('Toni', 'Velamazán'), (26, 27)),\n",
       " (('Banco', 'Central', 'de', 'Rusia'), (36, 39)),\n",
       " (('Alvaro', 'Vega'), (33, 34)),\n",
       " (('Centro', 'Pasarela', 'Show'), (11, 13)),\n",
       " (('Wembley',), (65, 65)),\n",
       " (('Antonio', 'Chenel'), (28, 29)),\n",
       " (('Leopoldo', 'Torrado'), (37, 38)),\n",
       " (('\"', 'Madagascar', '\"'), (36, 38)),\n",
       " (('Jurado',), (19, 19)),\n",
       " (('Dow', 'Jones'), (43, 44)),\n",
       " (('Lockhart',), (0, 0)),\n",
       " (('BM.', 'GRANOLLERS'), (60, 61)),\n",
       " (('Puerto', 'Suárez'), (34, 35)),\n",
       " (('Caquetá',), (28, 28)),\n",
       " (('Junta', 'de', 'Andalucía'), (27, 29)),\n",
       " (('PRD',), (3, 3)),\n",
       " (('Copa', 'del', 'Rey'), (54, 56)),\n",
       " (('SV2045',), (1, 1)),\n",
       " (('Santa', 'Fe'), (8, 9)),\n",
       " (('Turismo.', 'Deporte', 'de', 'la', 'Junta', 'de', 'Andalucía'), (3, 9)),\n",
       " (('OEA',), (23, 23)),\n",
       " (('Américas',), (15, 15)),\n",
       " (('Miño',), (25, 25)),\n",
       " (('Andrés', 'de', 'la', 'Oliva'), (37, 40)),\n",
       " (('Albright',), (5, 5)),\n",
       " (('Cáceres',), (13, 13)),\n",
       " (('PP',), (12, 12)),\n",
       " (('Guatemala',), (58, 58)),\n",
       " (('Urdangarin',), (53, 53)),\n",
       " (('Santander',), (0, 0)),\n",
       " (('Juegos',), (37, 37)),\n",
       " (('OEA',), (29, 29)),\n",
       " (('Franca',), (24, 24)),\n",
       " (('ME2072',), (1, 1)),\n",
       " (('Liechtenstein',), (34, 34)),\n",
       " (('Córdoba',), (3, 3)),\n",
       " (('Chávez',), (0, 0)),\n",
       " (('Montero',), (33, 33)),\n",
       " (('Curro', 'Romero'), (34, 35)),\n",
       " (('Deportivo',), (28, 28)),\n",
       " (('FRANCIA',), (1, 1)),\n",
       " (('Perú',), (47, 47)),\n",
       " (('BEL',), (4, 4)),\n",
       " (('France', 'Telecom'), (28, 29)),\n",
       " (('Guayana',), (19, 19)),\n",
       " (('Maia',), (17, 17)),\n",
       " (('Río',), (28, 28)),\n",
       " (('Oscar', 'Burrieza'), (6, 7)),\n",
       " (('AENA',), (2, 2)),\n",
       " (('Juegos', 'Panamericanos'), (8, 9)),\n",
       " (('XIV', 'Juegos', 'Panamericanos'), (9, 11)),\n",
       " (('Compañía', 'Riograndense', 'de', 'Telecomunicaciones'), (48, 51)),\n",
       " (('Congreso', 'de', 'EEUU'), (16, 18)),\n",
       " (('Alemania',), (18, 18)),\n",
       " (('\"', 'grupos', 'de', 'tareas', '\"'), (19, 23)),\n",
       " (('Diego', 'Manzanero'), (0, 1)),\n",
       " (('Poder', 'Ejecutivo'), (41, 42)),\n",
       " (('\"', 'Miss', 'Brasil', 'Gay', '\"'), (23, 27)),\n",
       " (('Alberto', 'Martín'), (55, 56)),\n",
       " (('Asuntos', 'Sociales'), (17, 18)),\n",
       " (('Brown',), (25, 25)),\n",
       " (('BANACCI',), (21, 21)),\n",
       " (('Rivera',), (4, 4)),\n",
       " (('Gobierno',), (34, 34)),\n",
       " (('ESES&S',), (31, 31)),\n",
       " (('Horst', 'Koehler'), (12, 13)),\n",
       " (('París',), (29, 29)),\n",
       " (('Grupo', 'Popular'), (11, 12)),\n",
       " (('Díez', 'Canseco'), (0, 1)),\n",
       " (('Banco', 'Central'), (27, 28)),\n",
       " (('\"', 'Antoñete', '\"'), (2, 4)),\n",
       " (('ECOTASA',), (2, 2)),\n",
       " (('Marx',), (0, 0)),\n",
       " (('Jeff', 'Tarango'), (19, 20)),\n",
       " (('ME2021',), (1, 1)),\n",
       " (('Grupo', 'Catalán'), (14, 15)),\n",
       " (('IU',), (3, 3)),\n",
       " (('Real', 'Federación', 'Española', 'de', 'Atletismo'), (10, 14)),\n",
       " (('Convergencia',), (34, 34)),\n",
       " (('OPEP',), (6, 6)),\n",
       " (('Lázaro', 'González'), (39, 40)),\n",
       " (('Scariolo',), (9, 9)),\n",
       " (('Congreso',), (5, 5)),\n",
       " (('Osvaldo', 'Braga'), (28, 29)),\n",
       " (('Asturias',), (6, 6)),\n",
       " (('Gobierno', 'de', 'Georgetown'), (52, 54)),\n",
       " (('Jean-Michel', 'Aulas'), (6, 7)),\n",
       " (('Campus', 'de', 'Verano'), (11, 13)),\n",
       " (('La', 'Cenicienta'), (24, 25)),\n",
       " (('Domoraud',), (14, 14)),\n",
       " (('Comisión', 'estadounidense', 'de', 'valores', 'en', 'bolsa'), (8, 13)),\n",
       " (('Paul', 'Denis'), (0, 1)),\n",
       " (('Badajoz',), (8, 8)),\n",
       " (('Gobierno',), (7, 7)),\n",
       " (('Departamento', 'de', 'Salud'), (15, 17)),\n",
       " (('\"', 'Manza', 'Music', '\"'), (10, 13)),\n",
       " (('Sebastián', 'Castella'), (6, 7)),\n",
       " (('SV2188',), (1, 1)),\n",
       " (('Carmen', 'Hermosín'), (12, 13)),\n",
       " (('Fundación', 'Española', 'del', 'Corazón'), (4, 7)),\n",
       " (('Mérida', 'CP'), (4, 5)),\n",
       " (('Barcelona',), (2, 2)),\n",
       " (('Gobierno', 'de', 'Estados', 'Unidos'), (16, 19)),\n",
       " (('México',), (8, 8)),\n",
       " (('Alfonso', 'Reyes'), (2, 3)),\n",
       " ...}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entidades_referencia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.7747644219719605\n",
      "Precision: 0.8156302927655457\n",
      "F-score: 0.7946723243752947\n"
     ]
    }
   ],
   "source": [
    "### AVALUEM ###\n",
    "encerts = 0\n",
    "for entitat in entitats_predites_testa_esp:\n",
    "    if entitat in entitats_reals_testa_esp:\n",
    "        encerts += 1\n",
    "\n",
    "total_entitats_reals = len(entitats_reals_testa_esp)\n",
    "total_entitats_predites = len(entitats_predites_testa_esp)\n",
    "\n",
    "recall = encerts / total_entitats_reals\n",
    "\n",
    "if total_entitats_predites != 0:\n",
    "    precision = encerts / total_entitats_predites\n",
    "    f_score = (2 * precision * recall) / (precision + recall)\n",
    "else:\n",
    "    precision = 0\n",
    "    f_score = 0\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F-score:\", f_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neerlandès"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tagger = CRFTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940191577997718\n"
     ]
    }
   ],
   "source": [
    "# Entrenem el model per predir els POS que corresponen a cada token\n",
    "\n",
    "train_ned_pos_tag = []\n",
    "for sentence in train_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem2))\n",
    "    train_ned_pos_tag.append(frases)\n",
    "    \n",
    "model_tagger.train(train_ned_pos_tag, 'model_POS.crf.tagger')\n",
    "\n",
    "\n",
    "# Fem prediccions i mirem l'accuracy\n",
    "\n",
    "testa_ned_pre_tag = []\n",
    "for sentence in testa_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append(elem1)\n",
    "    testa_ned_pre_tag.append(frases)\n",
    "    \n",
    "predicted = model_tagger.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "predictions = [elem[1] for sentence in predicted for elem in sentence]\n",
    "real_label = [elem[1] for sentence in testa_ned for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions, real_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "            - longitud\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "        token = tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "            \n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"SUF_\" + token[-3:])\n",
    "        \n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        feature_list.append(\"WORD_\" + token)\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "# Crear una instancia de FeatureExtractor\n",
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_BIO_tag = []\n",
    "for sentence in train_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    train_ned_BIO_tag.append(frases)\n",
    "    \n",
    "model_BIO = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIO.train(train_ned_BIO_tag, 'model_BIO.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9683975906811367\n"
     ]
    }
   ],
   "source": [
    "testa_ned_BIO_tag = []\n",
    "for sentence in testa_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    testa_ned_BIO_tag.append(frases)\n",
    "\n",
    "predicted_BIO = model_BIO.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "predictions_BIO = [elem[1] for sentence in predicted_BIO for elem in sentence]\n",
    "real_label_BIO = [elem[1] for sentence in testa_ned_BIO_tag for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions_BIO, real_label_BIO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "entitats_reals_testa_ned = []\n",
    "\n",
    "for sentence in testa_ned_BIO_tag:\n",
    "    ent = []\n",
    "    name = None\n",
    "    prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "    \n",
    "    for token in sentence:\n",
    "        word, tag = token\n",
    "        \n",
    "        if tag.startswith('B-'):\n",
    "            # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "            if ent:\n",
    "                entitats_reals_testa_ned.append((tuple(ent), name))\n",
    "            # Creamos una nueva entidad con la palabra actual\n",
    "            ent = [word]\n",
    "            # Obtenemos el tipo de entidad\n",
    "            name = tag.split('-')[1]\n",
    "            prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag.startswith('I-'):\n",
    "            # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "            if prev_tag:\n",
    "                ent.append(word)\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag == 'O' and ent:\n",
    "            # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "            entitats_reals_testa_ned.append((tuple(ent), name))\n",
    "            # Reiniciamos la lista de la entidad actual\n",
    "            ent = []\n",
    "            prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "    # Agregamos la última entidad si la hay\n",
    "    if ent:\n",
    "        entitats_reals_testa_ned.append((tuple(ent), name))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_BIO = model_BIO.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "entitats_predites_testa_ned = []\n",
    "\n",
    "for sentence in predicted_BIO:\n",
    "    ent = []\n",
    "    name = None\n",
    "    prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "    \n",
    "    for token in sentence:\n",
    "        word, tag = token\n",
    "        \n",
    "        if tag.startswith('B-'):\n",
    "            # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "            if ent:\n",
    "                entitats_predites_testa_ned.append((tuple(ent), name))\n",
    "            # Creamos una nueva entidad con la palabra actual\n",
    "            ent = [word]\n",
    "            # Obtenemos el tipo de entidad\n",
    "            name = tag.split('-')[1]\n",
    "            prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag.startswith('I-'):\n",
    "            # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "            if prev_tag:\n",
    "                ent.append(word)\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag == 'O' and ent:\n",
    "            # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "            entitats_predites_testa_ned.append((tuple(ent), name))\n",
    "            # Reiniciamos la lista de la entidad actual\n",
    "            ent = []\n",
    "            prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "    # Agregamos la última entidad si la hay\n",
    "    if ent:\n",
    "        entitats_predites_testa_ned.append((tuple(ent), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.6788990825688074\n",
      "Precision: 0.7477894736842106\n",
      "F-score: 0.7116810258465238\n"
     ]
    }
   ],
   "source": [
    "### AVALUEM ###\n",
    "encerts = 0\n",
    "for entitat in entitats_predites_testa_ned:\n",
    "    if entitat in entitats_reals_testa_ned:\n",
    "        encerts += 1\n",
    "\n",
    "total_entitats_reals = len(entitats_reals_testa_ned)\n",
    "total_entitats_predites = len(entitats_predites_testa_ned)\n",
    "\n",
    "recall = encerts / total_entitats_reals\n",
    "\n",
    "if total_entitats_predites != 0:\n",
    "    precision = encerts / total_entitats_predites\n",
    "    f_score = (2 * precision * recall) / (precision + recall)\n",
    "else:\n",
    "    precision = 0\n",
    "    f_score = 0\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F-score:\", f_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicció amb IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_io(train_data_bio):\n",
    "    train_data_io = []\n",
    "    for sentence in train_data_bio:\n",
    "        io_tags = []\n",
    "        for word, pos_tag, bio_tag in sentence:\n",
    "            if bio_tag == 'O':\n",
    "                io_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                io_tags.append('I' + bio_tag[1:])\n",
    "            else:\n",
    "                io_tags.append(bio_tag)\n",
    "                \n",
    "        train_data_io.append(list(zip([word for word, pos_tag, bio_tag in sentence], io_tags)))\n",
    "    return train_data_io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espanyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 50064\n",
      "Precisió d'entitats: 94.59781191542429 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testa_esp)\n",
    "prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'FeatureExtractor2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProva amb use_basic_features=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_basic_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_prefix_suffix_features=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_prefix_suffix_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_context_features=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_context_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Creem l'extractor de característiques amb els paràmetres corresponents\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mFeatureExtractor2\u001b[49m(use_basic_features\u001b[38;5;241m=\u001b[39muse_basic_features, \n\u001b[0;32m     16\u001b[0m                                        use_prefix_suffix_features\u001b[38;5;241m=\u001b[39muse_prefix_suffix_features, \n\u001b[0;32m     17\u001b[0m                                        use_context_features\u001b[38;5;241m=\u001b[39muse_context_features, \n\u001b[0;32m     18\u001b[0m                                        pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m train_esp_pre_IO \u001b[38;5;241m=\u001b[39m convert_to_io(train_esp)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Entrenem el model CRFTagger amb l'esquema IO\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FeatureExtractor2' is not defined"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_IO_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format IO\n",
    "    dades_prova = convert_to_io(testa_esp)\n",
    "    prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_IO_esp:  1\n",
      "Total de entidades: 52923\n",
      "Entidades predichas correctamente: 50132\n",
      "Precisión de entidades: 94.72630047427396 %\n",
      "--------------------------------------------------\n",
      "model_IO_esp:  2\n",
      "Total de entidades: 105846\n",
      "Entidades predichas correctamente: 100264\n",
      "Precisión de entidades: 94.72630047427396 %\n",
      "--------------------------------------------------\n",
      "model_IO_esp:  3\n",
      "Total de entidades: 158769\n",
      "Entidades predichas correctamente: 150396\n",
      "Precisión de entidades: 94.72630047427396 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pattern = r'\\d+' \n",
    "        \n",
    "extractor1 = feature_extractor1(pattern)\n",
    "extractor2 = feature_extractor2(pattern)\n",
    "extractor3 = feature_extractor3(pattern)\n",
    "\n",
    "train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "# Entrenamos el modelo CRFTagger con el esquema IO\n",
    "model_IO_esp1 = CRFTagger(feature_func=extractor1._get_features)\n",
    "model_IO_esp1.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "    \n",
    "model_IO_esp2 = CRFTagger(feature_func=extractor2._get_features)\n",
    "model_IO_esp2.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "    \n",
    "model_IO_esp3 = CRFTagger(feature_func=extractor3._get_features)\n",
    "model_IO_esp3.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "# Inicializamos los contadores\n",
    "total_entidades = 0\n",
    "entidades_correctas = 0\n",
    "\n",
    "# Convertimos los datos de prueba a formato IO\n",
    "data_prueba = convert_to_io(testa_esp)\n",
    "    \n",
    "predicciones1 = model_IO_esp1.tag_sents([[palabra for palabra, _ in frase] for frase in data_prueba])\n",
    "predicciones2 = model_IO_esp2.tag_sents([[palabra for palabra, _ in frase] for frase in data_prueba])\n",
    "predicciones3 = model_IO_esp3.tag_sents([[palabra for palabra, _ in frase] for frase in data_prueba])\n",
    "\n",
    "pre = [predicciones1, predicciones2, predicciones3]\n",
    "\n",
    "i = 0\n",
    "for predicciones in pre:\n",
    "    i += 1\n",
    "    # Iteramos sobre cada muestra en el conjunto de datos de prueba\n",
    "    for frase_certes, frase_predicciones in zip(data_prueba, predicciones):\n",
    "        for palabra_certes, etiqueta_certes in frase_certes:\n",
    "            for palabra_pred, etiqueta_pred in frase_predicciones:\n",
    "                if palabra_certes == palabra_pred:\n",
    "                    total_entidades += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entidades_correctas += 1\n",
    "                    break\n",
    "\n",
    "    # Calculamos el porcentaje de entidades predichas correctamente\n",
    "    precision_entidades = (entidades_correctas / total_entidades) * 100 if total_entidades > 0 else 0\n",
    "\n",
    "    print(\"model_IO_esp: \",i)\n",
    "    print(\"Total de entidades:\", total_entidades)\n",
    "    print(\"Entidades predichas correctamente:\", entidades_correctas)\n",
    "    print(\"Precisión de entidades:\", precision_entidades, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testb_esp)\n",
    "prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IO NED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_pre_IO = convert_to_io(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_ned.train(train_ned_pre_IO, 'model_io.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 36539\n",
      "Precisió d'entitats: 96.95385676758565 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testa_ned)\n",
    "prediccions = model_IO_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_ned_pre_IO = convert_to_io(train_ned)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_IO_esp.train(train_ned_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format IO\n",
    "    dades_prova = convert_to_io(testa_ned)\n",
    "    prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_ned_pre_IO = convert_to_io(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_ned.train(train_ned_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testb_ned)\n",
    "prediccions = model_IO_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_biow(train_data_bio):\n",
    "    train_data_biow = []\n",
    "    for sentence in train_data_bio:\n",
    "        biow_tags = []\n",
    "        for word, pos_tag, bio_tag in sentence:\n",
    "            if bio_tag == 'O':\n",
    "                biow_tags.append('O')\n",
    "            else:\n",
    "                biow_tags.append(bio_tag + 'W')  # Añadir 'W' a todas las etiquetas\n",
    "            \n",
    "        train_data_biow.append(list(zip([word for word, pos_tag, bio_tag in sentence], biow_tags)))\n",
    "    return train_data_biow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_pre_BIOW = convert_to_biow(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_esp.train(train_esp_pre_BIOW, 'model_biow.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 50166\n",
      "Precisió d'entitats: 94.79054475369877 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testa_esp)\n",
    "prediccions = model_BIOW_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_esp_pre_BIOW = convert_to_biow(train_esp)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema BIOW\n",
    "    model_BIOW_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOW_esp.train(train_esp_pre_IO, 'model_biow.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format BIOW\n",
    "    dades_prova = convert_to_biow(testa_esp)\n",
    "    prediccions = model_BIOW_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_pre_BIOW = convert_to_biow(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_esp.train(train_esp_pre_BIOW, 'model_biow.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testb_esp)\n",
    "prediccions = model_BIOW_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_pre_BIOW = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_ned.train(train_ned_pre_BIOW, 'model_biow.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 36486\n",
      "Precisió d'entitats: 96.81322471939926 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testa_ned)\n",
    "prediccions = model_BIOW_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_ned_pre_BIOW = convert_to_biow(train_ned)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_BIOW_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOW_ned.train(train_ned_pre_IO, 'model_biow.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format BIOW\n",
    "    dades_prova = convert_to_biow(testa_ned)\n",
    "    prediccions = model_BIOW_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_ned_pre_BIOW = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_ned.train(train_ned_pre_BIOW, 'model_biow.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testb_ned)\n",
    "prediccions = model_BIOW_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIOES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bioes(train_data_bio):\n",
    "    train_data_bioes = []\n",
    "    for sentence in train_data_bio:\n",
    "        bioes_tags = []\n",
    "        for i, (word, pos_tag, bio_tag) in enumerate(sentence):\n",
    "            if bio_tag == 'O':\n",
    "                bioes_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][2] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('S' + bio_tag[1:])  # Single\n",
    "                else:\n",
    "                    bioes_tags.append('B' + bio_tag[1:])  # Begin\n",
    "            elif bio_tag.startswith('I-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][2] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('E' + bio_tag[1:])  # End\n",
    "                else:\n",
    "                    bioes_tags.append('I' + bio_tag[1:])  # Inside\n",
    "            else:\n",
    "                raise ValueError(\"Etiqueta BIO incorrecta: {}\".format(bio_tag))\n",
    "                \n",
    "        train_data_bioes.append(list(zip([word for word, pos_tag, bio_tag in sentence], bioes_tags)))\n",
    "    return train_data_bioes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_pre_BIOES = convert_to_bioes(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_esp.train(train_esp_pre_BIOW, 'model_bioes.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 44792\n",
      "Precisió d'entitats: 84.63616952931618 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testa_esp)\n",
    "prediccions = model_BIOES_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_esp_pre_BIOES = convert_to_bioes(train_esp)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOES_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format IO\n",
    "    dades_prova = convert_to_bioes(testa_esp)\n",
    "    prediccions = model_BIOES_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_pre_BIOES = convert_to_bioes(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_esp.train(train_esp_pre_BIOW, 'model_bioes.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testb_esp)\n",
    "prediccions = model_BIOES_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_pre_BIOES = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_ned.train(train_ned_pre_BIOES, 'model_bioes.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33903\n",
      "Precisió d'entitats: 89.95940244646695 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testa_ned)\n",
    "prediccions = model_BIOES_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_ned_pre_BIOES = convert_to_bioes(train_ned)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOES_ned.train(train_ned_pre_IO, 'model_biow.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format BIOES\n",
    "    dades_prova = convert_to_bioes(testa_ned)\n",
    "    prediccions = model_BIOES_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_ned_pre_BIOES = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_ned.train(train_ned_pre_BIOES, 'model_bioes.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testb_ned)\n",
    "prediccions = model_BIOES_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mark', 'B-PER'),\n",
       " ('Pedersen', 'I-PER'),\n",
       " ('treballa', 'O'),\n",
       " ('a', 'B-PER'),\n",
       " ('Google', 'I-PER'),\n",
       " ('des', 'O'),\n",
       " ('del', 'O'),\n",
       " ('1994', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BIO.tag(nltk.word_tokenize(\"Mark Pedersen treballa a Google des del 1994.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_IO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_IO\u001b[49m\u001b[38;5;241m.\u001b[39mtag(nltk\u001b[38;5;241m.\u001b[39mword_tokenize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMark Pedersen treballa a Google des del 1994.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_IO' is not defined"
     ]
    }
   ],
   "source": [
    "model_IO.tag(nltk.word_tokenize(\"Mark Pedersen treballa a Google des del 1994.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaluació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459214330253387"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaluació mal feta, contant només quants tokens són correctes, i no les entitats correctes.\n",
    "model.accuracy(testa_esp_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaluació ben feta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hem d'avaluar quantes entitats estan reconegudes correctament, no quants tokens son correctes.\n",
    "Descodificar la sequencia i obtenir les entitats, i doncs avaluar les entitats.\n",
    "Per exemple, 'Mark Pedersen Romero' --> 'M P R' (una entitat) per BIO; 'M' i 'P R' (dos entitats) per IO; en aquest exemple IO ho fa malament.\n",
    "\n",
    "A nivell d'entitats: Recall i f-score\n",
    "\n",
    "Per avaluar el model avaluem en base a recall i precisio parcial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple d'ús CRFTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: El, Features: ['CAPITALIZATION', 'PRE_E', 'SUF_l', 'posterior1_men_NC', 'posterior2_atendió_VMI', 'WORD_El']\n",
      "Token: men, Features: ['PRE_m', 'PRE_me', 'SUF_n', 'SUF_en', 'anterior1_El_DA', 'posterior1_atendió_VMI', 'posterior2_a_SP', 'WORD_men']\n",
      "Token: atendió, Features: ['PRE_a', 'PRE_at', 'PRE_ate', 'SUF_ó', 'SUF_ió', 'SUF_dió', 'anterior1_men_NC', 'anterior2_El_DA', 'posterior1_a_SP', 'posterior2_la_DA', 'WORD_atendió']\n",
      "Token: a, Features: ['anterior1_atendió_VMI', 'anterior2_men_NC', 'posterior1_la_DA', 'posterior2_reunión_NC', 'WORD_a']\n",
      "Token: la, Features: ['PRE_l', 'SUF_a', 'anterior1_a_SP', 'anterior2_atendió_VMI', 'posterior1_reunión_NC', 'WORD_la']\n",
      "Token: reunión, Features: ['PRE_r', 'PRE_re', 'PRE_reu', 'SUF_n', 'SUF_ón', 'SUF_ión', 'anterior1_la_DA', 'anterior2_a_SP', 'WORD_reunión']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "            - longitud\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "        token = tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "            \n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"SUF_\" + token[-3:])\n",
    "        \n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        feature_list.append(\"WORD_\" + token)\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "# Ejemplo de uso:\n",
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "tokens = ['El', 'men', 'atendió', 'a', 'la', 'reunión']\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    features = feature_extractor._get_features(tokens, i)\n",
    "    print(f\"Token: {token}, Features: {features}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
