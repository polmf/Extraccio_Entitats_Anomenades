{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install python-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pycrfsuite\n",
    "from nltk.corpus import conll2002\n",
    "from nltk.tag import CRFTagger\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # Tokenitzador\n",
    "nltk.download('averaged_perceptron_tagger') # Etiquetador POS\n",
    "nltk.download('maxent_ne_chunker') # Etiquetador Entitats Anomenades\n",
    "nltk.download('words')\n",
    "nltk.download('treebank')\n",
    "nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_esp = conll2002.iob_sents('esp.train') # Train, ned.train => Neerlandès\n",
    "testa_esp = conll2002.iob_sents('esp.testa') # Dev\n",
    "testb_esp = conll2002.iob_sents('esp.testb') # Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ned = conll2002.iob_sents('ned.train') # Train, ned.train => Neerlandès\n",
    "testa_ned = conll2002.iob_sents('ned.testa') # Dev\n",
    "testb_ned = conll2002.iob_sents('ned.testb') # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicció amb BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Espanyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tagger = CRFTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447121289420479\n"
     ]
    }
   ],
   "source": [
    "# Entrenem el model per predir els POS que corresponen a cada token\n",
    "\n",
    "train_esp_pos_tag = []\n",
    "for sentence in train_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem2))\n",
    "    train_esp_pos_tag.append(frases)\n",
    "    \n",
    "model_tagger.train(train_esp_pos_tag, 'model_POS.crf.tagger')\n",
    "\n",
    "\n",
    "# Fem prediccions i mirem l'accuracy\n",
    "\n",
    "testa_esp_pre_tag = []\n",
    "for sentence in testa_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append(elem1)\n",
    "    testa_esp_pre_tag.append(frases)\n",
    "    \n",
    "predicted = model_tagger.tag_sents(testa_esp_pre_tag)\n",
    "\n",
    "predictions = [elem[1] for sentence in predicted for elem in sentence]\n",
    "real_label = [elem[1] for sentence in testa_esp for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions, real_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "\n",
    "class FeatureExtractor2:\n",
    "    def __init__(self, use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False, pattern = r'\\d+'):\n",
    "        self.use_basic_features = use_basic_features\n",
    "        self.use_prefix_suffix_features = use_prefix_suffix_features\n",
    "        self.use_context_features = use_context_features\n",
    "        self._pattern = pattern\n",
    "        self.feature_list = []\n",
    "\n",
    "    def _extract_basic_features(self, token):\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            self.feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            self.feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            self.feature_list.append(\"PUNCTUATION\")\n",
    "\n",
    "    def _extract_prefix_suffix_features(self, token):\n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            self.feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            self.feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            self.feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            self.feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            self.feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            self.feature_list.append(\"SUF_\" + token[-3:])\n",
    "\n",
    "    def _extract_context_features(self, token, tokens, idx):\n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            self.feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            self.feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            self.feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            self.feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        self.feature_list.append(\"WORD_\" + token)\n",
    "    \n",
    "    def _get_features(self, tokens, idx):\n",
    "        token = tokens[idx]\n",
    "        feature_list = []\n",
    "        \n",
    "        if self.use_basic_features:\n",
    "            self._extract_basic_features(token)\n",
    "                    \n",
    "        if self.use_prefix_suffix_features:\n",
    "            self._extract_prefix_suffix_features(token)\n",
    "        \n",
    "        if self.use_context_features:\n",
    "            self._extract_context_features(token, tokens, idx)\n",
    "            \n",
    "        \n",
    "        return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_BIO_tag = []\n",
    "for sentence in train_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    train_esp_BIO_tag.append(frases)\n",
    "    \n",
    "model_BIO = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIO.train(train_esp_BIO_tag, 'model_BIO.crf.tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span> Features que es tenen en compte:\n",
    "<ul>\n",
    "    <li>Paraula actual</li>\n",
    "    <li>Si comença en majúscula</li>\n",
    "    <li>Si té signe de puntuació</li>\n",
    "    <li>Si té números</li>\n",
    "    <li>Prefixos fins a longitud 3</li>\n",
    "    <li>Sufixos fins a longitud 3</li>\n",
    "    <li>Paraules prèvies i posteriors amb POS</li>\n",
    "    <li>POS-tags</li>\n",
    "    <li>Longitud de la paraula</li>\n",
    "</ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "            - longitud\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "        token = tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "            \n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"SUF_\" + token[-3:])\n",
    "        \n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        feature_list.append(\"WORD_\" + token)\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "# Crear una instancia de FeatureExtractor\n",
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_BIO_tag1 = []\n",
    "for sentence in train_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    train_esp_BIO_tag1.append(frases)\n",
    "    \n",
    "model_BIO = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIO.train(train_esp_BIO_tag1, 'model_BIO.crf.tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utilitzem aquest accuracy per ajustar els features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9580711599871511\n"
     ]
    }
   ],
   "source": [
    "testa_esp_BIO_tag = []\n",
    "for sentence in testa_esp:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    testa_esp_BIO_tag.append(frases)\n",
    "\n",
    "predicted_BIO = model_BIO.tag_sents(testa_esp_pre_tag)\n",
    "\n",
    "predictions_BIO = [elem[1] for sentence in predicted_BIO for elem in sentence]\n",
    "real_label_BIO = [elem[1] for sentence in testa_esp_BIO_tag for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions_BIO, real_label_BIO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reconeixem entitats i avaluem la detecció d'entitats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "entitats_reals_testa_esp = []\n",
    "\n",
    "for sentence in testa_esp_BIO_tag:\n",
    "    ent = []\n",
    "    name = None\n",
    "    prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "    \n",
    "    for token in sentence:\n",
    "        word, tag = token\n",
    "        \n",
    "        if tag.startswith('B-'):\n",
    "            # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "            if ent:\n",
    "                entitats_reals_testa_esp.append((tuple(ent), name))\n",
    "            # Creamos una nueva entidad con la palabra actual\n",
    "            ent = [word]\n",
    "            # Obtenemos el tipo de entidad\n",
    "            name = tag.split('-')[1]\n",
    "            prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag.startswith('I-'):\n",
    "            # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "            if prev_tag:\n",
    "                ent.append(word)\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag == 'O' and ent:\n",
    "            # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "            entitats_reals_testa_esp.append((tuple(ent), name))\n",
    "            # Reiniciamos la lista de la entidad actual\n",
    "            ent = []\n",
    "            prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "    # Agregamos la última entidad si la hay\n",
    "    if ent:\n",
    "        entitats_reals_testa_esp.append((tuple(ent), name))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_BIO = model_BIO.tag_sents(testa_esp_pre_tag)\n",
    "\n",
    "entitats_predites_testa_esp = []\n",
    "\n",
    "for sentence in predicted_BIO:\n",
    "    ent = []\n",
    "    name = None\n",
    "    prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "    \n",
    "    for token in sentence:\n",
    "        word, tag = token\n",
    "        \n",
    "        if tag.startswith('B-'):\n",
    "            # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "            if ent:\n",
    "                entitats_predites_testa_esp.append((tuple(ent), name))\n",
    "            # Creamos una nueva entidad con la palabra actual\n",
    "            ent = [word]\n",
    "            # Obtenemos el tipo de entidad\n",
    "            name = tag.split('-')[1]\n",
    "            prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag.startswith('I-'):\n",
    "            # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "            if prev_tag:\n",
    "                ent.append(word)\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag == 'O' and ent:\n",
    "            # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "            entitats_predites_testa_esp.append((tuple(ent), name))\n",
    "            # Reiniciamos la lista de la entidad actual\n",
    "            ent = []\n",
    "            prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "    # Agregamos la última entidad si la hay\n",
    "    if ent:\n",
    "        entitats_predites_testa_esp.append((tuple(ent), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.7747644219719605\n",
      "Precision: 0.8156302927655457\n",
      "F-score: 0.7946723243752947\n"
     ]
    }
   ],
   "source": [
    "### AVALUEM ###\n",
    "encerts = 0\n",
    "for entitat in entitats_predites_testa_esp:\n",
    "    if entitat in entitats_reals_testa_esp:\n",
    "        encerts += 1\n",
    "\n",
    "total_entitats_reals = len(entitats_reals_testa_esp)\n",
    "total_entitats_predites = len(entitats_predites_testa_esp)\n",
    "\n",
    "recall = encerts / total_entitats_reals\n",
    "\n",
    "if total_entitats_predites != 0:\n",
    "    precision = encerts / total_entitats_predites\n",
    "    f_score = (2 * precision * recall) / (precision + recall)\n",
    "else:\n",
    "    precision = 0\n",
    "    f_score = 0\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F-score:\", f_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neerlandès"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tagger = CRFTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940191577997718\n"
     ]
    }
   ],
   "source": [
    "# Entrenem el model per predir els POS que corresponen a cada token\n",
    "\n",
    "train_ned_pos_tag = []\n",
    "for sentence in train_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem2))\n",
    "    train_ned_pos_tag.append(frases)\n",
    "    \n",
    "model_tagger.train(train_ned_pos_tag, 'model_POS.crf.tagger')\n",
    "\n",
    "\n",
    "# Fem prediccions i mirem l'accuracy\n",
    "\n",
    "testa_ned_pre_tag = []\n",
    "for sentence in testa_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append(elem1)\n",
    "    testa_ned_pre_tag.append(frases)\n",
    "    \n",
    "predicted = model_tagger.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "predictions = [elem[1] for sentence in predicted for elem in sentence]\n",
    "real_label = [elem[1] for sentence in testa_ned for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions, real_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "            - longitud\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "        token = tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "            \n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"SUF_\" + token[-3:])\n",
    "        \n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        feature_list.append(\"WORD_\" + token)\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "# Crear una instancia de FeatureExtractor\n",
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_BIO_tag = []\n",
    "for sentence in train_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    train_ned_BIO_tag.append(frases)\n",
    "    \n",
    "model_BIO = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIO.train(train_ned_BIO_tag, 'model_BIO.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9683975906811367\n"
     ]
    }
   ],
   "source": [
    "testa_ned_BIO_tag = []\n",
    "for sentence in testa_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    testa_ned_BIO_tag.append(frases)\n",
    "\n",
    "predicted_BIO = model_BIO.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "predictions_BIO = [elem[1] for sentence in predicted_BIO for elem in sentence]\n",
    "real_label_BIO = [elem[1] for sentence in testa_ned_BIO_tag for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions_BIO, real_label_BIO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "entitats_reals_testa_ned = []\n",
    "\n",
    "for sentence in testa_ned_BIO_tag:\n",
    "    ent = []\n",
    "    name = None\n",
    "    prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "    \n",
    "    for token in sentence:\n",
    "        word, tag = token\n",
    "        \n",
    "        if tag.startswith('B-'):\n",
    "            # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "            if ent:\n",
    "                entitats_reals_testa_ned.append((tuple(ent), name))\n",
    "            # Creamos una nueva entidad con la palabra actual\n",
    "            ent = [word]\n",
    "            # Obtenemos el tipo de entidad\n",
    "            name = tag.split('-')[1]\n",
    "            prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag.startswith('I-'):\n",
    "            # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "            if prev_tag:\n",
    "                ent.append(word)\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag == 'O' and ent:\n",
    "            # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "            entitats_reals_testa_ned.append((tuple(ent), name))\n",
    "            # Reiniciamos la lista de la entidad actual\n",
    "            ent = []\n",
    "            prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "    # Agregamos la última entidad si la hay\n",
    "    if ent:\n",
    "        entitats_reals_testa_ned.append((tuple(ent), name))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_BIO = model_BIO.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "entitats_predites_testa_ned = []\n",
    "\n",
    "for sentence in predicted_BIO:\n",
    "    ent = []\n",
    "    name = None\n",
    "    prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "    \n",
    "    for token in sentence:\n",
    "        word, tag = token\n",
    "        \n",
    "        if tag.startswith('B-'):\n",
    "            # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "            if ent:\n",
    "                entitats_predites_testa_ned.append((tuple(ent), name))\n",
    "            # Creamos una nueva entidad con la palabra actual\n",
    "            ent = [word]\n",
    "            # Obtenemos el tipo de entidad\n",
    "            name = tag.split('-')[1]\n",
    "            prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag.startswith('I-'):\n",
    "            # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "            if prev_tag:\n",
    "                ent.append(word)\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag == 'O' and ent:\n",
    "            # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "            entitats_predites_testa_ned.append((tuple(ent), name))\n",
    "            # Reiniciamos la lista de la entidad actual\n",
    "            ent = []\n",
    "            prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "    # Agregamos la última entidad si la hay\n",
    "    if ent:\n",
    "        entitats_predites_testa_ned.append((tuple(ent), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.6788990825688074\n",
      "Precision: 0.7477894736842106\n",
      "F-score: 0.7116810258465238\n"
     ]
    }
   ],
   "source": [
    "### AVALUEM ###\n",
    "encerts = 0\n",
    "for entitat in entitats_predites_testa_ned:\n",
    "    if entitat in entitats_reals_testa_ned:\n",
    "        encerts += 1\n",
    "\n",
    "total_entitats_reals = len(entitats_reals_testa_ned)\n",
    "total_entitats_predites = len(entitats_predites_testa_ned)\n",
    "\n",
    "recall = encerts / total_entitats_reals\n",
    "\n",
    "if total_entitats_predites != 0:\n",
    "    precision = encerts / total_entitats_predites\n",
    "    f_score = (2 * precision * recall) / (precision + recall)\n",
    "else:\n",
    "    precision = 0\n",
    "    f_score = 0\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F-score:\", f_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicció amb IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_io(train_data_bio):\n",
    "    train_data_io = []\n",
    "    for sentence in train_data_bio:\n",
    "        io_tags = []\n",
    "        for word, pos_tag, bio_tag in sentence:\n",
    "            if bio_tag == 'O':\n",
    "                io_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                io_tags.append('I' + bio_tag[1:])\n",
    "            else:\n",
    "                io_tags.append(bio_tag)\n",
    "                \n",
    "        train_data_io.append(list(zip([word for word, pos_tag, bio_tag in sentence], io_tags)))\n",
    "    return train_data_io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espanyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 50064\n",
      "Precisió d'entitats: 94.59781191542429 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testa_esp)\n",
    "prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_IO_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format IO\n",
    "    dades_prova = convert_to_io(testa_esp)\n",
    "    prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testb_esp)\n",
    "prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IO NED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_pre_IO = convert_to_io(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_ned.train(train_ned_pre_IO, 'model_io.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 36539\n",
      "Precisió d'entitats: 96.95385676758565 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testa_ned)\n",
    "prediccions = model_IO_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_ned_pre_IO = convert_to_io(train_ned)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_IO_esp.train(train_ned_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format IO\n",
    "    dades_prova = convert_to_io(testa_ned)\n",
    "    prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_ned_pre_IO = convert_to_io(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_ned.train(train_ned_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testb_ned)\n",
    "prediccions = model_IO_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_biow(train_data_bio):\n",
    "    train_data_biow = []\n",
    "    for sentence in train_data_bio:\n",
    "        biow_tags = []\n",
    "        for word, pos_tag, bio_tag in sentence:\n",
    "            if bio_tag == 'O':\n",
    "                biow_tags.append('O')\n",
    "            else:\n",
    "                biow_tags.append(bio_tag + 'W')  # Añadir 'W' a todas las etiquetas\n",
    "            \n",
    "        train_data_biow.append(list(zip([word for word, pos_tag, bio_tag in sentence], biow_tags)))\n",
    "    return train_data_biow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_pre_BIOW = convert_to_biow(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_esp.train(train_esp_pre_BIOW, 'model_biow.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 50166\n",
      "Precisió d'entitats: 94.79054475369877 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testa_esp)\n",
    "prediccions = model_BIOW_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_esp_pre_BIOW = convert_to_biow(train_esp)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema BIOW\n",
    "    model_BIOW_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOW_esp.train(train_esp_pre_IO, 'model_biow.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format BIOW\n",
    "    dades_prova = convert_to_biow(testa_esp)\n",
    "    prediccions = model_BIOW_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_pre_BIOW = convert_to_biow(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_esp.train(train_esp_pre_BIOW, 'model_biow.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testb_esp)\n",
    "prediccions = model_BIOW_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_pre_BIOW = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_ned.train(train_ned_pre_BIOW, 'model_biow.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 36486\n",
      "Precisió d'entitats: 96.81322471939926 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testa_ned)\n",
    "prediccions = model_BIOW_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_ned_pre_BIOW = convert_to_biow(train_ned)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_BIOW_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOW_ned.train(train_ned_pre_IO, 'model_biow.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format BIOW\n",
    "    dades_prova = convert_to_biow(testa_ned)\n",
    "    prediccions = model_BIOW_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_ned_pre_BIOW = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_ned.train(train_ned_pre_BIOW, 'model_biow.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testb_ned)\n",
    "prediccions = model_BIOW_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIOES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bioes(train_data_bio):\n",
    "    train_data_bioes = []\n",
    "    for sentence in train_data_bio:\n",
    "        bioes_tags = []\n",
    "        for i, (word, pos_tag, bio_tag) in enumerate(sentence):\n",
    "            if bio_tag == 'O':\n",
    "                bioes_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][2] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('S' + bio_tag[1:])  # Single\n",
    "                else:\n",
    "                    bioes_tags.append('B' + bio_tag[1:])  # Begin\n",
    "            elif bio_tag.startswith('I-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][2] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('E' + bio_tag[1:])  # End\n",
    "                else:\n",
    "                    bioes_tags.append('I' + bio_tag[1:])  # Inside\n",
    "            else:\n",
    "                raise ValueError(\"Etiqueta BIO incorrecta: {}\".format(bio_tag))\n",
    "                \n",
    "        train_data_bioes.append(list(zip([word for word, pos_tag, bio_tag in sentence], bioes_tags)))\n",
    "    return train_data_bioes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_pre_BIOES = convert_to_bioes(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_esp.train(train_esp_pre_BIOW, 'model_bioes.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 44792\n",
      "Precisió d'entitats: 84.63616952931618 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testa_esp)\n",
    "prediccions = model_BIOES_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_esp_pre_BIOES = convert_to_bioes(train_esp)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOES_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format IO\n",
    "    dades_prova = convert_to_bioes(testa_esp)\n",
    "    prediccions = model_BIOES_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_pre_BIOES = convert_to_bioes(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_esp.train(train_esp_pre_BIOW, 'model_bioes.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testb_esp)\n",
    "prediccions = model_BIOES_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_pre_BIOES = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_ned.train(train_ned_pre_BIOES, 'model_bioes.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33903\n",
      "Precisió d'entitats: 89.95940244646695 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testa_ned)\n",
    "prediccions = model_BIOES_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_ned_pre_BIOES = convert_to_bioes(train_ned)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOES_ned.train(train_ned_pre_IO, 'model_biow.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format BIOES\n",
    "    dades_prova = convert_to_bioes(testa_ned)\n",
    "    prediccions = model_BIOES_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_ned_pre_BIOES = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_ned.train(train_ned_pre_BIOES, 'model_bioes.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testb_ned)\n",
    "prediccions = model_BIOES_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mark', 'B-PER'),\n",
       " ('Pedersen', 'I-PER'),\n",
       " ('treballa', 'O'),\n",
       " ('a', 'B-PER'),\n",
       " ('Google', 'I-PER'),\n",
       " ('des', 'O'),\n",
       " ('del', 'O'),\n",
       " ('1994', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BIO.tag(nltk.word_tokenize(\"Mark Pedersen treballa a Google des del 1994.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_IO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_IO\u001b[49m\u001b[38;5;241m.\u001b[39mtag(nltk\u001b[38;5;241m.\u001b[39mword_tokenize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMark Pedersen treballa a Google des del 1994.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_IO' is not defined"
     ]
    }
   ],
   "source": [
    "model_IO.tag(nltk.word_tokenize(\"Mark Pedersen treballa a Google des del 1994.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaluació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459214330253387"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaluació mal feta, contant només quants tokens són correctes, i no les entitats correctes.\n",
    "model.accuracy(testa_esp_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaluació ben feta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hem d'avaluar quantes entitats estan reconegudes correctament, no quants tokens son correctes.\n",
    "Descodificar la sequencia i obtenir les entitats, i doncs avaluar les entitats.\n",
    "Per exemple, 'Mark Pedersen Romero' --> 'M P R' (una entitat) per BIO; 'M' i 'P R' (dos entitats) per IO; en aquest exemple IO ho fa malament.\n",
    "\n",
    "A nivell d'entitats: Recall i f-score\n",
    "\n",
    "Per avaluar el model avaluem en base a recall i precisio parcial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple d'ús CRFTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: El, Features: ['CAPITALIZATION', 'PRE_E', 'SUF_l', 'posterior1_men_NC', 'posterior2_atendió_VMI', 'WORD_El']\n",
      "Token: men, Features: ['PRE_m', 'PRE_me', 'SUF_n', 'SUF_en', 'anterior1_El_DA', 'posterior1_atendió_VMI', 'posterior2_a_SP', 'WORD_men']\n",
      "Token: atendió, Features: ['PRE_a', 'PRE_at', 'PRE_ate', 'SUF_ó', 'SUF_ió', 'SUF_dió', 'anterior1_men_NC', 'anterior2_El_DA', 'posterior1_a_SP', 'posterior2_la_DA', 'WORD_atendió']\n",
      "Token: a, Features: ['anterior1_atendió_VMI', 'anterior2_men_NC', 'posterior1_la_DA', 'posterior2_reunión_NC', 'WORD_a']\n",
      "Token: la, Features: ['PRE_l', 'SUF_a', 'anterior1_a_SP', 'anterior2_atendió_VMI', 'posterior1_reunión_NC', 'WORD_la']\n",
      "Token: reunión, Features: ['PRE_r', 'PRE_re', 'PRE_reu', 'SUF_n', 'SUF_ón', 'SUF_ión', 'anterior1_la_DA', 'anterior2_a_SP', 'WORD_reunión']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "            - longitud\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "        token = tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "            \n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"SUF_\" + token[-3:])\n",
    "        \n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        feature_list.append(\"WORD_\" + token)\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "# Ejemplo de uso:\n",
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "tokens = ['El', 'men', 'atendió', 'a', 'la', 'reunión']\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    features = feature_extractor._get_features(tokens, i)\n",
    "    print(f\"Token: {token}, Features: {features}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
