{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pràctica 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install python-crfsuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pycrfsuite\n",
    "from nltk.corpus import conll2002\n",
    "from nltk.tag import CRFTagger\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # Tokenitzador\n",
    "nltk.download('averaged_perceptron_tagger') # Etiquetador POS\n",
    "nltk.download('maxent_ne_chunker') # Etiquetador Entitats Anomenades\n",
    "nltk.download('words')\n",
    "nltk.download('treebank')\n",
    "nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_esp = conll2002.iob_sents('esp.train') # Train, ned.train => Neerlandès\n",
    "testa_esp = conll2002.iob_sents('esp.testa') # Dev\n",
    "testb_esp = conll2002.iob_sents('esp.testb') # Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ned = conll2002.iob_sents('ned.train') # Train, ned.train => Neerlandès\n",
    "testa_ned = conll2002.iob_sents('ned.testa') # Dev\n",
    "testb_ned = conll2002.iob_sents('ned.testb') # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicció amb BIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Espanyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tagger_POS = CRFTagger()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Començament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447121289420479\n"
     ]
    }
   ],
   "source": [
    "# Entrenem el model per predir els POS que corresponen a cada token\n",
    "\n",
    "def obtener_token_POS(fitxer):\n",
    "    res = []\n",
    "    for sentence in fitxer:\n",
    "        frases = []\n",
    "        for elem1, elem2, elem3 in sentence:\n",
    "            frases.append((elem1, elem2))\n",
    "        res.append(frases)\n",
    "    return res\n",
    "\n",
    "train_esp_pos_tag = obtener_token_POS(train_esp)\n",
    "    \n",
    "model_tagger_POS.train(train_esp_pos_tag, 'model_POS.crf.tagger')\n",
    "\n",
    "\n",
    "# Fem prediccions i mirem l'accuracy\n",
    "def obtener_token(fitxer):\n",
    "    res = []\n",
    "    for sentence in fitxer:\n",
    "        frases = []\n",
    "        for elem1, elem2, elem3 in sentence:\n",
    "            frases.append(elem1)\n",
    "        res.append(frases)\n",
    "    return res\n",
    "\n",
    "def obtener_token_BIO(fitxer):\n",
    "    res = []\n",
    "    for sentence in fitxer:\n",
    "        frases = []\n",
    "        for elem1, elem2, elem3 in sentence:\n",
    "            frases.append((elem1, elem3))\n",
    "        res.append(frases)\n",
    "    return res    \n",
    "\n",
    "\n",
    "testa_esp_pre_tag = obtener_token(testa_esp)\n",
    "    \n",
    "predicted = model_tagger_POS.tag_sents(testa_esp_pre_tag)\n",
    "\n",
    "predictions = [elem[1] for sentence in predicted for elem in sentence]\n",
    "real_label = [elem[1] for sentence in testa_esp for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions, real_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaluació amb sets veure si son iguals també es pot mirar per intersecció i si coincideixen\n",
    "def obtener_entidades_con_posiciones_prova(testa_esp_BIO_tag):\n",
    "    entitats_con_posiciones = set()\n",
    "\n",
    "    for sentence_index, sentence in enumerate(testa_esp_BIO_tag):\n",
    "        ent = []\n",
    "        name = None\n",
    "        start_pos = None  # Posición de inicio de la entidad actual\n",
    "        prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "\n",
    "        for token_index, token in enumerate(sentence):\n",
    "            word, tag = token\n",
    "            #word = word[0]\n",
    "\n",
    "            if tag.startswith('B-'):\n",
    "                # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "                if ent:\n",
    "                    end_pos = token_index - 1  # La posición de fin es el token anterior\n",
    "                    entitats_con_posiciones.add((tuple(ent), (start_pos, end_pos), name))\n",
    "                # Creamos una nueva entidad con la palabra actual\n",
    "                ent = [word]\n",
    "                # Obtenemos el tipo de entidad\n",
    "                name = tag.split('-')[1]\n",
    "                start_pos = token_index  # La posición de inicio es el token actual\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "            elif tag.startswith('I-'):\n",
    "                # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "                if prev_tag:\n",
    "                    ent.append(word)\n",
    "                    prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "            elif tag == 'O' and ent:\n",
    "                # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "                end_pos = token_index - 1  # La posición de fin es el token anterior\n",
    "                entitats_con_posiciones.add((tuple(ent), (start_pos, end_pos), name))\n",
    "                # Reiniciamos la lista de la entidad actual\n",
    "                ent = []\n",
    "                prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "        # Agregamos la última entidad si la hay\n",
    "        if ent:\n",
    "            end_pos = len(sentence) - 1  # La posición de fin es el último token de la oración\n",
    "            entitats_con_posiciones.add((tuple(ent), (start_pos, end_pos)))\n",
    "\n",
    "    return entitats_con_posiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False, pattern = r'\\d+'):\n",
    "        self.use_basic_features = use_basic_features\n",
    "        self.use_prefix_suffix_features = use_prefix_suffix_features\n",
    "        self.use_context_features = use_context_features\n",
    "        self._pattern = pattern\n",
    "        \n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "            - longitud\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "            \n",
    "        token = tokens[idx]\n",
    "        \n",
    "        feature_list = []\n",
    "        \n",
    "        if self.use_basic_features:\n",
    "            # Capitalization\n",
    "            if token[0].isupper():\n",
    "                feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "            # Number\n",
    "            if re.search(self._pattern, token) is not None:\n",
    "                feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "            # Punctuation\n",
    "            punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "            if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "                feature_list.append(\"PUNCTUATION\")\n",
    "                    \n",
    "        if self.use_prefix_suffix_features:\n",
    "            # preffix up to length 3\n",
    "            if len(token) > 1:\n",
    "                feature_list.append(\"PRE_\" + token[:1])\n",
    "            if len(token) > 2:\n",
    "                feature_list.append(\"PRE_\" + token[:2])\n",
    "            if len(token) > 3:\n",
    "                feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "            # Suffix up to length 3\n",
    "            if len(token) > 1:\n",
    "                feature_list.append(\"SUF_\" + token[-1:])\n",
    "            if len(token) > 2:\n",
    "                feature_list.append(\"SUF_\" + token[-2:])\n",
    "            if len(token) > 3:\n",
    "                feature_list.append(\"SUF_\" + token[-3:])\n",
    "    \n",
    "        \n",
    "        if self.use_context_features:\n",
    "            # POS_tags\n",
    "            POS = model_tagger_POS.tag(tokens)\n",
    "                \n",
    "            # Paraules prèvies amb POS\n",
    "            if idx > 0:\n",
    "                feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "            if idx > 1:\n",
    "                feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "                \n",
    "            # Paraules posteriors amb POS\n",
    "            if idx < (len(tokens)-1):\n",
    "                feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "            if idx < (len(tokens)-2):\n",
    "                feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "            feature_list.append(\"WORD_\" + token)\n",
    "            \n",
    "        \n",
    "        return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_precision(entidades_referencia, entidades_extraidas):\n",
    "    # Calcular el número de entidades correctamente extraídas\n",
    "    entidades_correctas = entidades_referencia.intersection(entidades_extraidas)\n",
    "    \n",
    "    # Calcular la precisión\n",
    "    if len(entidades_extraidas) > 0:\n",
    "        precision = len(entidades_correctas) / len(entidades_extraidas)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "    \n",
    "    return precision\n",
    "\n",
    "\n",
    "def calcular_exhaustividad(entidades_referencia, entidades_extraidas):\n",
    "    # Calcular el número de entidades correctamente extraídas\n",
    "    entidades_correctas = entidades_referencia.intersection(entidades_extraidas)\n",
    "    \n",
    "    # Calcular la exhaustividad\n",
    "    if len(entidades_referencia) > 0:\n",
    "        exhaustividad = len(entidades_correctas) / len(entidades_referencia)\n",
    "    else:\n",
    "        exhaustividad = 0.0\n",
    "    \n",
    "    return exhaustividad\n",
    "\n",
    "def calcular_f1_score(precision, exhaustividad):\n",
    "    # Calcular el F1-score\n",
    "    if (precision + exhaustividad) > 0:\n",
    "        f1_score = 2 * (precision * exhaustividad) / (precision + exhaustividad)\n",
    "    else:\n",
    "        f1_score = 0.0\n",
    "    \n",
    "    return f1_score\n",
    "\n",
    "def resultats(predicted_BIO, testa_esp_BIO_tag):\n",
    "\n",
    "    # Obtener los conjuntos de entidades de referencia y extraídas\n",
    "    entidades_referencia = obtener_entidades_con_posiciones_prova(testa_esp_BIO_tag)  # Conjunto de entidades etiquetadas manualmente como referencia\n",
    "    entidades_extraidas =  obtener_entidades_con_posiciones_prova(predicted_BIO) # Obtener conjuntos de entidades extraídas\n",
    "\n",
    "    # Calcular la precisión\n",
    "    precision = calcular_precision(entidades_referencia, entidades_extraidas)\n",
    "\n",
    "    # Calcular la exhaustividad\n",
    "    exhaustividad = calcular_exhaustividad(entidades_referencia, entidades_extraidas)\n",
    "\n",
    "    # Calcular el F1-score\n",
    "    f1_score = calcular_f1_score(precision, exhaustividad)\n",
    "\n",
    "    print(\"Precisión:\", precision)\n",
    "    print(\"Exhaustividad:\", exhaustividad)\n",
    "    print(\"F1-score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span> Features que es tenen en compte:\n",
    "<ul>\n",
    "    <li>Paraula actual</li>\n",
    "    <li>Si comença en majúscula</li>\n",
    "    <li>Si té signe de puntuació</li>\n",
    "    <li>Si té números</li>\n",
    "    <li>Prefixos fins a longitud 3</li>\n",
    "    <li>Sufixos fins a longitud 3</li>\n",
    "    <li>Paraules prèvies i posteriors amb POS</li>\n",
    "    <li>POS-tags</li>\n",
    "    <li>Longitud de la paraula</li>\n",
    "</ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "si\n",
      "Precisión: 0.39166666666666666\n",
      "Exhaustividad: 0.3643410852713178\n",
      "F1-score: 0.37751004016064255\n",
      "fi\n",
      "\n",
      "si\n",
      "Precisión: 0.6701492537313433\n",
      "Exhaustividad: 0.6215393133997785\n",
      "F1-score: 0.6449296179258833\n",
      "fi\n",
      "\n",
      "si\n",
      "Precisión: 0.7519742614799649\n",
      "Exhaustividad: 0.7117940199335548\n",
      "F1-score: 0.7313326696060305\n",
      "fi\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "param_combinations = [\n",
    "    FeatureExtractor(True),\n",
    "    FeatureExtractor(True, True),\n",
    "    FeatureExtractor(True, True, True)\n",
    "]\n",
    "\n",
    "train_esp_BIO = obtener_token_BIO(train_esp)\n",
    "\n",
    "testa_esp_real = obtener_token_BIO(testa_esp)\n",
    "\n",
    "def model_entrenament(train_esp_BIO_tag, extractor, testa_esp_pre_tag):\n",
    "    \n",
    "    model_BIO = CRFTagger(feature_func=extractor._get_features)\n",
    "    model_BIO.train(train_esp_BIO_tag, 'model_BIO.crf.tagger')\n",
    "    \n",
    "    predicted_BIO = model_BIO.tag_sents(testa_esp_pre_tag)\n",
    "    \n",
    "    return resultats(predicted_BIO, testa_esp_real)\n",
    "\n",
    "for param in param_combinations:\n",
    "    model_entrenament(train_esp_BIO, param, testa_esp_pre_tag)\n",
    "    print('fi\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neerlandès"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tagger = CRFTagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940191577997718\n"
     ]
    }
   ],
   "source": [
    "# Entrenem el model per predir els POS que corresponen a cada token\n",
    "\n",
    "train_ned_pos_tag = []\n",
    "for sentence in train_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem2))\n",
    "    train_ned_pos_tag.append(frases)\n",
    "    \n",
    "model_tagger.train(train_ned_pos_tag, 'model_POS.crf.tagger')\n",
    "\n",
    "\n",
    "# Fem prediccions i mirem l'accuracy\n",
    "\n",
    "testa_ned_pre_tag = []\n",
    "for sentence in testa_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append(elem1)\n",
    "    testa_ned_pre_tag.append(frases)\n",
    "    \n",
    "predicted = model_tagger.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "predictions = [elem[1] for sentence in predicted for elem in sentence]\n",
    "real_label = [elem[1] for sentence in testa_ned for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions, real_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import CRFTagger\n",
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "            - longitud\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "        token = tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "            \n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"SUF_\" + token[-3:])\n",
    "        \n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        feature_list.append(\"WORD_\" + token)\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "# Crear una instancia de FeatureExtractor\n",
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_BIO_tag = []\n",
    "for sentence in train_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    train_ned_BIO_tag.append(frases)\n",
    "    \n",
    "model_BIO = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIO.train(train_ned_BIO_tag, 'model_BIO.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9683975906811367\n"
     ]
    }
   ],
   "source": [
    "testa_ned_BIO_tag = []\n",
    "for sentence in testa_ned:\n",
    "    frases = []\n",
    "    for elem1, elem2, elem3 in sentence:\n",
    "        frases.append((elem1, elem3))\n",
    "    testa_ned_BIO_tag.append(frases)\n",
    "\n",
    "predicted_BIO = model_BIO.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "predictions_BIO = [elem[1] for sentence in predicted_BIO for elem in sentence]\n",
    "real_label_BIO = [elem[1] for sentence in testa_ned_BIO_tag for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions_BIO, real_label_BIO))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "entitats_reals_testa_ned = []\n",
    "\n",
    "for sentence in testa_ned_BIO_tag:\n",
    "    ent = []\n",
    "    name = None\n",
    "    prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "    \n",
    "    for token in sentence:\n",
    "        word, tag = token\n",
    "        \n",
    "        if tag.startswith('B-'):\n",
    "            # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "            if ent:\n",
    "                entitats_reals_testa_ned.append((tuple(ent), name))\n",
    "            # Creamos una nueva entidad con la palabra actual\n",
    "            ent = [word]\n",
    "            # Obtenemos el tipo de entidad\n",
    "            name = tag.split('-')[1]\n",
    "            prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag.startswith('I-'):\n",
    "            # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "            if prev_tag:\n",
    "                ent.append(word)\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag == 'O' and ent:\n",
    "            # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "            entitats_reals_testa_ned.append((tuple(ent), name))\n",
    "            # Reiniciamos la lista de la entidad actual\n",
    "            ent = []\n",
    "            prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "    # Agregamos la última entidad si la hay\n",
    "    if ent:\n",
    "        entitats_reals_testa_ned.append((tuple(ent), name))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_BIO = model_BIO.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "entitats_predites_testa_ned = []\n",
    "\n",
    "for sentence in predicted_BIO:\n",
    "    ent = []\n",
    "    name = None\n",
    "    prev_tag = None  # Almacenar la etiqueta del token anterior\n",
    "    \n",
    "    for token in sentence:\n",
    "        word, tag = token\n",
    "        \n",
    "        if tag.startswith('B-'):\n",
    "            # Si hay una entidad anterior, la agregamos a la lista de entidades\n",
    "            if ent:\n",
    "                entitats_predites_testa_ned.append((tuple(ent), name))\n",
    "            # Creamos una nueva entidad con la palabra actual\n",
    "            ent = [word]\n",
    "            # Obtenemos el tipo de entidad\n",
    "            name = tag.split('-')[1]\n",
    "            prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag.startswith('I-'):\n",
    "            # Solo agregamos la palabra actual si el token anterior tiene etiqueta I- o B-\n",
    "            if prev_tag:\n",
    "                ent.append(word)\n",
    "                prev_tag = tag  # Actualizamos la etiqueta del token anterior\n",
    "        elif tag == 'O' and ent:\n",
    "            # Si encontramos una etiqueta 'O' y hay una entidad en curso, la agregamos a la lista de entidades\n",
    "            entitats_predites_testa_ned.append((tuple(ent), name))\n",
    "            # Reiniciamos la lista de la entidad actual\n",
    "            ent = []\n",
    "            prev_tag = None  # Reiniciamos la etiqueta del token anterior\n",
    "\n",
    "    # Agregamos la última entidad si la hay\n",
    "    if ent:\n",
    "        entitats_predites_testa_ned.append((tuple(ent), name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.6788990825688074\n",
      "Precision: 0.7477894736842106\n",
      "F-score: 0.7116810258465238\n"
     ]
    }
   ],
   "source": [
    "### AVALUEM ###\n",
    "encerts = 0\n",
    "for entitat in entitats_predites_testa_ned:\n",
    "    if entitat in entitats_reals_testa_ned:\n",
    "        encerts += 1\n",
    "\n",
    "total_entitats_reals = len(entitats_reals_testa_ned)\n",
    "total_entitats_predites = len(entitats_predites_testa_ned)\n",
    "\n",
    "recall = encerts / total_entitats_reals\n",
    "\n",
    "if total_entitats_predites != 0:\n",
    "    precision = encerts / total_entitats_predites\n",
    "    f_score = (2 * precision * recall) / (precision + recall)\n",
    "else:\n",
    "    precision = 0\n",
    "    f_score = 0\n",
    "\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F-score:\", f_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicció amb IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_io(train_data_bio):\n",
    "    train_data_io = []\n",
    "    for sentence in train_data_bio:\n",
    "        io_tags = []\n",
    "        for word, pos_tag, bio_tag in sentence:\n",
    "            if bio_tag == 'O':\n",
    "                io_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                io_tags.append('I' + bio_tag[1:])\n",
    "            else:\n",
    "                io_tags.append(bio_tag)\n",
    "                \n",
    "        train_data_io.append(list(zip([word for word, pos_tag, bio_tag in sentence], io_tags)))\n",
    "    return train_data_io\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Espanyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 50064\n",
      "Precisió d'entitats: 94.59781191542429 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testa_esp)\n",
    "prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'FeatureExtractor2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProva amb use_basic_features=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_basic_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_prefix_suffix_features=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_prefix_suffix_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     12\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_context_features=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00muse_context_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Creem l'extractor de característiques amb els paràmetres corresponents\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m \u001b[43mFeatureExtractor2\u001b[49m(use_basic_features\u001b[38;5;241m=\u001b[39muse_basic_features, \n\u001b[0;32m     16\u001b[0m                                        use_prefix_suffix_features\u001b[38;5;241m=\u001b[39muse_prefix_suffix_features, \n\u001b[0;32m     17\u001b[0m                                        use_context_features\u001b[38;5;241m=\u001b[39muse_context_features, \n\u001b[0;32m     18\u001b[0m                                        pattern\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md+\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m train_esp_pre_IO \u001b[38;5;241m=\u001b[39m convert_to_io(train_esp)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Entrenem el model CRFTagger amb l'esquema IO\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'FeatureExtractor2' is not defined"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_IO_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format IO\n",
    "    dades_prova = convert_to_io(testa_esp)\n",
    "    prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_IO_esp:  1\n",
      "Total de entidades: 52923\n",
      "Entidades predichas correctamente: 50132\n",
      "Precisión de entidades: 94.72630047427396 %\n",
      "--------------------------------------------------\n",
      "model_IO_esp:  2\n",
      "Total de entidades: 105846\n",
      "Entidades predichas correctamente: 100264\n",
      "Precisión de entidades: 94.72630047427396 %\n",
      "--------------------------------------------------\n",
      "model_IO_esp:  3\n",
      "Total de entidades: 158769\n",
      "Entidades predichas correctamente: 150396\n",
      "Precisión de entidades: 94.72630047427396 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "pattern = r'\\d+' \n",
    "        \n",
    "extractor1 = feature_extractor1(pattern)\n",
    "extractor2 = feature_extractor2(pattern)\n",
    "extractor3 = feature_extractor3(pattern)\n",
    "\n",
    "train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "# Entrenamos el modelo CRFTagger con el esquema IO\n",
    "model_IO_esp1 = CRFTagger(feature_func=extractor1._get_features)\n",
    "model_IO_esp1.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "    \n",
    "model_IO_esp2 = CRFTagger(feature_func=extractor2._get_features)\n",
    "model_IO_esp2.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "    \n",
    "model_IO_esp3 = CRFTagger(feature_func=extractor3._get_features)\n",
    "model_IO_esp3.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "# Inicializamos los contadores\n",
    "total_entidades = 0\n",
    "entidades_correctas = 0\n",
    "\n",
    "# Convertimos los datos de prueba a formato IO\n",
    "data_prueba = convert_to_io(testa_esp)\n",
    "    \n",
    "predicciones1 = model_IO_esp1.tag_sents([[palabra for palabra, _ in frase] for frase in data_prueba])\n",
    "predicciones2 = model_IO_esp2.tag_sents([[palabra for palabra, _ in frase] for frase in data_prueba])\n",
    "predicciones3 = model_IO_esp3.tag_sents([[palabra for palabra, _ in frase] for frase in data_prueba])\n",
    "\n",
    "pre = [predicciones1, predicciones2, predicciones3]\n",
    "\n",
    "i = 0\n",
    "for predicciones in pre:\n",
    "    i += 1\n",
    "    # Iteramos sobre cada muestra en el conjunto de datos de prueba\n",
    "    for frase_certes, frase_predicciones in zip(data_prueba, predicciones):\n",
    "        for palabra_certes, etiqueta_certes in frase_certes:\n",
    "            for palabra_pred, etiqueta_pred in frase_predicciones:\n",
    "                if palabra_certes == palabra_pred:\n",
    "                    total_entidades += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entidades_correctas += 1\n",
    "                    break\n",
    "\n",
    "    # Calculamos el porcentaje de entidades predichas correctamente\n",
    "    precision_entidades = (entidades_correctas / total_entidades) * 100 if total_entidades > 0 else 0\n",
    "\n",
    "    print(\"model_IO_esp: \",i)\n",
    "    print(\"Total de entidades:\", total_entidades)\n",
    "    print(\"Entidades predichas correctamente:\", entidades_correctas)\n",
    "    print(\"Precisión de entidades:\", precision_entidades, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_pre_IO = convert_to_io(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testb_esp)\n",
    "prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IO NED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_pre_IO = convert_to_io(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_ned.train(train_ned_pre_IO, 'model_io.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 36539\n",
      "Precisió d'entitats: 96.95385676758565 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testa_ned)\n",
    "prediccions = model_IO_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_ned_pre_IO = convert_to_io(train_ned)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_IO_esp.train(train_ned_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format IO\n",
    "    dades_prova = convert_to_io(testa_ned)\n",
    "    prediccions = model_IO_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_ned_pre_IO = convert_to_io(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_IO_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_ned.train(train_ned_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format IO\n",
    "dades_prova = convert_to_io(testb_ned)\n",
    "prediccions = model_IO_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_biow(train_data_bio):\n",
    "    train_data_biow = []\n",
    "    for sentence in train_data_bio:\n",
    "        biow_tags = []\n",
    "        for word, pos_tag, bio_tag in sentence:\n",
    "            if bio_tag == 'O':\n",
    "                biow_tags.append('O')\n",
    "            else:\n",
    "                biow_tags.append(bio_tag + 'W')  # Añadir 'W' a todas las etiquetas\n",
    "            \n",
    "        train_data_biow.append(list(zip([word for word, pos_tag, bio_tag in sentence], biow_tags)))\n",
    "    return train_data_biow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_pre_BIOW = convert_to_biow(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_esp.train(train_esp_pre_BIOW, 'model_biow.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 50166\n",
      "Precisió d'entitats: 94.79054475369877 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testa_esp)\n",
    "prediccions = model_BIOW_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_esp_pre_BIOW = convert_to_biow(train_esp)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema BIOW\n",
    "    model_BIOW_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOW_esp.train(train_esp_pre_IO, 'model_biow.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format BIOW\n",
    "    dades_prova = convert_to_biow(testa_esp)\n",
    "    prediccions = model_BIOW_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_pre_BIOW = convert_to_biow(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_esp.train(train_esp_pre_BIOW, 'model_biow.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testb_esp)\n",
    "prediccions = model_BIOW_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_pre_BIOW = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_ned.train(train_ned_pre_BIOW, 'model_biow.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 36486\n",
      "Precisió d'entitats: 96.81322471939926 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testa_ned)\n",
    "prediccions = model_BIOW_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_ned_pre_BIOW = convert_to_biow(train_ned)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_BIOW_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOW_ned.train(train_ned_pre_IO, 'model_biow.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format BIOW\n",
    "    dades_prova = convert_to_biow(testa_ned)\n",
    "    prediccions = model_BIOW_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_ned_pre_BIOW = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOW_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOW_ned.train(train_ned_pre_BIOW, 'model_biow.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_biow(testb_ned)\n",
    "prediccions = model_BIOW_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BIOES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bioes(train_data_bio):\n",
    "    train_data_bioes = []\n",
    "    for sentence in train_data_bio:\n",
    "        bioes_tags = []\n",
    "        for i, (word, pos_tag, bio_tag) in enumerate(sentence):\n",
    "            if bio_tag == 'O':\n",
    "                bioes_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][2] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('S' + bio_tag[1:])  # Single\n",
    "                else:\n",
    "                    bioes_tags.append('B' + bio_tag[1:])  # Begin\n",
    "            elif bio_tag.startswith('I-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][2] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('E' + bio_tag[1:])  # End\n",
    "                else:\n",
    "                    bioes_tags.append('I' + bio_tag[1:])  # Inside\n",
    "            else:\n",
    "                raise ValueError(\"Etiqueta BIO incorrecta: {}\".format(bio_tag))\n",
    "                \n",
    "        train_data_bioes.append(list(zip([word for word, pos_tag, bio_tag in sentence], bioes_tags)))\n",
    "    return train_data_bioes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_esp_pre_BIOES = convert_to_bioes(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_esp.train(train_esp_pre_BIOW, 'model_bioes.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 44792\n",
      "Precisió d'entitats: 84.63616952931618 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testa_esp)\n",
    "prediccions = model_BIOES_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 52923\n",
      "Entitats predites correctament: 45072\n",
      "Precisió d'entitats: 85.16524006575591 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_esp_pre_BIOES = convert_to_bioes(train_esp)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOES_esp.train(train_esp_pre_IO, 'model_io.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format IO\n",
    "    dades_prova = convert_to_bioes(testa_esp)\n",
    "    prediccions = model_BIOES_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_esp_pre_BIOES = convert_to_bioes(train_esp)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_esp.train(train_esp_pre_BIOW, 'model_bioes.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testb_esp)\n",
    "prediccions = model_BIOES_esp.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "train_ned_pre_BIOES = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_ned.train(train_ned_pre_BIOES, 'model_bioes.crf.tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33903\n",
      "Precisió d'entitats: 89.95940244646695 %\n"
     ]
    }
   ],
   "source": [
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testa_ned)\n",
    "prediccions = model_BIOES_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=True, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=True, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=True:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n",
      "Prova amb use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False:\n",
      "Total d'entitats: 37687\n",
      "Entitats predites correctament: 33973\n",
      "Precisió d'entitats: 90.14514288746783 %\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "# Llista de totes les combinacions possibles de valors booleans pels paràmetres\n",
    "param_combinations = list(product([True, False], repeat=3))\n",
    "\n",
    "for params in param_combinations:\n",
    "    # Desempaquetem els valors booleans pels paràmetres\n",
    "    use_basic_features, use_prefix_suffix_features, use_context_features = params\n",
    "    \n",
    "    print(f\"Prova amb use_basic_features={use_basic_features}, \"\n",
    "          f\"use_prefix_suffix_features={use_prefix_suffix_features}, \"\n",
    "          f\"use_context_features={use_context_features}:\")\n",
    "    \n",
    "    # Creem l'extractor de característiques amb els paràmetres corresponents\n",
    "    feature_extractor = FeatureExtractor2(use_basic_features=use_basic_features, \n",
    "                                           use_prefix_suffix_features=use_prefix_suffix_features, \n",
    "                                           use_context_features=use_context_features, \n",
    "                                           pattern=r'\\d+')\n",
    "\n",
    "    train_ned_pre_BIOES = convert_to_bioes(train_ned)\n",
    "\n",
    "    # Entrenem el model CRFTagger amb l'esquema IO\n",
    "    model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "    model_BIOES_ned.train(train_ned_pre_IO, 'model_biow.crf.tagger')\n",
    "\n",
    "    # Inicialitzem els comptadors\n",
    "    total_entitats = 0\n",
    "    entitats_correctes = 0\n",
    "\n",
    "    # Convertim les dades de prova a format BIOES\n",
    "    dades_prova = convert_to_bioes(testa_ned)\n",
    "    prediccions = model_BIOES_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "    # Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "    for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "        for paraula_certes, etiqueta_certes in frase_certes:\n",
    "            for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "                if paraula_certes == paraula_pred:\n",
    "                    total_entitats += 1\n",
    "                    if etiqueta_certes == etiqueta_pred:\n",
    "                        entitats_correctes += 1\n",
    "                    break\n",
    "\n",
    "    # Calculem el percentatge d'entitats predites correctament\n",
    "    precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "    print(\"Total d'entitats:\", total_entitats)\n",
    "    print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "    print(\"Precisió d'entitats:\", precisio_entitats, \"%\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = FeatureExtractor2(use_basic_features = False, use_prefix_suffix_features = False, use_context_features = False, pattern = r'\\d+')\n",
    "\n",
    "train_ned_pre_BIOES = convert_to_biow(train_ned)\n",
    "\n",
    "# Entrenar el modelo CRFTagger con el esquema IO\n",
    "model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_ned.train(train_ned_pre_BIOES, 'model_bioes.crf.tagger')\n",
    "\n",
    "# Inicialitzem els comptadors\n",
    "total_entitats = 0\n",
    "entitats_correctes = 0\n",
    "\n",
    "# Convertim les dades de prova a format BIOES\n",
    "dades_prova = convert_to_bioes(testb_ned)\n",
    "prediccions = model_BIOES_ned.tag_sents([[paraula for paraula, _ in frase] for frase in dades_prova])\n",
    "\n",
    "# Iterem sobre cada mostra en el conjunt de dades de prova\n",
    "for frase_certes, frase_prediccions in zip(dades_prova, prediccions):\n",
    "    for paraula_certes, etiqueta_certes in frase_certes:\n",
    "        for paraula_pred, etiqueta_pred in frase_prediccions:\n",
    "            \n",
    "            if paraula_certes == paraula_pred:\n",
    "                total_entitats += 1\n",
    "                \n",
    "                if etiqueta_certes == etiqueta_pred:\n",
    "                    entitats_correctes += 1\n",
    "                    \n",
    "                break\n",
    "\n",
    "# Calculem el percentatge d'entitats predites correctament\n",
    "precisio_entitats = (entitats_correctes / total_entitats) * 100 if total_entitats > 0 else 0\n",
    "\n",
    "print(\"Total d'entitats:\", total_entitats)\n",
    "print(\"Entitats predites correctament:\", entitats_correctes)\n",
    "print(\"Precisió d'entitats:\", precisio_entitats, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Mark', 'B-PER'),\n",
       " ('Pedersen', 'I-PER'),\n",
       " ('treballa', 'O'),\n",
       " ('a', 'B-PER'),\n",
       " ('Google', 'I-PER'),\n",
       " ('des', 'O'),\n",
       " ('del', 'O'),\n",
       " ('1994', 'O'),\n",
       " ('.', 'O')]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_BIO.tag(nltk.word_tokenize(\"Mark Pedersen treballa a Google des del 1994.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_IO' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel_IO\u001b[49m\u001b[38;5;241m.\u001b[39mtag(nltk\u001b[38;5;241m.\u001b[39mword_tokenize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMark Pedersen treballa a Google des del 1994.\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model_IO' is not defined"
     ]
    }
   ],
   "source": [
    "model_IO.tag(nltk.word_tokenize(\"Mark Pedersen treballa a Google des del 1994.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avaluació"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9459214330253387"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Avaluació mal feta, contant només quants tokens són correctes, i no les entitats correctes.\n",
    "model.accuracy(testa_esp_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaluació ben feta:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hem d'avaluar quantes entitats estan reconegudes correctament, no quants tokens son correctes.\n",
    "Descodificar la sequencia i obtenir les entitats, i doncs avaluar les entitats.\n",
    "Per exemple, 'Mark Pedersen Romero' --> 'M P R' (una entitat) per BIO; 'M' i 'P R' (dos entitats) per IO; en aquest exemple IO ho fa malament.\n",
    "\n",
    "A nivell d'entitats: Recall i f-score\n",
    "\n",
    "Per avaluar el model avaluem en base a recall i precisio parcial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple d'ús CRFTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: El, Features: ['CAPITALIZATION', 'PRE_E', 'SUF_l', 'posterior1_men_NC', 'posterior2_atendió_VMI', 'WORD_El']\n",
      "Token: men, Features: ['PRE_m', 'PRE_me', 'SUF_n', 'SUF_en', 'anterior1_El_DA', 'posterior1_atendió_VMI', 'posterior2_a_SP', 'WORD_men']\n",
      "Token: atendió, Features: ['PRE_a', 'PRE_at', 'PRE_ate', 'SUF_ó', 'SUF_ió', 'SUF_dió', 'anterior1_men_NC', 'anterior2_El_DA', 'posterior1_a_SP', 'posterior2_la_DA', 'WORD_atendió']\n",
      "Token: a, Features: ['anterior1_atendió_VMI', 'anterior2_men_NC', 'posterior1_la_DA', 'posterior2_reunión_NC', 'WORD_a']\n",
      "Token: la, Features: ['PRE_l', 'SUF_a', 'anterior1_a_SP', 'anterior2_atendió_VMI', 'posterior1_reunión_NC', 'WORD_la']\n",
      "Token: reunión, Features: ['PRE_r', 'PRE_re', 'PRE_reu', 'SUF_n', 'SUF_ón', 'SUF_ión', 'anterior1_la_DA', 'anterior2_a_SP', 'WORD_reunión']\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "class FeatureExtractor:\n",
    "    def __init__(self, pattern):\n",
    "        self._pattern = pattern\n",
    "\n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "            - longitud\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "        token = tokens[idx]\n",
    "\n",
    "        feature_list = []\n",
    "\n",
    "        if not token:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0].isupper():\n",
    "            feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token) is not None:\n",
    "            feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "            feature_list.append(\"PUNCTUATION\")\n",
    "            \n",
    "        # preffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"PRE_\" + token[:1])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"PRE_\" + token[:2])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token) > 1:\n",
    "            feature_list.append(\"SUF_\" + token[-1:])\n",
    "        if len(token) > 2:\n",
    "            feature_list.append(\"SUF_\" + token[-2:])\n",
    "        if len(token) > 3:\n",
    "            feature_list.append(\"SUF_\" + token[-3:])\n",
    "        \n",
    "        # POS_tags\n",
    "        POS = model_tagger.tag(tokens)\n",
    "            \n",
    "        # Paraules prèvies amb POS\n",
    "        if idx > 0:\n",
    "            feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "        if idx > 1:\n",
    "            feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "            \n",
    "        # Paraules posteriors amb POS\n",
    "        if idx < (len(tokens)-1):\n",
    "            feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "        if idx < (len(tokens)-2):\n",
    "            feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "        feature_list.append(\"WORD_\" + token)\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "# Ejemplo de uso:\n",
    "pattern = r'\\d+'  # Patrón para encontrar números\n",
    "feature_extractor = FeatureExtractor(pattern)\n",
    "\n",
    "tokens = ['El', 'men', 'atendió', 'a', 'la', 'reunión']\n",
    "\n",
    "for i, token in enumerate(tokens):\n",
    "    features = feature_extractor._get_features(tokens, i)\n",
    "    print(f\"Token: {token}, Features: {features}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
