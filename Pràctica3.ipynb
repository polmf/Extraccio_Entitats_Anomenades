{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightblue; font-weight:bold;\">EXTRACCIÓ D'ENTITATS ANOMENADES</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ADD8E6; font-weight:bold;\">Índex:</span>\n",
    "### <span style=\"color:#FFFFFF;\">1. [Inicialització](#init)</span>\n",
    "### <span style=\"color:#FFFFFF;\">2. [Predicció amb BIO](#bio)</span>\n",
    "### <span style=\"color:#FFFFFF;\">3. [Predicció amb IO](#io)</span>\n",
    "### <span style=\"color:#ADD8E6;\">4. [Predicció amb BIOES](#bioes)</span>\n",
    "### <span style=\"color:#ADD8E6;\">5. [Conclusions](#conclusions)</span>\n",
    "### <span style=\"color:#ADD8E6;\">6. [Execució dels models amb textos reals](#text_real)</span>\n",
    "### <span style=\"color:#ADD8E6;\">7. [Opcional CADEC](#opcional)</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue;\"> Imports i Descarregues </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pycrfsuite\n",
    "from nltk.corpus import conll2002\n",
    "from nltk.tag import CRFTagger\n",
    "from sklearn.metrics import accuracy_score\n",
    "import unicodedata\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n",
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt') # Tokenitzador\n",
    "nltk.download('averaged_perceptron_tagger') # Etiquetador POS\n",
    "nltk.download('maxent_ne_chunker') # Etiquetador Entitats Anomenades\n",
    "nltk.download('words')\n",
    "nltk.download('treebank')\n",
    "nltk.download('conll2002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue; font-weight:bold;\">Inicialització</span> <a id=\"init\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px\">\n",
    "En aquesta secció obtenim els conjunts que utilitzarem més endavant per entrenar i avaluar els nostres models de reconeixement d'entitats anomenades. \n",
    "A més, definim les funcions que utilitzarem a posteriori per automatitzar procesos repetitius.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_esp = conll2002.iob_sents('esp.train') # Train\n",
    "testa_esp = conll2002.iob_sents('esp.testa') # Dev\n",
    "testb_esp = conll2002.iob_sents('esp.testb') # Test\n",
    "\n",
    "train_ned = conll2002.iob_sents('ned.train') # Train\n",
    "testa_ned = conll2002.iob_sents('ned.testa') # Dev\n",
    "testb_ned = conll2002.iob_sents('ned.testb') # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Definim les funcions per a obtenir diferents configuracions de representació dels nostres conjunts a entrenar i avaluar.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenir_token_POS(fitxer):\n",
    "    \"\"\"\n",
    "    Funció per convertir un text amb el token, POS tag i entitat per \n",
    "    cada element en cada frase en un text amb el token i el seu POS tag\n",
    "    per cada element.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for sentence in fitxer:\n",
    "        frases = []\n",
    "        for elem1, elem2, elem3 in sentence:\n",
    "            frases.append((elem1, elem2))\n",
    "        res.append(frases)\n",
    "    return res\n",
    "\n",
    "# Fem prediccions i mirem l'accuracy\n",
    "def obtenir_token(fitxer):\n",
    "    \"\"\"\n",
    "    Funció per convertir un text amb el token, POS tag i entitat \n",
    "    per cada element en cada frase en un text amb només el token\n",
    "    per cada element.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for sentence in fitxer:\n",
    "        frases = []\n",
    "        for elem1, elem2, elem3 in sentence:\n",
    "            frases.append(elem1)\n",
    "        res.append(frases)\n",
    "    return res\n",
    "\n",
    "\n",
    "def obtenir_token_entity(fitxer):\n",
    "    \"\"\"\n",
    "    Funció per convertir un text amb el token, POS tag i entitat per cada \n",
    "    element en cada frase en un text amb el token i la seva entitat per \n",
    "    cada element.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for sentence in fitxer:\n",
    "        frases = []\n",
    "        for elem1, elem2, elem3 in sentence:\n",
    "            frases.append((elem1, elem3))\n",
    "        res.append(frases)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightblue;\"> Classe FeatureExtractor personalitzada </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span> Features que es tenen en compte:\n",
    "<ul>\n",
    "    <li>Paraula actual</li>\n",
    "    <li>Si comença en majúscula</li>\n",
    "    <li>Si té signe de puntuació</li>\n",
    "    <li>Si té números</li>\n",
    "    <li>Prefixos fins a longitud 3</li>\n",
    "    <li>Sufixos fins a longitud 3</li>\n",
    "    <li>Paraules prèvies i posteriors amb POS-tags</li>\n",
    "    <li>POS-tags</li>\n",
    "</ul>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \n",
    "    \"\"\"\n",
    "    Aquesta classe conté el mètode per calcular les features\n",
    "    que s'utilitzaran per entrenar el model més endavant.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_basic_features=False, use_prefix_suffix_features=False, use_context_features=False, pattern = r'\\d+', model_POS = None):\n",
    "        self.use_basic_features = use_basic_features\n",
    "        self.use_prefix_suffix_features = use_prefix_suffix_features\n",
    "        self.use_context_features = use_context_features\n",
    "        self._pattern = pattern\n",
    "        self.model_POS = model_POS\n",
    "        \n",
    "    def __str__(self):\n",
    "        features = []\n",
    "        if self.use_basic_features:\n",
    "            features.append(\"use_basic_features=True\")\n",
    "        if self.use_prefix_suffix_features:\n",
    "            features.append(\"use_prefix_suffix_features=True\")\n",
    "        if self.use_context_features:\n",
    "            features.append(\"use_context_features=True\")\n",
    "        return f\"FeatureExtractor({', '.join(features)})\"\n",
    "        \n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "            \n",
    "        token = tokens[idx]\n",
    "        \n",
    "        feature_list = []\n",
    "        \n",
    "        if self.use_basic_features:\n",
    "            # Capitalization\n",
    "            if token[0].isupper():\n",
    "                feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "            # Number\n",
    "            if re.search(self._pattern, token) is not None:\n",
    "                feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "            # Punctuation\n",
    "            punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "            if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "                feature_list.append(\"PUNCTUATION\")\n",
    "\n",
    "                    \n",
    "        if self.use_prefix_suffix_features:\n",
    "            # preffix up to length 3\n",
    "            if len(token) > 1:\n",
    "                feature_list.append(\"PRE_\" + token[:1])\n",
    "            if len(token) > 2:\n",
    "                feature_list.append(\"PRE_\" + token[:2])\n",
    "            if len(token) > 3:\n",
    "                feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "            # Suffix up to length 3\n",
    "            if len(token) > 1:\n",
    "                feature_list.append(\"SUF_\" + token[-1:])\n",
    "            if len(token) > 2:\n",
    "                feature_list.append(\"SUF_\" + token[-2:])\n",
    "            if len(token) > 3:\n",
    "                feature_list.append(\"SUF_\" + token[-3:])\n",
    "    \n",
    "        \n",
    "        if self.use_context_features:\n",
    "            # POS_tags\n",
    "            if self.model_POS:\n",
    "                POS = self.model_POS.tag(tokens)\n",
    "                \n",
    "            # Paraules prèvies amb POS\n",
    "            if idx > 0:\n",
    "                feature_list.append(\"anterior1_\" + tokens[idx-1] + \"_\" + POS[idx-1][1])\n",
    "            if idx > 1:\n",
    "                feature_list.append(\"anterior2_\" + tokens[idx-2] + \"_\" + POS[idx-2][1])\n",
    "                \n",
    "            # Paraules posteriors amb POS\n",
    "            if idx < (len(tokens)-1):\n",
    "                feature_list.append(\"posterior1_\" + tokens[idx+1] + \"_\" + POS[idx+1][1])\n",
    "            if idx < (len(tokens)-2):\n",
    "                feature_list.append(\"posterior2_\" + tokens[idx+2] + \"_\" + POS[idx+2][1])\n",
    "\n",
    "            feature_list.append(\"WORD_\" + token + \"_\" + POS[idx][1])\n",
    "            \n",
    "        \n",
    "        if not self.use_context_features:\n",
    "            feature_list.append(\"WORD_\" + token)\n",
    "            \n",
    "        \n",
    "        return feature_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:lightblue;\"> Mètriques d'avaluació </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquestes funcions calculen la precisió, el recall i el F1-score per avaluar quan bé un model identifica les entitats en comparació amb les dades reals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_precisio(entitats_referencia, entitats_predites):\n",
    "    # Calcula el número d'entitats correctament identificades pel model\n",
    "    entitats_correctes = entitats_referencia.intersection(entitats_predites)\n",
    "    \n",
    "    # Calcular la precisió\n",
    "    if len(entitats_predites) > 0:\n",
    "        precisio = len(entitats_correctes) / len(entitats_predites)\n",
    "    else:\n",
    "        precisio = 0.0\n",
    "    \n",
    "    return precisio\n",
    "\n",
    "\n",
    "def calcular_recall(entitats_referencia, entitats_predites):\n",
    "    # Calcula el número d'entitats correctament identificades pel model\n",
    "    entitats_correctes = entitats_referencia.intersection(entitats_predites)\n",
    "    \n",
    "    # Calcular recall\n",
    "    if len(entitats_referencia) > 0:\n",
    "        recall = len(entitats_correctes) / len(entitats_referencia)\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    \n",
    "    return recall\n",
    "\n",
    "def calcular_f1_score(precisio, recall):\n",
    "    # Calcular el F1-score\n",
    "    if (precisio + recall) > 0:\n",
    "        f1_score = 2 * (precisio * recall) / (precisio + recall)\n",
    "    else:\n",
    "        f1_score = 0.0\n",
    "    \n",
    "    return f1_score\n",
    "\n",
    "def resultats(predicted_BIO, testa_esp_BIO_tag, obtain_entity):\n",
    "\n",
    "    # Obtenir els conjunts d'entitats de referència i predites\n",
    "    entitats_referencia = obtain_entity(testa_esp_BIO_tag)  # Conjunt d'entitats etiquetades manualment com a referència\n",
    "    entitats_predites =  obtain_entity(predicted_BIO) # Conjunt d'entitats predites\n",
    "\n",
    "    # Calcular la precisió\n",
    "    precisio = calcular_precisio(entitats_referencia, entitats_predites)\n",
    "\n",
    "    # Calcular la recall\n",
    "    recall = calcular_recall(entitats_referencia, entitats_predites)\n",
    "\n",
    "    # Calcular el F1-score\n",
    "    f1_score = calcular_f1_score(precisio, recall)\n",
    "\n",
    "    print(\"Precisió:\", precisio)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1-score:\", f1_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue; font-weight:bold;\">Predicció amb BIO</span> <a id=\"bio\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenir_entitats_amb_posicions_BIO(fitxer_BIO_tag):\n",
    "    \"\"\"\n",
    "    Funció per agrupar en sets les entitats anomenades, l'índex on comença i l'índex on acaba,\n",
    "    i la classe de la entitat.\n",
    "    \n",
    "    Argument: un text amb una tupla (amb el token i la seva entitat) per cada element en cada frase.\n",
    "    \"\"\"\n",
    "    \n",
    "    entitats_amb_posicions = set()\n",
    "\n",
    "    for sentence in fitxer_BIO_tag:\n",
    "        ent = []\n",
    "        name = None\n",
    "        start_pos = None  # Posició d'inici de l'entitat actual\n",
    "        prev_tag = None  # Guardar l'etiqueta del token anterior\n",
    "\n",
    "        for token_index, token in enumerate(sentence):\n",
    "            word, tag = token\n",
    "            #word = word[0]\n",
    "\n",
    "            if tag.startswith('B-'):\n",
    "                # Si hi ha una entitat anterior, l'agreguem a la llista d'entitats\n",
    "                if ent:\n",
    "                    end_pos = token_index - 1  # La posició de fi es el token anterior\n",
    "                    entitats_amb_posicions.add((tuple(ent), (start_pos, end_pos), name))\n",
    "                # Creem una nova entitat amb la paraula actual\n",
    "                ent = [word]\n",
    "                # Obtenim el tipus d'entitat\n",
    "                name = tag.split('-')[1]\n",
    "                start_pos = token_index  # La posició d'inici es el token actual\n",
    "                prev_tag = tag  # Actualitzem l'etiqueta del token anterior\n",
    "            elif tag.startswith('I-'):\n",
    "                # Només agreguem la paraula actual si el token anterior té etiqueta I- o B-\n",
    "                if prev_tag:\n",
    "                    ent.append(word)\n",
    "                    prev_tag = tag  # Actualitzem l'etiqueta del token anterior\n",
    "            elif tag == 'O' and ent:\n",
    "                # Si trobem una etiqueta 'O' i hi ha una entitat en curs, l'agreguem a la llista d'entitats\n",
    "                end_pos = token_index - 1  # La posición de fin es el token anterior\n",
    "                entitats_amb_posicions.add((tuple(ent), (start_pos, end_pos), name))\n",
    "                # Reiniciem la llista de l'entitat actual\n",
    "                ent = []\n",
    "                prev_tag = None  # Reiniciem l'etiqueta del token anterior\n",
    "\n",
    "        # Agreguem la última entitat si hi ha\n",
    "        if ent:\n",
    "            end_pos = len(sentence) - 1  # La posició de fi es l'últim token de la oració\n",
    "            entitats_amb_posicions.add((tuple(ent), (start_pos, end_pos)))\n",
    "\n",
    "    return entitats_amb_posicions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px\">\n",
    "Comencem entrenant un model CRFTagger per a la predicció de les etiquetes POS, ja que serà utilitzat posteriorment per a calcular els features necessaris en el procés d'extracció d'entitats anomenades. Inicialment, vam considerar utilitzar les etiquetes POS existents en els textos com a dades d'entrada, però vam enfrontar-nos a un error durant el procés d'entrenament del model CRFTagger. Aquest error indicava que el model esperava rebre només un element amb la seva etiqueta, en comptes de dos elements amb una etiqueta, ja que estàvem passant una tupla que contenia tant el token com el seu POS, juntament amb l'etiqueta de l'entitat. Per tant, per evitar aquest problema, vam optar per entrenar un model separat per a la predicció de les etiquetes POS, que posteriorment seran utilitzades com a característiques addicionals en el procés d'entrenament per a l'extracció d'entitats anomenades.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veiem que l'accuracy del model és prou elevada per tenir-lo en compte i utilitzar-lo més endavant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9447121289420479\n"
     ]
    }
   ],
   "source": [
    "model_tagger_POS_esp = CRFTagger()\n",
    "\n",
    "# Entrenem el model per predir els POS que corresponen a cada token\n",
    "\n",
    "train_esp_pos_tag = obtenir_token_POS(train_esp)\n",
    "    \n",
    "model_tagger_POS_esp.train(train_esp_pos_tag, 'model_POS_esp.crf.tagger')    \n",
    "\n",
    "\n",
    "testa_esp_pre_tag = obtenir_token(testa_esp)\n",
    "    \n",
    "predicted = model_tagger_POS_esp.tag_sents(testa_esp_pre_tag)\n",
    "\n",
    "predictions = [elem[1] for sentence in predicted for elem in sentence]\n",
    "real_label = [elem[1] for sentence in testa_esp for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions, real_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px\">\n",
    "A continuació, realitzem experiments amb diverses features per determinar quines proporcionen un rendiment òptim pel model amb etiquetatge BIO, i en textos escrits en espanyol. A més, aquests experiments els executem en el conjunt de proves \"testa\", que considerem com a conjunt de validació per ajustar i identificar les millors característiques.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Features per defecte de CRFTagger\n",
      "Precisió: 0.6927890345649583\n",
      "Recall: 0.643687707641196\n",
      "F1-score: 0.6673363949483353\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor()\n",
      "Precisió: 0.718299164768413\n",
      "Recall: 0.2619047619047619\n",
      "F1-score: 0.3838506796510448\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True)\n",
      "Precisió: 0.6447638603696099\n",
      "Recall: 0.6085271317829457\n",
      "F1-score: 0.626121635094716\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True)\n",
      "Precisió: 0.7015675835551612\n",
      "Recall: 0.6566998892580288\n",
      "F1-score: 0.6783926783926784\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True)\n",
      "Precisió: 0.7475160724722385\n",
      "Recall: 0.7081949058693244\n",
      "F1-score: 0.7273244242251918\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_combinations_esp = [\n",
    "    None,\n",
    "    FeatureExtractor(),\n",
    "    FeatureExtractor(True, model_POS=model_tagger_POS_esp),\n",
    "    FeatureExtractor(True, True, model_POS=model_tagger_POS_esp),\n",
    "    FeatureExtractor(True, True, True, model_POS=model_tagger_POS_esp)\n",
    "]\n",
    "\n",
    "train_esp_BIO = obtenir_token_entity(train_esp)\n",
    "\n",
    "testa_esp_real = obtenir_token_entity(testa_esp)\n",
    "\n",
    "def model_entrenament(train_esp_BIO_tag, extractor, testa_esp_pre_tag):\n",
    "    if extractor == None:\n",
    "        model_BIO = CRFTagger()\n",
    "        model_BIO.train(train_esp_BIO_tag, 'model_BIO.crf.tagger')\n",
    "        \n",
    "        predicted_BIO = model_BIO.tag_sents(testa_esp_pre_tag)\n",
    "    \n",
    "    else:\n",
    "        model_BIO = CRFTagger(feature_func=extractor._get_features)\n",
    "        model_BIO.train(train_esp_BIO_tag, 'model_BIO.crf.tagger')\n",
    "        \n",
    "        predicted_BIO = model_BIO.tag_sents(testa_esp_pre_tag)\n",
    "    \n",
    "    return resultats(predicted_BIO, testa_esp_real, obtenir_entitats_amb_posicions_BIO)\n",
    "\n",
    "for param in param_combinations_esp:\n",
    "    print(f'Model: {str(param)}') if param != None else print(f'Model: Features per defecte de CRFTagger')\n",
    "    model_entrenament(train_esp_BIO, param, testa_esp_pre_tag)\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observem que els millors resultats es donen amb el model que usa els 3 'features' diferents i, per tant, usarem aquest model per a poder identificar les entitats correctament en el conjunt de test que no hem utilitzat fins ara, el 'testb'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisió: 0.7869019341703427\n",
      "Recall: 0.7645895153313551\n",
      "F1-score: 0.7755852842809364\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor(True, True, True, model_POS=model_tagger_POS_esp)\n",
    "\n",
    "testb_esp_real = obtenir_token_entity(testb_esp)\n",
    "testb_esp_pre_tag = obtenir_token(testb_esp)\n",
    "\n",
    "model_BIO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIO_esp.train(train_esp_BIO, 'model_BIO.crf.tagger')\n",
    "    \n",
    "predicted_BIO = model_BIO_esp.tag_sents(testb_esp_pre_tag)\n",
    "\n",
    "resultats(predicted_BIO, testb_esp_real, obtenir_entitats_amb_posicions_BIO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els resultats són fins i tot millors que els obtinguts en el testa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenem el model de CRF per predir els POS tags però ara pel nederlandés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.940191577997718\n"
     ]
    }
   ],
   "source": [
    "model_tagger_POS_ned = CRFTagger()\n",
    "\n",
    "# Entrenem el model per predir els POS que corresponen a cada token\n",
    "train_ned_pos_tag = obtenir_token_POS(train_ned)\n",
    "    \n",
    "model_tagger_POS_ned.train(train_ned_pos_tag, 'model_POS_ned.crf.tagger')\n",
    "\n",
    "\n",
    "# Fem prediccions i mirem l'accuracy\n",
    "testa_ned_pre_tag = obtenir_token(testa_ned)\n",
    "    \n",
    "predicted = model_tagger_POS_ned.tag_sents(testa_ned_pre_tag)\n",
    "\n",
    "predictions = [elem[1] for sentence in predicted for elem in sentence]\n",
    "real_label = [elem[1] for sentence in testa_ned for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions, real_label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentació amb diferents 'features' per a veure quins són els més adequats pel model amb 'BIO' i la llengua neerlandesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Features per defecte de CRFTagger\n",
      "Precisió: 0.6441908713692946\n",
      "Recall: 0.565059144676979\n",
      "F1-score: 0.602035870092099\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor()\n",
      "Precisió: 0.762114537444934\n",
      "Recall: 0.15741583257506825\n",
      "F1-score: 0.2609351432880845\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True)\n",
      "Precisió: 0.655096011816839\n",
      "Recall: 0.4035486806187443\n",
      "F1-score: 0.49943693693693697\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True)\n",
      "Precisió: 0.6853182751540041\n",
      "Recall: 0.6073703366696998\n",
      "F1-score: 0.6439942112879885\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True)\n",
      "Precisió: 0.7082306554953179\n",
      "Recall: 0.6537761601455869\n",
      "F1-score: 0.6799148332150462\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_combinations_ned = [\n",
    "    None,\n",
    "    FeatureExtractor(),\n",
    "    FeatureExtractor(True, model_POS=model_tagger_POS_ned),\n",
    "    FeatureExtractor(True, True, model_POS=model_tagger_POS_ned),\n",
    "    FeatureExtractor(True, True, True, model_POS=model_tagger_POS_ned)\n",
    "]\n",
    "\n",
    "train_ned_BIO = obtenir_token_entity(train_ned)\n",
    "\n",
    "testa_ned_real = obtenir_token_entity(testa_ned)\n",
    "\n",
    "def model_entrenament(train_BIO_tag, extractor, testa_pre_tag):\n",
    "    if extractor == None:\n",
    "        model_BIO = CRFTagger()\n",
    "        model_BIO.train(train_BIO_tag, 'model_BIO_ned.crf.tagger')\n",
    "        \n",
    "        predicted_BIO = model_BIO.tag_sents(testa_pre_tag)\n",
    "    \n",
    "    else:    \n",
    "        model_BIO = CRFTagger(feature_func=extractor._get_features)\n",
    "        model_BIO.train(train_BIO_tag, 'model_BIO_ned.crf.tagger')\n",
    "        \n",
    "        predicted_BIO = model_BIO.tag_sents(testa_pre_tag)\n",
    "    \n",
    "    return resultats(predicted_BIO, testa_ned_real, obtenir_entitats_amb_posicions_BIO)\n",
    "\n",
    "for param in param_combinations_ned:\n",
    "    print(f'Model: {str(param)}') if param != None else print(f'Model: Features per defecte de CRFTagger')\n",
    "    model_entrenament(train_ned_BIO, param, testa_ned_pre_tag)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observem que els millors resultats es donen amb el model que usa els 3 'features' diferents i, per tant, usarem aquest model per a poder identificar les entitats correctament."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisió: 0.7402511566424322\n",
      "Recall: 0.6860643185298622\n",
      "F1-score: 0.7121284374503258\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor(True, True, True, model_POS=model_tagger_POS_ned)\n",
    "\n",
    "testb_ned_real = obtenir_token_entity(testb_ned)\n",
    "testb_ned_pre_tag = obtenir_token(testb_ned)\n",
    "\n",
    "model_BIO_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIO_ned.train(train_ned_BIO, 'model_BIO_ned.crf.tagger')\n",
    "    \n",
    "predicted_BIO = model_BIO_ned.tag_sents(testb_ned_pre_tag)\n",
    "\n",
    "resultats(predicted_BIO, testb_ned_real, obtenir_entitats_amb_posicions_BIO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els resultats tornen a ser novament millors que els obtinguts en el testa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue; font-weight:bold;\">Predicció amb IO</span> <a id=\"io\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definim una funció per passar de l'etiquetatge per defecte 'BIO' a l'etiquetatge 'IO'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_io(train_data_bio):\n",
    "    \"\"\"\n",
    "    Funció per convertir les dades del format BIO al format IO.\n",
    "    Argument:\n",
    "    train_data_bio: una llista de frases, on cada frase és una llista de tuples (paraula, etiqueta POS, etiqueta BIO).\n",
    "    Retorna:\n",
    "    Una llista de frases en format IO, on cada frase és una llista de tuples (paraula, etiqueta POS, etiqueta IO).\n",
    "    \"\"\"\n",
    "    train_data_io = []\n",
    "    for sentence in train_data_bio:\n",
    "        io_tags = []\n",
    "        for word, pos_tag, bio_tag in sentence:\n",
    "            if bio_tag == 'O':\n",
    "                io_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                io_tags.append('I' + bio_tag[1:])\n",
    "            else:\n",
    "                io_tags.append(bio_tag)\n",
    "        \n",
    "        train_data_io.append([(word, pos_tag, io_tag) for (word, pos_tag, bio_tag), io_tag in zip(sentence, io_tags)])\n",
    "    return train_data_io"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "Aquesta funció agrupa les entitats anomenades amb les seves posicions d'inici i fi, així com la seva classe, en un conjunt de tuples. Cada tuple conté tres elements: la llista de tokens que formen l'entitat, una tupla amb les posicions d'inici i fi (els índexs) de l'entitat dins del text, i la classe de l'entitat.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenir_entitats_amb_posicions_IO(fitxer_IO_tag):\n",
    "    \"\"\"\n",
    "    Funció per a agrupar en sets les entitats anomenades, l'índex on comença i l'índex on acaba,\n",
    "    i la classe de l'entitat.\n",
    "    \n",
    "    Argument: un text amb una tupla (amb el token i la seva entitat) per a cada element en cada frase.\n",
    "    \"\"\"\n",
    "    \n",
    "    entitats_amb_posicions = set()\n",
    "\n",
    "    for sentence_index, sentence in enumerate(fitxer_IO_tag):\n",
    "        ent = []\n",
    "        name = None\n",
    "        start_pos = None  # Posició de inici de la entitat actual\n",
    "        prev_tag = None  # Guardar l'etiqueta del token anterior\n",
    "\n",
    "        for token_index, token in enumerate(sentence):\n",
    "            word, tag = token\n",
    "\n",
    "            if tag.startswith('I-'):\n",
    "                # Si l'etiqueta es 'I-' i el token anterior es 'O', comencem una nova entitat\n",
    "                if not prev_tag:\n",
    "                    # Si hi ha una entitat anterior, l'afegim a la llista d'entitats\n",
    "                    if ent:\n",
    "                        end_pos = token_index - 1  # La posició de fi es el token anterior\n",
    "                        entitats_amb_posicions.add((tuple(ent), (start_pos, end_pos), name))\n",
    "                    # Creem una nova entitat amb la palabra actual\n",
    "                    ent = [word]\n",
    "                    # Obtenim el tipus de entitat\n",
    "                    name = tag.split('-')[1]\n",
    "                    start_pos = token_index  # La posició de inici es el token actual\n",
    "                else:\n",
    "                    # Si el token anterior es 'I-', agreguem la paraula actual a la entitat en curs\n",
    "                    ent.append(word)\n",
    "                prev_tag = tag  # Actualitzem l'etiqueta del token anterior\n",
    "            \n",
    "            elif tag == 'O' and ent:\n",
    "                # Si trobem una etiqueta 'O' i hi ha una entitat en curs, l'agreguem a la llista d'entitats\n",
    "                end_pos = token_index - 1  # La posición de fin es el token anterior\n",
    "                entitats_amb_posicions.add((tuple(ent), (start_pos, end_pos), name))\n",
    "                # Reiniciem la llista de l'entitat actual\n",
    "                ent = []\n",
    "                prev_tag = None  # Reiniciem l'etiqueta del token anterior\n",
    "\n",
    "        # Agreguem la última entitat si hi ha\n",
    "        if ent:\n",
    "            end_pos = len(sentence) - 1  # La posició de fi es l'últim token de la oració\n",
    "            entitats_amb_posicions.add((tuple(ent), (start_pos, end_pos), name))\n",
    "\n",
    "    return entitats_amb_posicions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "Experimentació amb diferents 'features' per a veure quins són els més adequats pel model amb 'IO' i la llengua espanyola, el mateix que hem fet amb la codificació 'BIO'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Features per defecte de CRFTagger\n",
      "Precisió: 0.6720413751140858\n",
      "Recall: 0.6208544125913434\n",
      "F1-score: 0.6454346238130021\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor()\n",
      "Precisió: 0.6519083969465649\n",
      "Recall: 0.24002248454187747\n",
      "F1-score: 0.35086277732128185\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True)\n",
      "Precisió: 0.6396209653538644\n",
      "Recall: 0.6070826306913997\n",
      "F1-score: 0.622927180966114\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True)\n",
      "Precisió: 0.6832579185520362\n",
      "Recall: 0.636593591905565\n",
      "F1-score: 0.6591008293321694\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True)\n",
      "Precisió: 0.738569753810082\n",
      "Recall: 0.7082630691399663\n",
      "F1-score: 0.7230989956958392\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_esp_io = convert_to_io(train_esp)\n",
    "train_esp_IO = obtenir_token_entity(train_esp_io)\n",
    "\n",
    "testa_esp_io = convert_to_io(testa_esp)\n",
    "testa_esp_real = obtenir_token_entity(testa_esp_io)\n",
    "\n",
    "def model_entrenament(train_tag, extractor, testa_pre_tag):\n",
    "    if extractor == None:\n",
    "        model_IO = CRFTagger()\n",
    "        model_IO.train(train_tag, 'model_IO.crf.tagger')\n",
    "        \n",
    "        predicted_IO = model_IO.tag_sents(testa_pre_tag)\n",
    "        \n",
    "    else:\n",
    "        model_IO = CRFTagger(feature_func=extractor._get_features)\n",
    "        model_IO.train(train_tag, 'model_IO.crf.tagger')\n",
    "        \n",
    "        predicted_IO = model_IO.tag_sents(testa_pre_tag)\n",
    "        \n",
    "    return resultats(predicted_IO, testa_esp_real, obtenir_entitats_amb_posicions_IO)\n",
    "\n",
    "for param in param_combinations_esp: # definida primerament en la predicció del BIO\n",
    "    print(f'Model: {str(param)}') if param != None else print(f'Model: Features per defecte de CRFTagger')\n",
    "    model_entrenament(train_esp_IO, param, testa_esp_pre_tag)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "Observem que els millors resultats es donen amb el model que usa els 3 'features' diferents, com en el cas anterior. Farem servir el model que utilitza aquestes 3 'features' per a poder identificar les entitats correctament en el 'testb'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisió: 0.779678412589805\n",
      "Recall: 0.7553861451773285\n",
      "F1-score: 0.7673400673400673\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor(True, True, True, model_POS=model_tagger_POS_esp)\n",
    "\n",
    "testb_esp_io = convert_to_io(testb_esp)\n",
    "testb_esp_real = obtenir_token_entity(testb_esp_io)\n",
    "\n",
    "testb_esp_pre_tag = obtenir_token(testb_esp)\n",
    "\n",
    "model_IO_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_esp.train(train_esp_IO, 'model_IO.crf.tagger')\n",
    "    \n",
    "predicted_IO = model_IO_esp.tag_sents(testb_esp_pre_tag)\n",
    "\n",
    "resultats(predicted_IO, testb_esp_real, obtenir_entitats_amb_posicions_IO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Novament els resultats són millors que els calculats sobre el 'testa'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentació amb diferents 'features' per a veure quins són els més adequats pel model amb 'IO' i la llengua neerlandesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Features per defecte de CRFTagger\n",
      "Precisió: 0.6347177848775293\n",
      "Recall: 0.5614696184644371\n",
      "F1-score: 0.5958510372406899\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor()\n",
      "Precisió: 0.7369727047146402\n",
      "Recall: 0.13989637305699482\n",
      "F1-score: 0.2351543942992874\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True)\n",
      "Precisió: 0.623082542001461\n",
      "Recall: 0.401789919924635\n",
      "F1-score: 0.4885452462772051\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True)\n",
      "Precisió: 0.6628211851074987\n",
      "Recall: 0.5953838907206783\n",
      "F1-score: 0.6272952853598015\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True)\n",
      "Precisió: 0.7160931174089069\n",
      "Recall: 0.6665096561469619\n",
      "F1-score: 0.6904122956818737\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_ned_io = convert_to_io(train_ned)\n",
    "train_ned_IO = obtenir_token_entity(train_ned_io)\n",
    "\n",
    "testa_ned_io = convert_to_io(testa_ned)\n",
    "testa_ned_real = obtenir_token_entity(testa_ned_io)\n",
    "\n",
    "def model_entrenament(train_tag, extractor, testa_pre_tag):\n",
    "    if extractor == None:\n",
    "        model_IO = CRFTagger()\n",
    "        model_IO.train(train_tag, 'model_io_ned.crf.tagger')\n",
    "        \n",
    "        predicted_IO = model_IO.tag_sents(testa_pre_tag)\n",
    "        \n",
    "    else:\n",
    "        model_IO = CRFTagger(feature_func=extractor._get_features)\n",
    "        model_IO.train(train_tag, 'model_io_ned.crf.tagger')\n",
    "        \n",
    "        predicted_IO = model_IO.tag_sents(testa_pre_tag)\n",
    "        \n",
    "    return resultats(predicted_IO, testa_ned_real, obtenir_entitats_amb_posicions_IO)\n",
    "\n",
    "for param in param_combinations_ned: # definida primerament en la predicció del BIO\n",
    "    print(f'Model: {str(param)}') if param != None else print(f'Model: Features per defecte de CRFTagger')\n",
    "    model_entrenament(train_ned_IO, param, testa_ned_pre_tag)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "En aquesta ocasió tornem a observar que els millors resultats es donen amb el model que usa els 3 'features' diferents, per tant, farem servir el model que utilitza aquestes 3 'features' per a poder identificar les entitats correctament en el 'testb'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisió: 0.7119216480918609\n",
      "Recall: 0.670057215511761\n",
      "F1-score: 0.6903553299492386\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor(True, True, True, model_POS=model_tagger_POS_ned)\n",
    "\n",
    "testb_ned_io = convert_to_io(testb_ned)\n",
    "testb_ned_real = obtenir_token_entity(testb_ned_io)\n",
    "\n",
    "testb_ned_pre_tag = obtenir_token(testb_ned)\n",
    "\n",
    "model_IO_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_IO_ned.train(train_ned_IO, 'model_io_ned.crf.tagger')\n",
    "    \n",
    "predicted_IO = model_IO_ned.tag_sents(testb_ned_pre_tag)\n",
    "\n",
    "resultats(predicted_IO, testb_ned_real, obtenir_entitats_amb_posicions_IO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue; font-weight:bold;\">Predicció amb BIOES</span> <a id=\"bioes\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bioes(train_data_bio):\n",
    "    \"\"\"\n",
    "    Funció per convertir dades de format BIO a format BIOES.\n",
    "    \n",
    "    Argument:\n",
    "    train_data_bio: una llista de frases, on cada frase és una llista de tuples (paraula, etiqueta POS, etiqueta BIO).\n",
    "    \n",
    "    Retorna:\n",
    "    Una llista de frases en format BIOES, on cada frase és una llista de tuples (paraula, etiqueta POS, etiqueta BIOES).\n",
    "    \"\"\"\n",
    "    train_data_bioes = []\n",
    "    for sentence in train_data_bio:\n",
    "        bioes_tags = []\n",
    "        for i, (word, pos_tag, bio_tag) in enumerate(sentence):\n",
    "            if bio_tag == 'O':\n",
    "                bioes_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][2] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('S' + bio_tag[1:])  # Single\n",
    "                else:\n",
    "                    bioes_tags.append('B' + bio_tag[1:])  # Begin\n",
    "            elif bio_tag.startswith('I-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][2] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('E' + bio_tag[1:])  # End\n",
    "                else:\n",
    "                    bioes_tags.append('I' + bio_tag[1:])  # Inside\n",
    "            else:\n",
    "                raise ValueError(\"Etiqueta BIO incorrecta: {}\".format(bio_tag))\n",
    "        \n",
    "        train_data_bioes.append([(word, pos_tag, bioes_tag) for (word, pos_tag, bio_tag), bioes_tag in zip(sentence, bioes_tags)])\n",
    "    return train_data_bioes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenir_entitats_amb_posicions_bioes(train_data_bioes):\n",
    "    \"\"\"\n",
    "    Funció per agrupar a sets les entitats nomenades, l'índex on comença i l'índex on acaba,\n",
    "    i la classe de lentitat.\n",
    "\n",
    "    Argument: un text amb una tupla (amb el token i la seva entitat) per a cada element a cada frase.\n",
    "    \"\"\"\n",
    "        \n",
    "    entitats_amb_posicions = set()\n",
    "\n",
    "    for sentence_index, sentence in enumerate(train_data_bioes):\n",
    "        ent = []\n",
    "        name = None\n",
    "        start_pos = None  # Posició d'inici de l'entitat actual\n",
    "\n",
    "        for token_index, (word, bioes_tag) in enumerate(sentence):\n",
    "            if bioes_tag != 'O':\n",
    "                if bioes_tag.startswith('B-') or bioes_tag.startswith('S-'):\n",
    "                    # Si hi ha una entitat anterior, l'afegim a la llista d'entitats\n",
    "                    if ent:\n",
    "                        end_pos = token_index - 1  # La posició de fi és el token anterior\n",
    "                        entitats_amb_posicions.add((tuple(ent), (start_pos, end_pos), name))\n",
    "                    # Creem una nova entitat amb la paraula actual\n",
    "                    ent = [word]\n",
    "                    # Obtenim el tipus d'entitat\n",
    "                    name = bioes_tag.split('-')[1]\n",
    "                    start_pos = token_index  # La posició inicial és el token actual\n",
    "                elif bioes_tag.startswith('I-') or bioes_tag.startswith('E-'):\n",
    "                    ent.append(word)\n",
    "            elif ent:\n",
    "                # Si trobem una etiqueta 'O' i hi ha una entitat en curs, l'afegim a la llista d'entitats\n",
    "                end_pos = token_index - 1  # La posició de fi és el token anterior\n",
    "                entitats_amb_posicions.add((tuple(ent), (start_pos, end_pos), name))\n",
    "                # Reiniciem la llista de l'entitat actual\n",
    "                ent = []\n",
    "\n",
    "        # Agreguem la darrera entitat si n'hi ha\n",
    "        if ent:\n",
    "            end_pos = len(sentence) - 1  # La posició de fi és el darrer token de l'oració\n",
    "            entitats_amb_posicions.add((tuple(ent), (start_pos, end_pos), name))\n",
    "\n",
    "    return entitats_amb_posicions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ESP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentació amb diferents 'features' per a veure quins són els més adequats pel model amb 'BIOES' i la llengua espanyola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Features per defecte de CRFTagger\n",
      "Precisió: 0.6887340301974448\n",
      "Recall: 0.6565181289786881\n",
      "F1-score: 0.6722403287515941\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor()\n",
      "Precisió: 0.7877838684416602\n",
      "Recall: 0.2784389703847218\n",
      "F1-score: 0.4114519427402863\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True)\n",
      "Precisió: 0.6522241478913923\n",
      "Recall: 0.6249654027124274\n",
      "F1-score: 0.638303886925795\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True)\n",
      "Precisió: 0.7036930178880554\n",
      "Recall: 0.6750622751176307\n",
      "F1-score: 0.6890803785845458\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True)\n",
      "Precisió: 0.7442737025224703\n",
      "Recall: 0.7104898975920287\n",
      "F1-score: 0.7269895213820448\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_esp_bioes = convert_to_bioes(train_esp)\n",
    "train_esp_BIOES = obtenir_token_entity(train_esp_bioes)\n",
    "\n",
    "testa_esp_bioes = convert_to_bioes(testa_esp)\n",
    "testa_esp_real = obtenir_token_entity(testa_esp_bioes)\n",
    "\n",
    "def model_entrenament(train_tag, extractor, testa_pre_tag):\n",
    "    if extractor == None:\n",
    "        model_BIOES = CRFTagger()\n",
    "        model_BIOES.train(train_tag, 'model_BIOES_esp.crf.tagger')\n",
    "        \n",
    "        predicted_BIOES = model_BIOES.tag_sents(testa_pre_tag)\n",
    "        \n",
    "    else:\n",
    "        model_BIOES = CRFTagger(feature_func=extractor._get_features)\n",
    "        model_BIOES.train(train_tag, 'model_BIOES_esp.crf.tagger')\n",
    "        \n",
    "        predicted_BIOES = model_BIOES.tag_sents(testa_pre_tag)\n",
    "        \n",
    "    return resultats(predicted_BIOES, testa_esp_real, obtenir_entitats_amb_posicions_bioes)\n",
    "\n",
    "for param in param_combinations_esp: # definida primerament en la predicció del BIO\n",
    "    print(f'Model: {str(param)}') if param != None else print(f'Model: Features per defecte de CRFTagger')\n",
    "    model_entrenament(train_esp_BIOES, param, testa_esp_pre_tag)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "Tornem a veure com el model que usa el 3 'features' obte els millors resultats i en aquesta ocasió tornarem a utilitzar el model que utilitza els 3 'features' per a identificar les entitats correctament.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisió: 0.7817327065144393\n",
      "Recall: 0.7673038892551087\n",
      "F1-score: 0.7744510978043911\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor(True, True, True, model_POS=model_tagger_POS_esp)\n",
    "\n",
    "testb_esp_bioes = convert_to_bioes(testb_esp)\n",
    "testb_esp_real = obtenir_token_entity(testb_esp_bioes)\n",
    "\n",
    "testb_esp_pre_tag = obtenir_token(testb_esp)\n",
    "\n",
    "model_BIOES_esp = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_esp.train(train_esp_BIOES, 'model_BIOES_esp.crf.tagger')\n",
    "    \n",
    "predicted_BIOES = model_BIOES_esp.tag_sents(testb_esp_pre_tag)\n",
    "\n",
    "resultats(predicted_BIOES, testb_esp_real, obtenir_entitats_amb_posicions_bioes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els resultats són gairebé els mateixos que els que hem obtingut amb la codificació 'BIO'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentació amb diferents 'features' per a veure quins són els més adequats pel model amb 'BIOES' i la llengua neerlandesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Features per defecte de CRFTagger\n",
      "Precisió: 0.6562178828365879\n",
      "Recall: 0.5828388863532633\n",
      "F1-score: 0.6173555716702925\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor()\n",
      "Precisió: 0.7785087719298246\n",
      "Recall: 0.16202647193062528\n",
      "F1-score: 0.26822818284850775\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True)\n",
      "Precisió: 0.6494252873563219\n",
      "Recall: 0.41259698767685987\n",
      "F1-score: 0.504605079542283\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True)\n",
      "Precisió: 0.6781725888324873\n",
      "Recall: 0.6097672295755363\n",
      "F1-score: 0.6421533285267964\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True, use_context_features=True)\n",
      "Precisió: 0.7135802469135802\n",
      "Recall: 0.659516202647193\n",
      "F1-score: 0.6854838709677419\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_ned_bioes = convert_to_bioes(train_ned)\n",
    "train_ned_BIOES = obtenir_token_entity(train_ned_bioes)\n",
    "\n",
    "testa_ned_bioes = convert_to_bioes(testa_ned)\n",
    "testa_ned_real = obtenir_token_entity(testa_ned_bioes)\n",
    "\n",
    "def model_entrenament(train_tag, extractor, testa_pre_tag):\n",
    "    if extractor == None:\n",
    "        model_BIOES = CRFTagger()\n",
    "        model_BIOES.train(train_tag, 'model_BIOES_ned.crf.tagger')\n",
    "        \n",
    "        predicted_BIOES = model_BIOES.tag_sents(testa_pre_tag)\n",
    "        \n",
    "    else:\n",
    "        model_BIOES = CRFTagger(feature_func=extractor._get_features)\n",
    "        model_BIOES.train(train_tag, 'model_BIOES_ned.crf.tagger')\n",
    "        \n",
    "        predicted_BIOES = model_BIOES.tag_sents(testa_pre_tag)\n",
    "        \n",
    "    return resultats(predicted_BIOES, testa_ned_real, obtenir_entitats_amb_posicions_bioes)\n",
    "\n",
    "for param in param_combinations_ned: # definida primerament en la predicció del BIO\n",
    "    print(f'Model: {str(param)}') if param != None else print(f'Model: Features per defecte de CRFTagger')\n",
    "    model_entrenament(train_ned_BIOES, param, testa_ned_pre_tag)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "En aquest últim model veiem com una vegada més els millors resultats ens el dona el model que usa els 3 'features' i, per tant, una vegada més utilitzarem aquest model per identificar correctament les identitats en el 'testb'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisió: 0.7451505016722408\n",
      "Recall: 0.6853275915103045\n",
      "F1-score: 0.7139881429258131\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = FeatureExtractor(True, True, True, model_POS=model_tagger_POS_ned)\n",
    "\n",
    "testb_ned_bioes = convert_to_bioes(testb_ned)\n",
    "testb_ned_real = obtenir_token_entity(testb_ned_bioes)\n",
    "\n",
    "testb_ned_pre_tag = obtenir_token(testb_ned)\n",
    "\n",
    "model_BIOES_ned = CRFTagger(feature_func=feature_extractor._get_features)\n",
    "model_BIOES_ned.train(train_ned_BIOES, 'model_BIOES_ned.crf.tagger')\n",
    "    \n",
    "predicted_BIOES = model_BIOES_ned.tag_sents(testb_ned_pre_tag)\n",
    "\n",
    "resultats(predicted_BIOES, testb_ned_real, obtenir_entitats_amb_posicions_bioes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amb la codificació 'BIO' hem obtingut resultats molt semblants sobre aquest mateix 'testb'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue; font-weight:bold;\">CONCLUSIONS</span> <a id=\"conclusions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "Després de les proves realitzades, es pot observar clarament que l'ús de tots els múltiples 'features' en un model millora significativament la identificació d'entitats. Aquesta millora és notable en comparació amb models que utilitzen menys característiques o cap, destacant la importància d'aquesta pràctica en el desenvolupament de models precisos entrenats amb molts atributs.\n",
    "\n",
    "Pel que fa a les codificacions BIO, IO i BIOES en les tasques d'etiquetatge d'entitats anomenades, les proves mostren que proporcionen resultats molt similars, sense destacar notablement l'una sobre les altres. Tot i això, creiem que és important assenyalar que la codificació IO tendeix a obtenir lleugerament resultats pitjors en comparació amb les altres dues, tot i que aquesta diferència no és significativa o notòria. Podem atribuir aquest fet a la menor quantitat d'informació proporcionada per la codificació IO en la detecció d'entitats, limitant així les opcions dels models predictius en la seva capacitat per detectar-les o no.\n",
    "\n",
    "Quant a la comparació entre els models en castellà i neerlandès, és evident que els models en castellà mostren millors resultats. Aquesta diferència pot atribuir-se a diversos factors, com ara la disponibilitat de dades etiquetades i corpus de text, la complexitat lingüística i els esforços de recerca i desenvolupament en cada idioma.\n",
    "\n",
    "En resum, és important l'ús de múltiples 'features' en els models, les codificacions 'BIO', 'IO' i 'BIOES' donen resultats molt semblants. Tot i així, es pot observar un rendiment lleugerament inferior amb la codificació 'IO' en comparació amb les altres. A més, els models entrenats en castellà demostren un millor rendiment en comparació amb els models en neerlandès.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue; font-weight:bold;\">Execució dels models amb textos reals</span> <a id=\"text_real\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per veure com funcionen els nostres models amb textos reals, hem utilitzat els següents dos textos en castellà i neerlandès respectivament."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "'En la soleada ciudad de Barcelona, España, se celebró una emocionante competición de tenis. Rafael Nadal, el famoso tenista español, dominó la cancha con su habilidad característica. Los espectadores animaban con entusiasmo mientras Nadal avanzaba hacia la victoria. Al final del torneo, Nadal levantó el trofeo en medio de aplausos y ovaciones.'\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "'In de bruisende stad Amsterdam, Nederland, vond een spannende fietsrace plaats. Tom Dumoulin, de beroemde Nederlandse wielrenner, schitterde op de route met zijn krachtige pedaalslagen. Toeschouwers juichten hem toe terwijl Dumoulin naar de overwinning fietste. Aan het einde van de race stond Dumoulin trots op het podium, omgeven door applaus en felicitaties.'\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definim ara funcions per tractar els textos reals per a que puguin ser predits pels nostres models.\n",
    "\n",
    "def transformar(text):\n",
    "    \"\"\"\n",
    "    Funció per transformar un text en una llista de frases.\n",
    "\n",
    "    Argument:\n",
    "    text: una cadena de caràcters que conté el text.\n",
    "\n",
    "    Retorna:\n",
    "    Una llista de frases, on cada frase és una llista de paraules del text original.\n",
    "    \"\"\"\n",
    "    \n",
    "    output = []\n",
    "    frase = []\n",
    "    palabras = text.split()\n",
    "    \n",
    "    for palabra in palabras:\n",
    "        frase.append(palabra)\n",
    "        if '.' in palabra:\n",
    "            output.append(frase)\n",
    "            frase = []\n",
    "    \n",
    "    if frase:\n",
    "        output.append(frase)\n",
    "    \n",
    "    return output\n",
    "\n",
    "def entitats(tupla):\n",
    "    \"\"\"\n",
    "    Retorna l'entitat d'una tupla que conté les entitats en la primera posició\n",
    "    \"\"\"\n",
    "    return tupla[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiquetar_paraules(text, paraules_etiqueta, codificacio):\n",
    "    \"\"\"\n",
    "    Funció per etiquetar correctament les entitats anomenades d'un \n",
    "    text per cada token en una llista de frases.\n",
    "\n",
    "    Argument:\n",
    "    text: una llista de tokens per cada frase.\n",
    "    paraules_etiqueta: una llista de tuples amb els tokens que formen les entitats i la seva classe.\n",
    "    codificacio: el tipus de codificacio que volem obtenir.\n",
    "\n",
    "    Retorna:\n",
    "    Una llista de frases, on cada frase és una llista de tuples amb el token i la entitat anomenada.\n",
    "    \"\"\"\n",
    "    \n",
    "    etiquetes = []\n",
    "    prev_tag = 'O'\n",
    "    for sentence in text:\n",
    "        etiquetes_oracio = []\n",
    "        for i, token in enumerate(sentence):\n",
    "            etiqueta = 'O'\n",
    "            for paraula, etiqueta_paraula in paraules_etiqueta:\n",
    "                if token == paraula:\n",
    "                    etiqueta = etiqueta_paraula\n",
    "                    break\n",
    "            etiquetes_oracio.append([token, etiqueta])\n",
    "            \n",
    "            \n",
    "        for i, etiqueta in enumerate(etiquetes_oracio):\n",
    "            if codificacio == 'BIO':\n",
    "                if etiqueta[1] != 'O':\n",
    "                    if prev_tag == 'O':\n",
    "                        etiqueta[1] = 'B-' + etiqueta[1]\n",
    "                    else:\n",
    "                        etiqueta[1] = 'I-' + etiqueta[1]\n",
    "                prev_tag = etiqueta[1]\n",
    "            \n",
    "            elif codificacio == 'IO':\n",
    "                if etiqueta[1] != 'O':\n",
    "                    etiqueta[1] = 'I-' + etiqueta[1]\n",
    "            \n",
    "            elif codificacio == 'BIOES':\n",
    "                if etiqueta[1] != 'O':\n",
    "                    if i == 0 or prev_tag == 'O':\n",
    "                        if i == len(sentence) - 1 or prev_tag == 'O' or sentence[i + 1][1] != etiqueta[1]:\n",
    "                            etiqueta[1] = 'S-' + etiqueta[1]  # Single\n",
    "                        else:\n",
    "                            etiqueta[1] = 'B-' + etiqueta[1]  # Begin\n",
    "                    else:\n",
    "                        if i == len(sentence) - 1 or sentence[i + 1][1] == 'O' or sentence[i + 1][1] != etiqueta[1]:\n",
    "                            etiqueta[1] = 'E-' + etiqueta[1]  # End\n",
    "                        else:\n",
    "                            etiqueta[1] = 'I-' + etiqueta[1]  # Inside\n",
    "                prev_tag = etiqueta[1]\n",
    "                \n",
    "            etiquetes_oracio[i] = tuple(etiqueta)\n",
    "            \n",
    "        etiquetes.append(etiquetes_oracio)\n",
    "    return etiquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardem els textos en variables que indiquen l'idioma de cada text \n",
    "\n",
    "esp = 'En la soleada ciudad de Barcelona, España, se celebró una emocionante competición de tenis. Rafael Nadal, el famoso tenista español, dominó la cancha con su habilidad característica. Los espectadores animaban con entusiasmo mientras Nadal avanzaba hacia la victoria. Al final del torneo, Nadal levantó el trofeo en medio de aplausos y ovaciones.'\n",
    "ned = 'In de bruisende stad Amsterdam, Nederland, vond een spannende fietsrace plaats. Tom Dumoulin, de beroemde Nederlandse wielrenner, schitterde op de route met zijn krachtige pedaalslagen. Toeschouwers juichten hem toe terwijl Dumoulin naar de overwinning fietste. Aan het einde van de race stond Dumoulin trots op het podium, omgeven door applaus en felicitaties.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenitzem els textos amb la funció definida prèviament i creem els textos amb les etiquetes correctament definides\n",
    "\n",
    "esp = transformar(esp)\n",
    "\n",
    "palabras_etiqueta_esp = [('Barcelona,', 'LOC'), ('España,', 'LOC'), ('Rafael', 'PER'), ('Nadal,', 'PER'), ('Nadal', 'PER')]\n",
    "text_real_BIO_esp = etiquetar_paraules(esp, palabras_etiqueta_esp, codificacio='BIO') # etiquetatge BIO\n",
    "text_real_IO_esp = etiquetar_paraules(esp, palabras_etiqueta_esp, codificacio='IO') # etiquetatge IO\n",
    "text_real_BIOES_esp = etiquetar_paraules(esp, palabras_etiqueta_esp, codificacio='BIOES') # etiquetatge BIOES\n",
    "\n",
    "\n",
    "\n",
    "ned = transformar(ned)\n",
    "\n",
    "palabras_etiqueta_ned = [('Amsterdam,', 'LOC'), ('Nederland,', 'LOC'), ('Tom', 'PER'), ('Dumoulin,', 'PER'), ('Nederlandse', 'MISC'), ('Dumoulin', 'PER')]\n",
    "text_real_BIO_ned = etiquetar_paraules(ned, palabras_etiqueta_ned, codificacio='BIO') # etiquetatge BIO\n",
    "text_real_IO_ned = etiquetar_paraules(ned, palabras_etiqueta_ned, codificacio='IO') # etiquetatge IO\n",
    "text_real_BIOES_ned = etiquetar_paraules(ned, palabras_etiqueta_ned, codificacio='BIOES') # etiquetatge BIOES\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ESP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIO: [[('En', 'O'), ('la', 'O'), ('soleada', 'O'), ('ciudad', 'O'), ('de', 'O'), ('Barcelona,', 'B-LOC'), ('España,', 'I-LOC'), ('se', 'O'), ('celebró', 'O'), ('una', 'O'), ('emocionante', 'O'), ('competición', 'O'), ('de', 'O'), ('tenis.', 'B-MISC')], [('Rafael', 'B-PER'), ('Nadal,', 'I-PER'), ('el', 'O'), ('famoso', 'O'), ('tenista', 'O'), ('español,', 'O'), ('dominó', 'O'), ('la', 'O'), ('cancha', 'O'), ('con', 'O'), ('su', 'O'), ('habilidad', 'O'), ('característica.', 'B-MISC')], [('Los', 'O'), ('espectadores', 'O'), ('animaban', 'O'), ('con', 'O'), ('entusiasmo', 'O'), ('mientras', 'O'), ('Nadal', 'O'), ('avanzaba', 'O'), ('hacia', 'O'), ('la', 'O'), ('victoria.', 'B-ORG')], [('Al', 'O'), ('final', 'O'), ('del', 'O'), ('torneo,', 'O'), ('Nadal', 'O'), ('levantó', 'O'), ('el', 'O'), ('trofeo', 'O'), ('en', 'O'), ('medio', 'O'), ('de', 'O'), ('aplausos', 'O'), ('y', 'O'), ('ovaciones.', 'B-MISC')]]\n",
      "IO: [[('En', 'O'), ('la', 'O'), ('soleada', 'O'), ('ciudad', 'O'), ('de', 'O'), ('Barcelona,', 'I-LOC'), ('España,', 'I-LOC'), ('se', 'O'), ('celebró', 'O'), ('una', 'O'), ('emocionante', 'O'), ('competición', 'O'), ('de', 'O'), ('tenis.', 'I-MISC')], [('Rafael', 'I-PER'), ('Nadal,', 'I-PER'), ('el', 'O'), ('famoso', 'O'), ('tenista', 'O'), ('español,', 'O'), ('dominó', 'O'), ('la', 'O'), ('cancha', 'O'), ('con', 'O'), ('su', 'O'), ('habilidad', 'O'), ('característica.', 'I-MISC')], [('Los', 'O'), ('espectadores', 'O'), ('animaban', 'O'), ('con', 'O'), ('entusiasmo', 'O'), ('mientras', 'O'), ('Nadal', 'O'), ('avanzaba', 'O'), ('hacia', 'O'), ('la', 'O'), ('victoria.', 'I-ORG')], [('Al', 'O'), ('final', 'O'), ('del', 'O'), ('torneo,', 'O'), ('Nadal', 'O'), ('levantó', 'O'), ('el', 'O'), ('trofeo', 'O'), ('en', 'O'), ('medio', 'O'), ('de', 'O'), ('aplausos', 'O'), ('y', 'O'), ('ovaciones.', 'I-MISC')]]\n",
      "BIOES: [[('En', 'O'), ('la', 'O'), ('soleada', 'O'), ('ciudad', 'O'), ('de', 'O'), ('Barcelona,', 'B-MISC'), ('España,', 'E-MISC'), ('se', 'O'), ('celebró', 'O'), ('una', 'O'), ('emocionante', 'O'), ('competición', 'O'), ('de', 'O'), ('tenis.', 'O')], [('Rafael', 'B-PER'), ('Nadal,', 'E-PER'), ('el', 'O'), ('famoso', 'O'), ('tenista', 'O'), ('español,', 'O'), ('dominó', 'O'), ('la', 'O'), ('cancha', 'O'), ('con', 'O'), ('su', 'O'), ('habilidad', 'O'), ('característica.', 'O')], [('Los', 'O'), ('espectadores', 'O'), ('animaban', 'O'), ('con', 'O'), ('entusiasmo', 'O'), ('mientras', 'O'), ('Nadal', 'O'), ('avanzaba', 'O'), ('hacia', 'O'), ('la', 'O'), ('victoria.', 'O')], [('Al', 'O'), ('final', 'O'), ('del', 'O'), ('torneo,', 'O'), ('Nadal', 'O'), ('levantó', 'O'), ('el', 'O'), ('trofeo', 'O'), ('en', 'O'), ('medio', 'O'), ('de', 'O'), ('aplausos', 'O'), ('y', 'O'), ('ovaciones.', 'S-LOC')]]\n"
     ]
    }
   ],
   "source": [
    "# Fem la predicció de l'etiquetat d'entitats amb els diferents models per les diferents codificacions\n",
    "\n",
    "predicted_BIO_esp = model_BIO_esp.tag_sents(esp)\n",
    "print(f'BIO: {predicted_BIO_esp}')\n",
    "\n",
    "predicted_IO_esp = model_IO_esp.tag_sents(esp)\n",
    "print(f'IO: {predicted_IO_esp}')\n",
    "\n",
    "predicted_BIOES_esp = model_BIOES_esp.tag_sents(esp)\n",
    "print(f'BIOES: {predicted_BIOES_esp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "Observant les frases resultants amb els tokens etiquetats per tipus d'entitat per les tres diferents codificacions podem extreure que les dues primeres codificacions, 'BIO' i 'IO', tenen automatitzada la reconeixença de les últimes paraules, és a dir, les que acaben en punt, com a entitats anomenades. Malgrat això totes reconeixen correctament Rafael Nadal com una entitat de classe PER, però cap d'elles reconeix l'altre entitat 'Nadal' de la classe PER.\n",
    "Finalment, la ciutat Barcelona i Espanya és reconeguda correctament com a entitat de classe LOC per les codificacions 'BIO' i 'IO', però, tot i que és reconeguda per la codificació 'BIOES' com a entitat, la classe predita d'aquesta entitat no és la correcte. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculem ara els resultats de les prediccions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetatge BIO: [('característica.',), ('Barcelona,', 'España,'), ('victoria.',), ('Rafael', 'Nadal,'), ('tenis.',), ('ovaciones.',)]\n",
      "Etiquetatge IO: [('Barcelona,', 'España,'), ('característica.',), ('Rafael', 'Nadal,'), ('ovaciones.',), ('tenis.',), ('victoria.',)]\n",
      "Etiquetatge BIOES: [('ovaciones.',), ('Barcelona,', 'España,'), ('Rafael', 'Nadal,')]\n"
     ]
    }
   ],
   "source": [
    "esp_bio = obtenir_entitats_amb_posicions_BIO(predicted_BIO_esp)\n",
    "palabras_y_etiqueta = [entitats(tupla) for tupla in esp_bio]\n",
    "print('Etiquetatge BIO:', palabras_y_etiqueta)\n",
    "\n",
    "esp_io = obtenir_entitats_amb_posicions_IO(predicted_IO_esp)\n",
    "palabras_y_etiqueta = [entitats(tupla) for tupla in esp_io]\n",
    "print('Etiquetatge IO:', palabras_y_etiqueta)\n",
    "\n",
    "esp_bioes = obtenir_entitats_amb_posicions_bioes(predicted_BIOES_esp)\n",
    "palabras_y_etiqueta = [entitats(tupla) for tupla in esp_bioes]\n",
    "print('Etiquetatge BIOES:', palabras_y_etiqueta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetatge BIO:\n",
      "Precisió: 0.3333333333333333\n",
      "Recall: 0.5\n",
      "F1-score: 0.4\n",
      "--------------------------------------------------\n",
      "\n",
      "Etiquetatge IO:\n",
      "Precisió: 0.3333333333333333\n",
      "Recall: 0.5\n",
      "F1-score: 0.4\n",
      "--------------------------------------------------\n",
      "\n",
      "Etiquetatge BIOES:\n",
      "Precisió: 0.3333333333333333\n",
      "Recall: 0.25\n",
      "F1-score: 0.28571428571428575\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Etiquetatge BIO:')\n",
    "resultats(predicted_BIO_esp, text_real_BIO_esp, obtenir_entitats_amb_posicions_BIO)\n",
    "print('-'*50)\n",
    "\n",
    "print('\\nEtiquetatge IO:')\n",
    "resultats(predicted_IO_esp, text_real_IO_esp, obtenir_entitats_amb_posicions_IO)\n",
    "print('-'*50)\n",
    "\n",
    "print('\\nEtiquetatge BIOES:')\n",
    "resultats(predicted_BIOES_esp, text_real_BIOES_esp, obtenir_entitats_amb_posicions_bioes)\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "Veiem que les codificacions que millor reconeixen entitats són les codificacions BIO i IO, tot i que no presenten bons resultats. Concloem que es deu a les poques dades utilitzades per fer les prediccions amb el text real, creiem que amb un text real més gran les prediccions augmentarien i on les codificacions BIO i BIOES tindrien millors resultats, tal com hem vist amb el còrpora de 'conll'.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BIO: [[('In', 'O'), ('de', 'O'), ('bruisende', 'O'), ('stad', 'O'), ('Amsterdam,', 'B-PER'), ('Nederland,', 'I-PER'), ('vond', 'O'), ('een', 'O'), ('spannende', 'O'), ('fietsrace', 'O'), ('plaats.', 'O')], [('Tom', 'B-PER'), ('Dumoulin,', 'I-PER'), ('de', 'O'), ('beroemde', 'O'), ('Nederlandse', 'B-MISC'), ('wielrenner,', 'O'), ('schitterde', 'O'), ('op', 'O'), ('de', 'O'), ('route', 'O'), ('met', 'O'), ('zijn', 'O'), ('krachtige', 'O'), ('pedaalslagen.', 'O')], [('Toeschouwers', 'O'), ('juichten', 'O'), ('hem', 'O'), ('toe', 'O'), ('terwijl', 'O'), ('Dumoulin', 'B-PER'), ('naar', 'O'), ('de', 'O'), ('overwinning', 'O'), ('fietste.', 'O')], [('Aan', 'O'), ('het', 'O'), ('einde', 'O'), ('van', 'O'), ('de', 'O'), ('race', 'O'), ('stond', 'O'), ('Dumoulin', 'B-PER'), ('trots', 'O'), ('op', 'O'), ('het', 'O'), ('podium,', 'O'), ('omgeven', 'O'), ('door', 'O'), ('applaus', 'O'), ('en', 'O'), ('felicitaties.', 'O')]]\n",
      "IO: [[('In', 'O'), ('de', 'O'), ('bruisende', 'O'), ('stad', 'O'), ('Amsterdam,', 'I-MISC'), ('Nederland,', 'I-MISC'), ('vond', 'O'), ('een', 'O'), ('spannende', 'O'), ('fietsrace', 'O'), ('plaats.', 'O')], [('Tom', 'I-PER'), ('Dumoulin,', 'I-PER'), ('de', 'O'), ('beroemde', 'O'), ('Nederlandse', 'I-MISC'), ('wielrenner,', 'O'), ('schitterde', 'O'), ('op', 'O'), ('de', 'O'), ('route', 'O'), ('met', 'O'), ('zijn', 'O'), ('krachtige', 'O'), ('pedaalslagen.', 'O')], [('Toeschouwers', 'O'), ('juichten', 'O'), ('hem', 'O'), ('toe', 'O'), ('terwijl', 'O'), ('Dumoulin', 'I-PER'), ('naar', 'O'), ('de', 'O'), ('overwinning', 'O'), ('fietste.', 'O')], [('Aan', 'O'), ('het', 'O'), ('einde', 'O'), ('van', 'O'), ('de', 'O'), ('race', 'O'), ('stond', 'O'), ('Dumoulin', 'I-PER'), ('trots', 'O'), ('op', 'O'), ('het', 'O'), ('podium,', 'O'), ('omgeven', 'O'), ('door', 'O'), ('applaus', 'O'), ('en', 'O'), ('felicitaties.', 'O')]]\n",
      "BIOES: [[('In', 'O'), ('de', 'O'), ('bruisende', 'O'), ('stad', 'O'), ('Amsterdam,', 'B-ORG'), ('Nederland,', 'E-ORG'), ('vond', 'O'), ('een', 'O'), ('spannende', 'O'), ('fietsrace', 'O'), ('plaats.', 'O')], [('Tom', 'B-PER'), ('Dumoulin,', 'E-PER'), ('de', 'O'), ('beroemde', 'O'), ('Nederlandse', 'S-MISC'), ('wielrenner,', 'O'), ('schitterde', 'O'), ('op', 'O'), ('de', 'O'), ('route', 'O'), ('met', 'O'), ('zijn', 'O'), ('krachtige', 'O'), ('pedaalslagen.', 'O')], [('Toeschouwers', 'O'), ('juichten', 'O'), ('hem', 'O'), ('toe', 'O'), ('terwijl', 'O'), ('Dumoulin', 'S-PER'), ('naar', 'O'), ('de', 'O'), ('overwinning', 'O'), ('fietste.', 'O')], [('Aan', 'O'), ('het', 'O'), ('einde', 'O'), ('van', 'O'), ('de', 'O'), ('race', 'O'), ('stond', 'O'), ('Dumoulin', 'S-PER'), ('trots', 'O'), ('op', 'O'), ('het', 'O'), ('podium,', 'O'), ('omgeven', 'O'), ('door', 'O'), ('applaus', 'O'), ('en', 'O'), ('felicitaties.', 'O')]]\n"
     ]
    }
   ],
   "source": [
    "predicted_BIO_ned = model_BIO_ned.tag_sents(ned)\n",
    "print(f'BIO: {predicted_BIO_ned}')\n",
    "\n",
    "predicted_IO_ned = model_IO_ned.tag_sents(ned)\n",
    "print(f'IO: {predicted_IO_ned}')\n",
    "\n",
    "predicted_BIOES_ned = model_BIOES_ned.tag_sents(ned)\n",
    "print(f'BIOES: {predicted_BIOES_ned}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify; max-width: 1250px;\">\n",
    "Observant les frases resultants amb els tokens etiquetats per tipus d'entitat per les tres diferents codificacions podem extreure que cap dels models usats per cada tipus d'etiquetatge tenen automatitzada la reconeixença de les últimes paraules, és a dir, les que acaben en punt, com a entitats anomenades tal com passava amb l'idioma espanyol. Totes reconeixen les mateixes entitats, i només s'equivoquen quan reconeixen correctament l'entitat 'Amsterdam, Nederland' perquè cap defineix de manera acertada la classe d'aquesta entitat, 'LOC'. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculem ara les prediccions per l'idioma neerlandés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetatge BIO: [('Amsterdam,', 'Nederland,'), ('Tom', 'Dumoulin,'), ('Nederlandse',), ('Dumoulin',), ('Dumoulin',)]\n",
      "Etiquetatge IO: [('Amsterdam,', 'Nederland,'), ('Tom', 'Dumoulin,'), ('Nederlandse',), ('Dumoulin',), ('Dumoulin',)]\n",
      "Etiquetatge BIOES: [('Tom', 'Dumoulin,'), ('Amsterdam,', 'Nederland,'), ('Nederlandse',), ('Dumoulin',), ('Dumoulin',)]\n"
     ]
    }
   ],
   "source": [
    "ned_bio = obtenir_entitats_amb_posicions_BIO(predicted_BIO_ned)\n",
    "palabras_y_etiqueta = [entitats(tupla) for tupla in ned_bio]\n",
    "print('Etiquetatge BIO:', palabras_y_etiqueta)\n",
    "\n",
    "ned_io = obtenir_entitats_amb_posicions_IO(predicted_IO_ned)\n",
    "palabras_y_etiqueta = [entitats(tupla) for tupla in ned_io]\n",
    "print('Etiquetatge IO:', palabras_y_etiqueta)\n",
    "\n",
    "ned_bioes = obtenir_entitats_amb_posicions_bioes(predicted_BIOES_ned)\n",
    "palabras_y_etiqueta = [entitats(tupla) for tupla in ned_bioes]\n",
    "print('Etiquetatge BIOES:', palabras_y_etiqueta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiquetatge BIO:\n",
      "Precisió: 0.8\n",
      "Recall: 0.8\n",
      "F1-score: 0.8000000000000002\n",
      "--------------------------------------------------\n",
      "\n",
      "Etiquetatge IO:\n",
      "Precisió: 0.8\n",
      "Recall: 0.8\n",
      "F1-score: 0.8000000000000002\n",
      "--------------------------------------------------\n",
      "\n",
      "Etiquetatge BIOES:\n",
      "Precisió: 0.8\n",
      "Recall: 0.8\n",
      "F1-score: 0.8000000000000002\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print('Etiquetatge BIO:')\n",
    "resultats(predicted_BIO_ned, text_real_BIO_ned, obtenir_entitats_amb_posicions_BIO)\n",
    "print('-'*50)\n",
    "\n",
    "print('\\nEtiquetatge IO:')\n",
    "resultats(predicted_IO_ned, text_real_IO_ned, obtenir_entitats_amb_posicions_IO)\n",
    "print('-'*50)\n",
    "\n",
    "print('\\nEtiquetatge BIOES:')\n",
    "resultats(predicted_BIOES_ned, text_real_BIOES_ned, obtenir_entitats_amb_posicions_bioes)\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tots presenten els mateixos resultats com ens esperàvem després d'analitzar la reconeixença d'entitats per cada codificació."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <span style=\"color:lightblue; font-weight:bold;\">Opcional CADEC</span> <a id=\"opcional_cadec\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor_opcional:\n",
    "    \n",
    "    \"\"\"\n",
    "    Aquesta classe conté el mètode per calcular les features\n",
    "    que s'utilitzaran per entrenar el model més endavant.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, use_basic_features=False, use_prefix_suffix_features=False, context_features=False, pattern = r'\\d+'):\n",
    "        self.use_basic_features = use_basic_features\n",
    "        self.use_prefix_suffix_features = use_prefix_suffix_features\n",
    "        self._pattern = pattern\n",
    "        self.context_features = context_features\n",
    "        \n",
    "    def __str__(self):\n",
    "        features = []\n",
    "        if self.use_basic_features:\n",
    "            features.append(\"use_basic_features=True\")\n",
    "        if self.use_prefix_suffix_features:\n",
    "            features.append(\"use_prefix_suffix_features=True\")\n",
    "        if self.context_features:\n",
    "            features.append(\"context_features=True\")\n",
    "        return f\"FeatureExtractor({', '.join(features)})\"\n",
    "        \n",
    "    def _get_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Preffixes up to length 3\n",
    "            - Suffixes up to length 3\n",
    "            - paraules prèvies i posteriors amb POS\n",
    "            - POS-tags\n",
    "\n",
    "        Note that : we might include feature over previous word, next word etc.\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(str)\n",
    "        \"\"\"\n",
    "            \n",
    "        token = tokens[idx]\n",
    "        \n",
    "        feature_list = []\n",
    "        \n",
    "        if self.use_basic_features:\n",
    "            # Capitalization\n",
    "            if token[0].isupper():\n",
    "                feature_list.append(\"CAPITALIZATION\")\n",
    "\n",
    "            # Number\n",
    "            if re.search(self._pattern, token) is not None:\n",
    "                feature_list.append(\"HAS_NUM\")\n",
    "\n",
    "            # Punctuation\n",
    "            punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "            if all(unicodedata.category(x) in punc_cat for x in token):\n",
    "                feature_list.append(\"PUNCTUATION\")\n",
    "\n",
    "                    \n",
    "        if self.use_prefix_suffix_features:\n",
    "            # preffix up to length 3\n",
    "            if len(token) > 1:\n",
    "                feature_list.append(\"PRE_\" + token[:1])\n",
    "            if len(token) > 2:\n",
    "                feature_list.append(\"PRE_\" + token[:2])\n",
    "            if len(token) > 3:\n",
    "                feature_list.append(\"PRE_\" + token[:3])\n",
    "\n",
    "            # Suffix up to length 3\n",
    "            if len(token) > 1:\n",
    "                feature_list.append(\"SUF_\" + token[-1:])\n",
    "            if len(token) > 2:\n",
    "                feature_list.append(\"SUF_\" + token[-2:])\n",
    "            if len(token) > 3:\n",
    "                feature_list.append(\"SUF_\" + token[-3:])\n",
    "                \n",
    "        if self.context_features:\n",
    "            # Paraules prèvies amb POS\n",
    "            if idx > 0:\n",
    "                feature_list.append(\"anterior1_\" + tokens[idx-1])\n",
    "            if idx > 1:\n",
    "                feature_list.append(\"anterior2_\" + tokens[idx-2])\n",
    "                \n",
    "            # Paraules posteriors amb POS\n",
    "            if idx < (len(tokens)-1):\n",
    "                feature_list.append(\"posterior1_\" + tokens[idx+1])\n",
    "            if idx < (len(tokens)-2):\n",
    "                feature_list.append(\"posterior2_\" + tokens[idx+2])\n",
    "\n",
    "            feature_list.append(\"WORD_\" + token)\n",
    "            \n",
    "        \n",
    "        if not self.context_features:\n",
    "            feature_list.append(\"WORD_\" + token)        \n",
    "            \n",
    "        \n",
    "        return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtenir_token_opcional(fitxer):\n",
    "    \"\"\"\n",
    "    Funció per convertir un text amb el token, POS tag i entitat \n",
    "    per cada element en cada frase en un text amb només el token\n",
    "    per cada element.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for sentence in fitxer:\n",
    "        frases = []\n",
    "        for elem1, elem2 in sentence:\n",
    "            frases.append(elem1)\n",
    "        res.append(frases)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from conllu import parse\n",
    "\n",
    "# Ruta del archivo .conll de entrenamiento\n",
    "ruta_entrenamiento_conll = \"train.conll\"\n",
    "\n",
    "# Ruta del archivo .conll de prueba\n",
    "ruta_prueba_conll = \"test.conll\"\n",
    "\n",
    "# Cargar datos de entrenamiento\n",
    "with open(ruta_entrenamiento_conll, \"r\", encoding=\"utf-8\") as file:\n",
    "    entrenamiento_conll = file.read()\n",
    "    opcional_train = entrenamiento_conll\n",
    "\n",
    "# Cargar datos de prueba\n",
    "with open(ruta_prueba_conll, \"r\", encoding=\"utf-8\") as file:\n",
    "    prueba_conll = file.read()\n",
    "    opcional_test = prueba_conll\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_datos(fitxer):\n",
    "    # Dividir los datos por líneas\n",
    "    lineas = fitxer.strip().split('\\n')\n",
    "\n",
    "    # Inicializar la lista de resultados\n",
    "    resultados = []\n",
    "\n",
    "    # Inicializar la lista para cada bloque de datos\n",
    "    bloque_actual = []\n",
    "\n",
    "    # Iterar sobre cada línea de los datos\n",
    "    for linea in lineas:\n",
    "        # Dividir la línea en sus elementos\n",
    "        elementos = linea.split('\\t')\n",
    "\n",
    "        # Verificar si la línea está vacía (inicio de un nuevo bloque)\n",
    "        if len(elementos) == 1:\n",
    "            # Agregar el bloque actual a los resultados si no está vacío\n",
    "            if bloque_actual:\n",
    "                resultados.append(bloque_actual)\n",
    "                bloque_actual = []  # Reiniciar el bloque actual\n",
    "\n",
    "        # Si la línea no está vacía, procesarla\n",
    "        else:\n",
    "            # Obtener el tipo de entidad según la columna\n",
    "            tipo_entidad = None\n",
    "            for i in range(1, len(elementos)):\n",
    "                if elementos[i] != 'O':\n",
    "                    tipo_entidad = 'ADR' if i == 1 else ('Di' if i == 2 else ('Dr' if i == 3 else ('S' if i == 4 else 'F')))\n",
    "                    indx = i\n",
    "                    break\n",
    "\n",
    "            # Construir la etiqueta de entidad\n",
    "            if tipo_entidad:\n",
    "                if elementos[indx].startswith(('B')):\n",
    "                    entidad = 'B'\n",
    "                elif elementos[indx].startswith(('I')):\n",
    "                    entidad = 'I'\n",
    "\n",
    "                bloque_actual.append((elementos[0], entidad + '-' + tipo_entidad))\n",
    "            else:\n",
    "                bloque_actual.append((elementos[0], 'O'))\n",
    "\n",
    "    # Agregar el último bloque a los resultados si no está vacío\n",
    "    if bloque_actual:\n",
    "        resultados.append(bloque_actual)\n",
    "\n",
    "    return resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcional_train = procesar_datos(opcional_train)\n",
    "opcional_test = procesar_datos(opcional_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8954845923636005\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Diria que aixo no fa falta, perquè en el opcional_train no \n",
    "tenim els POS_tags, només les entitats i les seves codificacions. \n",
    "\"\"\"\n",
    "\n",
    "model_tagger_POS_eng = CRFTagger()\n",
    "\n",
    "# Entrenem el model per predir els POS que corresponen a cada token    \n",
    "model_tagger_POS_eng.train(opcional_train, 'model_POS_eng.crf.tagger')    \n",
    "\n",
    "\n",
    "testa_eng_pre_tag = obtenir_token_opcional(opcional_test)\n",
    "    \n",
    "predicted = model_tagger_POS_eng.tag_sents(testa_eng_pre_tag)\n",
    "\n",
    "predictions = [elem[1] for sentence in predicted for elem in sentence]\n",
    "real_label = [elem[1] for sentence in opcional_test for elem in sentence]\n",
    "\n",
    "print(accuracy_score(predictions, real_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Features per defecte de CRFTagger\n",
      "Precisió: 0.6053067993366501\n",
      "Recall: 0.3967391304347826\n",
      "F1-score: 0.47931713722915303\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor()\n",
      "Precisió: 0.608324439701174\n",
      "Recall: 0.30978260869565216\n",
      "F1-score: 0.4105149441843716\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True)\n",
      "Precisió: 0.6102403343782654\n",
      "Recall: 0.3173913043478261\n",
      "F1-score: 0.4175902752949589\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True)\n",
      "Precisió: 0.6141141141141141\n",
      "Recall: 0.44456521739130433\n",
      "F1-score: 0.5157629255989912\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True, context_features=True)\n",
      "Precisió: 0.6603508771929825\n",
      "Recall: 0.5114130434782609\n",
      "F1-score: 0.5764165390505359\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "param_combinations_eng = [\n",
    "    None,\n",
    "    FeatureExtractor_opcional(),\n",
    "    FeatureExtractor_opcional(True),\n",
    "    FeatureExtractor_opcional(True, True),\n",
    "    FeatureExtractor_opcional(True, True, True)\n",
    "]\n",
    "\n",
    "train_eng_BIO = opcional_train\n",
    "test_eng_real = opcional_test\n",
    "\n",
    "test_eng_pre_tag = obtenir_token_opcional(opcional_test)\n",
    "\n",
    "\n",
    "def model_entrenament(train_eng_BIO_tag, extractor, test_eng_pre_tag):\n",
    "    if extractor == None:\n",
    "        model_BIO = CRFTagger()\n",
    "        model_BIO.train(train_eng_BIO_tag, 'model_opcional.crf.tagger')\n",
    "        \n",
    "        predicted_BIO = model_BIO.tag_sents(test_eng_pre_tag)\n",
    "    \n",
    "    else:\n",
    "        model_BIO = CRFTagger(feature_func=extractor._get_features)\n",
    "        model_BIO.train(train_eng_BIO_tag, 'model_opcional.crf.tagger')\n",
    "        \n",
    "        predicted_BIO = model_BIO.tag_sents(test_eng_pre_tag)\n",
    "    \n",
    "    return resultats(predicted_BIO, test_eng_real, obtenir_entitats_amb_posicions_BIO)\n",
    "\n",
    "for param in param_combinations_eng:\n",
    "    print(f'Model: {str(param)}') if param != None else print(f'Model: Features per defecte de CRFTagger')\n",
    "    model_entrenament(train_eng_BIO, param, test_eng_pre_tag)\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_io_opcional(train_data_bio):\n",
    "    \"\"\"\n",
    "    Funció per convertir les dades del format BIO al format IO.\n",
    "    Argument:\n",
    "    train_data_bio: una llista de frases, on cada frase és una llista de tuples (paraula, etiqueta POS, etiqueta BIO).\n",
    "    Retorna:\n",
    "    Una llista de frases en format IO, on cada frase és una llista de tuples (paraula, etiqueta POS, etiqueta IO).\n",
    "    \"\"\"\n",
    "    train_data_io = []\n",
    "    for sentence in train_data_bio:\n",
    "        io_tags = []\n",
    "        for word, bio_tag in sentence:\n",
    "            if bio_tag == 'O':\n",
    "                io_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                io_tags.append('I' + bio_tag[1:])\n",
    "            else:\n",
    "                io_tags.append(bio_tag)\n",
    "        \n",
    "        train_data_io.append([(word, io_tag) for (word, bio_tag), io_tag in zip(sentence, io_tags)])\n",
    "    return train_data_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Features per defecte de CRFTagger\n",
      "Precisió: 0.5913621262458472\n",
      "Recall: 0.37160751565762007\n",
      "F1-score: 0.45641025641025645\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor()\n",
      "Precisió: 0.5845665961945031\n",
      "Recall: 0.2886221294363257\n",
      "F1-score: 0.3864430468204053\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True)\n",
      "Precisió: 0.5886524822695035\n",
      "Recall: 0.30323590814196244\n",
      "F1-score: 0.40027557698932137\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True)\n",
      "Precisió: 0.6059925093632959\n",
      "Recall: 0.4222338204592902\n",
      "F1-score: 0.4976930175330668\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True, context_features=True)\n",
      "Precisió: 0.6535057862491491\n",
      "Recall: 0.5010438413361169\n",
      "F1-score: 0.5672082717872969\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_eng_IO = convert_to_io_opcional(opcional_train)\n",
    "test_eng_real = convert_to_io_opcional(opcional_test)\n",
    "\n",
    "test_eng_pre_tag = obtenir_token_opcional(opcional_test)\n",
    "\n",
    "\n",
    "def model_entrenament(train_eng_IO_tag, extractor, test_eng_pre_tag):\n",
    "    if extractor == None:\n",
    "        model_IO = CRFTagger()\n",
    "        model_IO.train(train_eng_IO_tag, 'model_opcional.crf.tagger')\n",
    "        \n",
    "        predicted_IO = model_IO.tag_sents(test_eng_pre_tag)\n",
    "    \n",
    "    else:\n",
    "        model_IO = CRFTagger(feature_func=extractor._get_features)\n",
    "        model_IO.train(train_eng_IO_tag, 'model_opcional.crf.tagger')\n",
    "        \n",
    "        predicted_IO = model_IO.tag_sents(test_eng_pre_tag)\n",
    "    \n",
    "    return resultats(predicted_IO, test_eng_real, obtenir_entitats_amb_posicions_IO)\n",
    "\n",
    "for param in param_combinations_eng:\n",
    "    print(f'Model: {str(param)}') if param != None else print(f'Model: Features per defecte de CRFTagger')\n",
    "    model_entrenament(train_eng_IO, param, test_eng_pre_tag)\n",
    "    print('-'*50)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bioes_opcional(train_data_bio):\n",
    "    \"\"\"\n",
    "    Funció per convertir dades de format BIO a format BIOES.\n",
    "    \n",
    "    Argument:\n",
    "    train_data_bio: una llista de frases, on cada frase és una llista de tuples (paraula, etiqueta POS, etiqueta BIO).\n",
    "    \n",
    "    Retorna:\n",
    "    Una llista de frases en format BIOES, on cada frase és una llista de tuples (paraula, etiqueta POS, etiqueta BIOES).\n",
    "    \"\"\"\n",
    "    train_data_bioes = []\n",
    "    for sentence in train_data_bio:\n",
    "        bioes_tags = []\n",
    "        for i, (word, bio_tag) in enumerate(sentence):\n",
    "            if bio_tag == 'O':\n",
    "                bioes_tags.append('O')\n",
    "            elif bio_tag.startswith('B-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][1] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('S' + bio_tag[1:])  # Single\n",
    "                else:\n",
    "                    bioes_tags.append('B' + bio_tag[1:])  # Begin\n",
    "            elif bio_tag.startswith('I-'):\n",
    "                if i == len(sentence) - 1 or sentence[i + 1][1] != 'I' + bio_tag[1:]:\n",
    "                    bioes_tags.append('E' + bio_tag[1:])  # End\n",
    "                else:\n",
    "                    bioes_tags.append('I' + bio_tag[1:])  # Inside\n",
    "            else:\n",
    "                raise ValueError(\"Etiqueta BIO incorrecta: {}\".format(bio_tag))\n",
    "        \n",
    "        train_data_bioes.append([(word, bioes_tag) for (word, bio_tag), bioes_tag in zip(sentence, bioes_tags)])\n",
    "    return train_data_bioes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Features per defecte de CRFTagger\n",
      "Precisió: 0.6179245283018868\n",
      "Recall: 0.40494590417310666\n",
      "F1-score: 0.48926237161531283\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor()\n",
      "Precisió: 0.63579604578564\n",
      "Recall: 0.3147861926841834\n",
      "F1-score: 0.42108890420399725\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True)\n",
      "Precisió: 0.6367305751765893\n",
      "Recall: 0.3250901597114889\n",
      "F1-score: 0.4304229195088677\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True)\n",
      "Precisió: 0.6296028880866426\n",
      "Recall: 0.44925296239052037\n",
      "F1-score: 0.524353577871317\n",
      "--------------------------------------------------\n",
      "Model: FeatureExtractor(use_basic_features=True, use_prefix_suffix_features=True, context_features=True)\n",
      "Precisió: 0.6646300067888663\n",
      "Recall: 0.5043791859866048\n",
      "F1-score: 0.5735207967193907\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "train_eng_BIOES = convert_to_bioes_opcional(opcional_train)\n",
    "test_eng_real = convert_to_bioes_opcional(opcional_test)\n",
    "\n",
    "test_eng_pre_tag = obtenir_token_opcional(opcional_test)\n",
    "\n",
    "\n",
    "def model_entrenament(train_eng_BIOES_tag, extractor, test_eng_pre_tag):\n",
    "    if extractor == None:\n",
    "        model_BIOES = CRFTagger()\n",
    "        model_BIOES.train(train_eng_BIOES_tag, 'model_opcional.crf.tagger')\n",
    "        \n",
    "        predicted_BIOES = model_BIOES.tag_sents(test_eng_pre_tag)\n",
    "    \n",
    "    else:\n",
    "        model_BIOES = CRFTagger(feature_func=extractor._get_features)\n",
    "        model_BIOES.train(train_eng_BIOES_tag, 'model_opcional.crf.tagger')\n",
    "        \n",
    "        predicted_BIOES = model_BIOES.tag_sents(test_eng_pre_tag)\n",
    "    \n",
    "    return resultats(predicted_BIOES, test_eng_real, obtenir_entitats_amb_posicions_bioes)\n",
    "\n",
    "for param in param_combinations_eng:\n",
    "    print(f'Model: {str(param)}') if param != None else print(f'Model: Features per defecte de CRFTagger')\n",
    "    model_entrenament(train_eng_BIOES, param, test_eng_pre_tag)\n",
    "    print('-'*50)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
